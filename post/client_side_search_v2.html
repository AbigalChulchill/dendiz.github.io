<!DOCTYPE html>
<html lang="en">
  <head>
    <title>client side search engine v2</title>
      <meta charset="utf-8">
      <meta name="viewport" content="initial-scale=1">
      <link rel="stylesheet" href="/css/style.css">
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.18/dist/katex.min.css" integrity="sha384-zTROYFVGOfTw7JV7KUu8udsvW2fx4lWOsCEDqhBreBwlHI4ioVRtmIvEThzJHGET" crossorigin="anonymous">
      <script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.18/dist/katex.min.js" integrity="sha384-GxNFqL3r9uRJQhR+47eDxuPoNE7yLftQM8LcxzgS4HT73tp970WS/wV5p8UzCOmb" crossorigin="anonymous"></script>
      <script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.18/dist/contrib/auto-render.min.js" integrity="sha384-vZTG03m+2yp6N6BNi5iM4rW4oIwk5DfcNdFfxkk9ZWpDriOkXX8voJBFrAO7MpVl" crossorigin="anonymous"
           onload="renderMathInElement(document.body);"></script>
    </head>
    <body>
        <div>
        <strong>
        <a href="/micro/micro-index.html" onClick="this.href+='?rnd='+new Date().getTime()">Micro</a> &middot; 
        <a href="/post/index.html" onClick="this.href+='?rnd='+new Date().getTime()">Macro</a> &middot; 
        <a href="/post/about.html">About</a> &middot; 
        <a href="/post/now.html">Now</a> &middot; 
        <a href="/post/fn.html">fn</a>
        &middot;
        <a href="/twtxt.txt">twtxt</a>
        </strong>
        </div>
        <hr />
        <div id="main">
        <h1 id="title">client side search engine v2</h1>
        <div id="date"><em>created 2021-10-03 </em></div>
        <div class="content">
        <p>I posted about how to implement a client side search engine with lemmatization for better natural language understanding and query processing before. Since then I've been thinking a bit more about this problem and realized 2 short commings:</p>
<ul>
<li>The index size needs to be much smaller than it's current 1.1mb size because it takes too long to load and parse and the client freezes</li>
<li>There can be cases where the highligthing in the search result may fail because of the lemmatization. If a document has the the word &quot;paying&quot;, but the search term was &quot;paid&quot; even though the document would match, it would not be possible to highlight the match.</li>
</ul>
<p>So I wanted to address these. The first issue needed a restructing of the way the index was being represented. In the old engine there was no inverted index, the search was just looking for multiple versions of the query in all the documents. So the source of all the documents had to be downloaded on the client for the search. I now changed this to a completely different approach. An invereted index is created by the compiler and is the main index for the search. I tried to use a trie structure to store this index bu the overhead of the JSON formatting resulted in a worse file size than just storing then in a dictionary. The trie was about 500kb but using the dict resulted in 350kb.</p>
<p>To address the second issue, the compiler will generate a mapping of the root of a word to all the inflections found in the document. So if you have the word &quot;paying&quot; and &quot;pays&quot; in the doc, the <code>rootMapping</code> variable in the index will contain <code>pay -&gt; [paying, pays]</code>.
This will be used on the client side to do the highlighting. So if the user searched for &quot;paid&quot; the searching code would expand to search to encompass all the versions of the word that was indexed.</p>
<p>In the previous version I had also incorporated synonym expansion but that turned out to be subpar simply because synonyms for words are actually context dependent. Without that context the results would contain low quality results, so I ditched that.</p>

        </div>
        </div>
	<footer>
	<em>generated on 2021-10-03 21:40:47</em>
	</footer>
    </body>
</html>
