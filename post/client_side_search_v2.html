<!DOCTYPE html>
<html lang="en">
  <head>
    <title> client side search engine v2</title>
      <meta charset="utf-8">
      <meta name="viewport" content="initial-scale=1">
      <link rel="stylesheet" href="/css/style.css">
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.18/dist/katex.min.css" integrity="sha384-zTROYFVGOfTw7JV7KUu8udsvW2fx4lWOsCEDqhBreBwlHI4ioVRtmIvEThzJHGET" crossorigin="anonymous">
      <script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.18/dist/katex.min.js" integrity="sha384-GxNFqL3r9uRJQhR+47eDxuPoNE7yLftQM8LcxzgS4HT73tp970WS/wV5p8UzCOmb" crossorigin="anonymous"></script>
      <script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.18/dist/contrib/auto-render.min.js" integrity="sha384-vZTG03m+2yp6N6BNi5iM4rW4oIwk5DfcNdFfxkk9ZWpDriOkXX8voJBFrAO7MpVl" crossorigin="anonymous"
           onload="renderMathInElement(document.body);"></script>
    </head>
    <body>
        <div>
        <strong>
        <a href="/micro/micro-index.html" onClick="this.href+='?rnd='+new Date().getTime()">Micro</a> &middot; 
        <a href="/post/index.html" onClick="this.href+='?rnd='+new Date().getTime()">Macro</a> &middot; 
        <a href="/post/about.html">About</a> &middot; 
        <a href="/post/now.html">Now</a> &middot; 
        <a href="/post/fn.html">fn</a>
        &middot;
        <a href="/twtxt.txt">twtxt</a>
        </strong>
        </div>
        <hr />
        <div id="main">
        <h1 id="title"> client side search engine v2</h1>
        <div id="date"><em>created  2021-10-03 </em></div>
        <div class="content">
        <p>I posted about how to implement a client side search engine with lemmatization for better natural language understanding and query processing before. Since then I've been thinking a bit more about this problem and realized 2 short commings:</p>
<ul>
<li>The index size needs to be much smaller than it's current 1.1mb size because it takes too long to load and parse and the client freezes</li>
<li>The search engine expanded the search by doing a reverse lemmatization on the on the input text. So if the documents contained &quot;paid&quot;, &quot;pays&quot; they would all point to the canonical form &quot;pay&quot; and if the user query was &quot;paid&quot; a search for the versions in the documents (paid, pays) would be performed. This brings performance issues with it.</li>
</ul>
<p>So I wanted to address these. The first issue needed a restructing of the way the index was being represented. In the old engine there was no inverted index, the search was just looking for multiple versions of the query in all the documents. So the source of all the documents had to be downloaded on the client for the search. I now changed this to a completely different approach. An invereted index is created by the compiler and stored as a trie structure in a json file. This is how it looks:</p>
<pre><code>{&quot;h&quot;: {&quot;e&quot;: {&quot;l&quot;: {&quot;p&quot;, &quot;files&quot;: [d1, d2]}, {&quot;e&quot;: {&quot;r&quot;: {}, &quot;files&quot;: [d3]}}}}}} 
</code></pre>
<p>What this represent? It is means that there are 2 docs (d1 and d2) that have the word &quot;help&quot; and 1 doc (d3) that had the word &quot;helper&quot; in it. Since these 2 words share a prefix, using a trie means I only need to store it once. An even better version could be</p>
<pre><code>{&quot;help&quot;: {&quot;er&quot;: {}, files:[d3]}, files: [d1,d2]}
</code></pre>
<p>as it would remove a couple of bytes needed for the propertly formed JSON but would make parsing and generating this JSON a bit more complicated.</p>
<p>To get some more compression there the URLs of the documents are stored in an array and the trie references the positions in that array.</p>
<p>Implementing this method for index storage brougth the download to 0.5mb which is acceptable.</p>

        </div>
        </div>
	<footer>
	<em>generated on 2021-10-03 21:02:39</em>
	</footer>
    </body>
</html>
