<!DOCTYPE html>
<html lang="en">
    <head>
      <title>Deniz's personal pages</title>
      <meta charset="utf-8">
      <meta name="viewport" content="initial-scale=1">
      <link rel="stylesheet" href="/css/style.css">
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.18/dist/katex.min.css" integrity="sha384-zTROYFVGOfTw7JV7KUu8udsvW2fx4lWOsCEDqhBreBwlHI4ioVRtmIvEThzJHGET" crossorigin="anonymous">
      <script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.18/dist/katex.min.js" integrity="sha384-GxNFqL3r9uRJQhR+47eDxuPoNE7yLftQM8LcxzgS4HT73tp970WS/wV5p8UzCOmb" crossorigin="anonymous"></script>
      <script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.18/dist/contrib/auto-render.min.js" integrity="sha384-vZTG03m+2yp6N6BNi5iM4rW4oIwk5DfcNdFfxkk9ZWpDriOkXX8voJBFrAO7MpVl" crossorigin="anonymous"
           onload="renderMathInElement(document.body);"></script>
    </head>
    <body>
        <div>
        <strong>
        <a href="/micro/micro-index.html" onClick="this.href+='?rnd='+new Date().getTime()">Micro</a> &middot; 
        <a href="/post/index.html" onClick="this.href+='?rnd='+new Date().getTime()">Macro</a> &middot; 
        <a href="/post/about.html">üßëüèª‚ÄçüíªAbout</a> &middot; 
        <a href="/post/now.html">‚è∞Now</a> &middot; 
        <a href="/post/fn.html">fn</a>
        &middot;
        <a href="/twtxt.txt">‚úâÔ∏ètwtxt</a>
        </strong>
        </div>
        <hr />
        <div id="main">
        <h1 id="title"> TechScan DevLog 2018-08-10</h1>
        <div id="date"><em> 2018-08-10</em></div>
        <div class="content">
        <h2>summary</h2>
<p>‚Ä¢ reboot the project ‚Ä¢ current status</p>
<h1>Rebooting the project</h1>
<p>A technical analyzer is one of those project I keep returning to. I had already
laid down a nice foundation with TaLib4J for the technical calculations so it‚Äôs
usually cleaning up the glue code that is changing with each new iteration.
This time around I‚Äôve taken a new approach by building a team around the
project to drive me to turn it into a product. I‚Äôve created a multi module
spring project with the following modules: API, Databus, Engine, corelib. The
API is the gateway for clients to access analysis data and takes care of user
management.  The databus module is an API for the api module to access the
data. The engine is a command line application that does the actual
calculations and the corelib is the module that contains common classes shared
by the modules. After initial testing it turned out that having the Databus as
a separate service comes with severe performance penalties due to JSON data
conversions etc, so I integrated the databus module into the corelib module.
You want to go service oriented until you realize that there are only 2 other
services that want to consume it and then you decide to integrate it back.
Keeping the engine separate made sense though as it runs as a batch processor.</p>
<h1>Current status</h1>
<p>As of today there are 33 unique scanners, and I also run the 2 element
combinations of these scanners for a total of 33c2 (528) scanners.  This
produces around 6 M scan results for a 20 month worth of stock EOD data. I want
to increase the combination count but I‚Äôm not sure if the server I have in mind
for production deployment can handle the amount. That‚Äôs on my try this list and
will report how it goes.  I have most of the basic user management features
completed in the API, except for the integrations to payment and transactional
emails.  I‚Äôm also adding performance evaluation for the scanners by means of
running a test from the date the signal was generated going forward and
checking the price went up/down X ATRs confirming the signal. This calculation
is affected by the amount of scan results so increasing the combination count
will have an impact on the performance calculation. I‚Äôve asked a question on
the math StackExchange forum about calculating the conditional probability of 2
technical indicator but have yet to receive a satisfying answer. Being able to
calculate a reasonably (~%1 error maybe?) accurate approximation for this would
mean that I do not have the actually run all the combinations to get their
scores. I‚Äôm also using an error rate calculation based on Z-tables to give a
confidence interval on the scanner score.  A nice optimization I did was to
keep all the stock OHLCV data in cache and use a binary search to query data
between given dates instead of hitting the DB for each time. In the earlier
version I was actually keeping the raw OHLCV data in files but reading them
into cache takes longer than reading them from a DB plus using a DB also gives
opportunities for querying in different ways which I need in the future.</p>
<p>Yesterday I noticed that one the scanners used 4 conditions to check for a
signal ma5 &gt; ma26 , ma26 &gt; ma50, ma50 &gt; ma200, stoch &lt; 20.  This led me to the
idea that I should actually make each of these conditions a scanner on it‚Äôs own
and brute force my way through all of the combinations to reach the ideal
scenario for each symbol by calculating the score. Maybe the best results for a
stock are when ma5 &lt; ma26, ma26 &gt; ma50, ‚Ä¶ because there was a short term fall
in the price for the stoch to reach a low etc.  I also implemented an
optimization for the score calculator yesterday. Pre-optimization I was looping
each symbol, fetching the scan results for each symbol and calculating the
score for the scanners from those results. This was doing too much DB round
trips. I changed it to looping through each scanner combination and storing the
results of the scans in a map keyed by it‚Äôs symbol. This is 1 less loop and
less DB requests.</p>

        </div>
        </div>
	<footer>
	<em>generated on 2021-09-30 22:06:31</em>
	</footer>
    </body>
</html>
