<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Deniz's Web blog</title><link>https://dendiz.github.io</link><description>Deniz's personal web space</description><language>en-US</language><lastBuildDate>Sun, 16 Jan 2022 22:09:36 GMT</lastBuildDate><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>My MacBook pro just died</title><description>the story of my macbook pro and how it died</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Mon, 08 Nov 2021 00:00:00 GMT</pubDate><guid isPermaLink="true">mbp32_death.html</guid><content:encoded>&lt;p&gt;I got a macbook pro from work around 2 years ago. It was the replacement for the first macbook pro they gave me which was not the correct specs. The new one was a monster: Core i9 with 32gb RAM and 1tb disk space. Unfortunately it had the touchbar and the crappy keyboard that feels okay to type on but is just super unreliable. It has been my daily driver in conjunction with my iMac ever since, spending countless CPU cycles on compiling objective c and swift code.&lt;/p&gt;
&lt;p&gt;This morning I stopped at a Safeway to get some groceries and also picked up a bottle of sparkling flavored water. I put the bottle in my bag, went home then went to the office. I opened the bottle at my desk and it squirted everywhere including all over my laptop's keyboard and me. I got some paper towels and dried it up and everything seemed to be working fine, computer still alive - phew. I did my daily stuff and then packed it back in my bag, started driving to pick up my kid. After we got home I put a half full water bottle that was sealed properly in my bag and went inside. As soon as I got inside I set my bag on the chair and took out the water bottle and put it somewhere else. Then we had dinner, etc. A totally ordinary evening. After my kid went to sleep I thought I’d get some work done so I went to take out my laptop and realized the chair was wet. It looked like water had leaked from the bag and got the chair wet. I was surprised at how that could have happened but didn't dwell on it and got my computer and went upstairs. I plugged my screens in the usb-c ports and opened the lid. The screens turned on and I tried to enter my password but some of the keys didn’t register. Crappy butterfly keyboard I thought and tried again. No luck. I also realized some shadows on the screen but I had just upgraded to Monterey and thought it was part of the new wallpaper. I wanted to use the trackpad to click on something but it wasn’t clickable. At this point I noticed water leaking out from in between the keys and that what I saw on the screen were not shadows but water. The more I pressed the more water came out. Then I heard a hissing sound coming from the side vents. I was scared something was wrong with the battery, but that wasn’t very likely. The hissing went on for a few seconds and then the computer shut itself off. And I think it was for good, as it has not responded to any of my power on attempts. There was still some water coming out of the chassis after it had been off for 10 minutes.&lt;/p&gt;
&lt;p&gt;I don’t miraculously expect it to come back to life so I started setting up an environment on my old macbook. I’m still puzzled how so much water could have come out of the computer. I checked the bottle I had in the bag that I took out and it was still half full so I don't think it's that. My best guess is that the accident from the morning leaked when I put the computer vertically in the bag. Or maybe it's ghosts?&lt;/p&gt;
</content:encoded></item><item><title>Micro rss</title><description>Micro blog syndication</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Sun, 07 Nov 2021 00:00:00 GMT</pubDate><guid isPermaLink="true">micro-rss.html</guid><content:encoded>&lt;p&gt;The micro posts page no longer exists in HTML form, but can only be accessed via RSS.&lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;You can subscribe &lt;a href="/micro.rss"&gt;here&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;A good news reader for iOS is NetNewsWire and there are many many other RSS readers
available on all platforms.&lt;/p&gt;
</content:encoded></item><item><title>Macro rss</title><description>Macro blog syndication</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Sun, 07 Nov 2021 00:00:00 GMT</pubDate><guid isPermaLink="true">macro-rss.html</guid><content:encoded>&lt;p&gt;The macro posts page no longer exists in HTML form, but can only be accessed via RSS.&lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;You can subscribe &lt;a href="/macro.rss"&gt;here&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;A good news reader for iOS is NetNewsWire and there are many many other RSS readers
available on all platforms.&lt;/p&gt;
</content:encoded></item><item><title>AirPod Max review</title><description>My thoughs on the AirPod Max after 6 months of daily usage</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Sat, 06 Nov 2021 00:00:00 GMT</pubDate><guid isPermaLink="true">airpod_max_review.html</guid><content:encoded>&lt;p&gt;I was pretty reluctant to get the Airpod Max’s even with my discount. I have never spent that much money on headphones and the thought of it just put me off. I went to the apple store to get something unrelated and had the opportunity to try them out. I’m not an audiophile or a music snob, but I do listen to music 6-8 hours every week day and have been playing an instrument for 20+ years. I recall doing this musical IQ test for some university online and got an average score. I also did a test where you listen to different samples recorded in different quality and didn’t really do well on it. Later a friend of mine who is a self proclaimed audiophile proved to me that equipment really does make a difference and the reason why I scored ⅗ on that test was equipment. I was given a beats solo 3 when I first started working at my current company but those cans got destroyed after 1.5 years of use. I was absolutely shocked as I do take care of my stuff. So I was in the market for some wireless headphones and the AirPod Max just came out. So at the store I put them on and fired up Apple music to try out the sample songs. And, yeah it sounded great. The noise cancelling was sublime, it was as if everybody just disappeared and I was alone in that store. I then searched for a song that I knew well to really understand what the device could deliver. It had crystal clear highs, great mids and beefy bass. Not overpowering but easy to distinguish all the notes the bass was playing and each kick drum note. I tried fooling around with the spatial audio stuff but wasn’t too interested in that. So I think the sound and the quality of music that flows is great, 5 stars would buy again.&lt;/p&gt;
&lt;p&gt;The first thing I noticed as many others have pointed out is that the device is pretty heavy. I thought that would not be a problem as I’m not planning on being mobile while wearing it but after about 6 months of owning it my ears do feel the fatigue of carrying that extra weight some days. When I do get tired I switch to my Sony MDR1A or Audio Technica ATH50x headphones which probably weigh less than a half of the AirPod Max.&lt;/p&gt;
&lt;p&gt;Another downside is that wireless, while convenient , does not perform well when latency is a concern, so no guitar recording is possible with this. I kind of guessed it wouldn’t work but gave it a try anyway and just as I thought there is maybe a 500ms delay after hitting a string and sound coming through the headphones. Not a big deal as I wasn’t expecting this to work.&lt;/p&gt;
&lt;p&gt;Apart from the music usage with the COVID era I’m in virtual meetings and use it to communicate. The audio quality and the mic quality are great, no complaints there. The battery life is also good for home use, I can get 2 days of usage without charging if I leave it in the black case that puts it to ultra power saving mode.&lt;/p&gt;
&lt;p&gt;Would I recommend it? I guess it depends on your situation. If you are in the Apple ecosystem the AirPod Max fits in perfectly, has great sound quality and looks sleek (like any Apple product). If you are not in the ecosystem and are audio savvy you could probably get better bang for your buck elsewhere.&lt;/p&gt;
</content:encoded></item><item><title>Ticker data upsampling for stocks</title><description>increasing the resolution for Yahoo stock price data</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Fri, 15 Oct 2021 00:00:00 GMT</pubDate><guid isPermaLink="true">ohlc_upsampling.html</guid><content:encoded>&lt;p&gt;Finding good data for stock prices is a pain. There are some paid providers which are good as far as their reviews go but are pretty expensive. I've been using the free Yahoo data api that gives stock prices on a daily resolution. Is this probably fine for most algorithms but I wanted to come up with a method for increasing the resolution of the data from daily to minutely for day trading applications.&lt;/p&gt;
&lt;p&gt;Some research on this showed that this process is called &amp;quot;upsampling&amp;quot; which is the reverse (doh!) of downsampling. Downsampling is easy, you just lose some of the data to reduce the bandwidth, but the reverse is not easy. I didn’t really see any useful articles for financial data (there are some for other types of time series). The major difference for daily stock data is that you have some extra data points such as the high and low of the day, the open and close. All this can be incorporated into the upsampling process to make it more realistic.&lt;/p&gt;
&lt;p&gt;The main idea for upsampling is interpolating the missing data points in between the given data points. There are a couple of ways this can be done:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Linearly&lt;/li&gt;
&lt;li&gt;Polynomially&lt;/li&gt;
&lt;li&gt;Using splines&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;….&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/upsampling.png"&gt;illustration1&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In the image you only have the data points A,B,C,D and these points are joined by lines. Since you can figure out the equation of a line given two points you interpolate that the missing data points are on that line. This is called “linear interpolation” because you are drawing lines. A line is an equation of the first degree. If you take this to higher degrees you will get a smoother fit, this is called polynomial interpolation.&lt;/p&gt;
&lt;p&gt;For interpolating stock price data we use the open price and close price at the beginning and end of a list. We can then fill that list up with N null values, N depending on the resolution we are aiming for. If we wanted minutely resolution then we would select N as follows:
The market opens at 9:30a and closes at 4p (discard extended hours). This means there are 6.5 hours worth of minutes which are 6.5 * 60 = 390 minutes. So we would have an array with 390 elements for each trading minute. The first element of this array would be the opening price and the last would be the closing price.&lt;/p&gt;
&lt;p&gt;During the day the stock makes a high and a low. We can select these points to be random points in the day. There are no obvious patterns of when during the day stocks make their high and low points so a uniform random selection is adequate. One invariant is that the time of the high and low cannot be the same. Once we have the indices for the high and low points in the day we can put those values in the array at the correct points. Our list would be something like this&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[open, ….., high, …., low, …. Close]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we can run a linear or polynomial interpolation of a low degree to get the missing data points. The resulting chart wouldn’t be a good representation of the path a stock price would take during a trading day. The missing element here is noise. To add noise we can adjust each point on the lines by a random factor from a gaussian distribution. The reason to use a gaussian distribution is that most of the price movements from point i to point i+1 are within a certain percentage.&lt;/p&gt;
&lt;p&gt;A function like&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;fn = lambda x: random.gauss(x, x/50)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That is applied on each element of the list will introduce a good amount of noise. Plotting this graph will show that we have a very jagged chart with sharp movements.&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/upsampling2.png"&gt;chart1&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;We can smooth this signal by taking a rolling average of N periods to achieve a final chart that looks this&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/upsampling3.png"&gt;chart2&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Visually this looks a good approximation of how a stock price may move during a day still satisfying the constraints we set up at the beginning. Starting at the open price, hitting the high and low, then closing at the correct price.&lt;/p&gt;
</content:encoded></item><item><title>Votagoo backpack review</title><description>My thoughts about this backpack after a month of usage</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Sun, 10 Oct 2021 00:00:00 GMT</pubDate><guid isPermaLink="true">votagoo-backpack-review.html</guid><content:encoded>&lt;p&gt;Honestly during COVID I didn't have the chance to use a lot of bags (but this didn't stop me from accumulating more 😅). This backpack was no exception, but in the last few weeks I have been trying to go out more and take a bag with me.&lt;/p&gt;
&lt;p&gt;So how did I find this bag? Well after spending a lot of time on Amazon I realized that some companies offer the exact same bag with different branding for different prices. This is known practice called white labeling. But this type of deeper research enabled me to find this bag which I think is made by the same factory that makes the Direct Action Dragon egg mk2 bag but skips the branding and sells it for half the price. Either this or they just cloned it. It's made from durable nylon material (probably 500D) and has laser cut molle webbing in the front. It has some organizational pockets which are good for storing small items like a wallet, airpods, etc. and offer quick access. The main compartment is big and offers a mesh pocket. It can easily accommodate an A4 rocketbook, 13&amp;quot; iPad, mid size tech organizer, headphones. The laptop compartment is at the back and you have to get the straps out of the way to access them. It looks like it offers decent protection and can also be used as a hydration bladder compartment.&lt;/p&gt;
&lt;p&gt;The zippers are good quality and silent with some rope attached to function as the handle you pull on. The top handle is braided and looks cool but I'm a bit concerned it's going to come undone. The hardware is lacking in quality as it can't hold the straps in place properly and they slide. I need to take some extra measures to fix them. Not sure if it's water proof as I haven't used it in rain, but fall is upon us and I will go out to test that.&lt;/p&gt;
&lt;p&gt;Overall it's a cool looking bag and good value.&lt;/p&gt;
</content:encoded></item><item><title>Client side search engine v2</title><description>some improvements on the previous approach for a client side search engine implementation</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Sun, 03 Oct 2021 00:00:00 GMT</pubDate><guid isPermaLink="true">client_side_search_v2.html</guid><content:encoded>&lt;p&gt;I posted about how to implement a client side search engine with lemmatization for better natural language understanding and query processing before. Since then I've been thinking a bit more about this problem and realized 2 short commings:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The index size needs to be much smaller than it's current 1.1mb size because it takes too long to load and parse and the client freezes&lt;/li&gt;
&lt;li&gt;There can be cases where the highligthing in the search result may fail because of the lemmatization. If a document has the the word &amp;quot;paying&amp;quot;, but the search term was &amp;quot;paid&amp;quot; even though the document would match, it would not be possible to highlight the match.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So I wanted to address these. The first issue needed a restructing of the way the index was being represented. In the old engine there was no inverted index, the search was just looking for multiple versions of the query in all the documents. So the source of all the documents had to be downloaded on the client for the search. I now changed this to a completely different approach. An invereted index is created by the compiler and is the main index for the search. I tried to use a trie structure to store this index bu the overhead of the JSON formatting resulted in a worse file size than just storing then in a dictionary. The trie was about 500kb but using the dict resulted in 350kb.&lt;/p&gt;
&lt;p&gt;To address the second issue, the compiler will generate a mapping of the root of a word to all the inflections found in the document. So if you have the word &amp;quot;paying&amp;quot; and &amp;quot;pays&amp;quot; in the doc, the &lt;code&gt;rootMapping&lt;/code&gt; variable in the index will contain &lt;code&gt;pay -&amp;gt; [paying, pays]&lt;/code&gt;.
This will be used on the client side to do the highlighting. So if the user searched for &amp;quot;paid&amp;quot; the searching code would expand to search to encompass all the versions of the word that was indexed.&lt;/p&gt;
&lt;p&gt;In the previous version I had also incorporated synonym expansion but that turned out to be subpar simply because synonyms for words are actually context dependent. Without that context the results would contain low quality results, so I ditched that.&lt;/p&gt;
</content:encoded></item><item><title>Yaran diyaloglar</title><description>🇹🇷Funny dialogs - Turkish</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Tue, 21 Sep 2021 00:00:00 GMT</pubDate><guid isPermaLink="true">yaran_diyaloglar.html</guid><content:encoded>&lt;p&gt;&lt;em&gt;2021-09-21&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Sabah telefonu kic cebine koyan B apple watch'undan telefonu pingler. Yakininda caldigini fark eder ama tam anlayamaz. Acaba minderin altinda mi diye bakar. Bulamayinca acaba yukaridan mi geliyor diye yukari cikip tekrar pingler. &amp;quot;alla alla cok ta yakinda sanki&amp;quot; diye dusunur.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;2020-11-14&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Konu workout app’i aboneligine devam edip etmemektir.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;B: zaten zorluk kucuk steplerle gradually artiyor. Sen ara versen de donunce kaldigin videodan devam ediyorsun&lt;/p&gt;
&lt;p&gt;D: o zaman bi baslayip butun videolara bakip not alip tum contenti alabilirsin, abonelige gerek kalmaz&lt;/p&gt;
&lt;p&gt;B: gunde 24 saat yapsan haraketleri…&lt;/p&gt;
&lt;p&gt;D: puhaha haraketleri niye yapiyorsun sadece videolara baksan yeter 😂😂&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Dogrucu davutluk boyle bisi iste.&lt;/p&gt;
</content:encoded></item><item><title>New microblogging tools</title><description>Some changes to the way I microblog (and blog)</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Tue, 21 Sep 2021 00:00:00 GMT</pubDate><guid isPermaLink="true">new_microblog_tools.html</guid><content:encoded>&lt;p&gt;I recently stumbled upon an old initiative called twtxt which is an indie-web type of project to replace micro blogging platforms. The idea is very simple, a file called twtxt.txt on your server per user to hold the updates. The file format is dead simple too with a timestamp and the text. It doesn't support embedded images etc but that's not really a big deal as you can add rudimentary markdown support to the client to display images from a URL.&lt;/p&gt;
&lt;p&gt;I'm not really publishing these updates for others or to start conversations etc. so I don't really care if it is federated or not but the data storage is so simple it just makes sense to adopt it. With this in mind I sat down for a day over the weekend to create a tool that imports the micro posts from the jupyter notebooks that I was using into the twtxt file. The twtxt file by itself is not enough to display the posts, so I had to write a script to output all the static html pages hosted in github. Well, since I started I though I might as well simplify the whole process and converted the macro post notebooks to markdown as well. My end goal with this conversion was to import these into Obsidian, but I might not do that.&lt;/p&gt;
&lt;p&gt;After migrating the micro-imap scripts to Laminar, I started enjoying stable micro post updates with proper error logging etc. But sending an email everytime to post was getting a bit cumbersome, so I also added support to post updates via a telegram bot.&lt;/p&gt;
</content:encoded></item><item><title>RocketBook review</title><description>Thoughts about the RocketBook notebook</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Thu, 09 Sep 2021 00:00:00 GMT</pubDate><guid isPermaLink="true">rockerbook-review.html</guid><content:encoded>&lt;p&gt;The RocketBook reusable notebook is just what it sounds like - a reusable notebook that you can archive and erase and reuse. The writing experience is somewhere between the Apple pencil + iPad and a plain notebook. You have to use the Pilot Frixion erasable pens which are pleasant to use. The paper on the notebook is coated and feels like it lacks friction. The metal binder makes it difficult to fold it and write on a table because the height difference makes it unstable on the flat surface but it’s not too bad.&lt;/p&gt;
&lt;p&gt;The iOS app is good. It’s very easy to snap the pages and archive them as a PDF. This process has to be seamless because you’ll be snapping 20 pages or so when the notebook is full. There are features like some rudimentary OCR to extract titles and categorize pages but I haven’t used any of them. Erasing the pages of the notebook is a hassle. There is a microfiber cloth that comes with it which you have to dampen and scrub the pages clean. That cloth gets dirty with ink and you have to clean it a couple of times and give it a good squeeze and continue cleaning. Maybe the microwave erase version is better, but cleaning is tedious.&lt;/p&gt;
&lt;p&gt;I mainly use this for quick note taking during the day, or note taking when reading a book. I also got a small notepad version that’s more portable.&lt;/p&gt;
</content:encoded></item><item><title>Magic Keyboard review</title><description>iPad pro + magic keyboard review</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Thu, 02 Sep 2021 00:00:00 GMT</pubDate><guid isPermaLink="true">Magic-keyboard-review.html</guid><content:encoded>&lt;p&gt;I tried to resist for a long time, tried to use my 15&amp;quot; laptop but it's just not the same. I tried cheap keyboards with track pads from amazon but that was not the same either. So when I got an unexpected budget for spending due to some life events, I decided to go for it an get the magic keyboard for the 12.9&amp;quot; iPad.&lt;/p&gt;
&lt;p&gt;The feel of the keys are great. It's missing the f keys and an escape key but that's ok. I was thinking the escape key would be an issue in vim but I've gotten used to the &lt;code&gt;ctrl+[&lt;/code&gt; pretty quick. The track pad is really good, precise and no lagging at all. This makes all the difference compared to the cheaper keyboards out there.&lt;/p&gt;
&lt;p&gt;The magnetic attachment system is good, makesit very easy to detach the device for tablet use. The angels of usage are very limited though, so if you want a steep angel or fold the device back completely, that's not going to happen.&lt;/p&gt;
&lt;p&gt;another topic I was worried about was the stability while using it on my lap. On a table it's great, just like a laptop but what happens on an uneven surface like a pairof legs? Well once you find your balance it's pretty decent. Finding that balance does't take long either so I'm pretty happy with the way everything turned out.&lt;/p&gt;
</content:encoded></item><item><title>Jupyter notebook custom magic</title><description>How to get a custom magic working for your jupyter notebook</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Wed, 01 Sep 2021 00:00:00 GMT</pubDate><guid isPermaLink="true">jupyter_magic.html</guid><content:encoded>&lt;p&gt;Jupyter notebooks a great way of prototyping small programs and exploring/visualizing data from scripts. I use them to run back tests on trading algos. One of the most power features is that you can actually pipe the contents of a cell to another python function. This feature came in really handy when I wanted to pipe a trading algo into my backtesting framework. To accomplish this you need to make use of &amp;quot;magics&amp;quot;&lt;/p&gt;
&lt;p&gt;First create a function in your &lt;code&gt;__init__.py&lt;/code&gt; file in your package&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;def load_ipython_extension(ipython):
        def rtrade(line, cell):
            parser = argparse.ArgumentParser()
            parser.add_argument(&amp;quot;-s&amp;quot;, help=&amp;quot;start date YYYY-mm-dd&amp;quot;, dest=&amp;quot;start&amp;quot;,
                    action=&amp;quot;store&amp;quot;, required=False)
            parser.add_argument(&amp;quot;-e&amp;quot;, help=&amp;quot;end date YYYY-mm-dd&amp;quot;, dest=&amp;quot;end&amp;quot;,
                    action='store', required=False)
            parser.add_argument(&amp;quot;-o&amp;quot;, help=&amp;quot;result output file name&amp;quot;, dest=&amp;quot;output&amp;quot;,
                    action='store', required=False, default=&amp;quot;result_df.pickle&amp;quot;)
            # We create a string buffer containing the
            # contents of the cell.
            args = parser.parse_args(line.split())
            sio = StringIO(cell)
            print(&amp;quot;dates&amp;quot;,args.start)
            print(&amp;quot;end&amp;quot;, args.end)
            return Simulator(args.start, args.end, args.output).test(cell)
        ipython.register_magic_function(rtrade, &amp;quot;line_cell&amp;quot;, &amp;quot;rtrade&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;when we load the extension Jupyter will execute this function for us. The line parameter is the line of the magic function and the cell parameter is the contents of the cell.&lt;/p&gt;
&lt;p&gt;Load the extension with (my package is called retrotrade)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;%load_ext retrotrade
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;now execute the magic with&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;%%rtrade -s 2020-01-01 -e 2021-01-01 -o result.pickle

&amp;lt;some python code&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The line parameter above will contain the first line that starts with &lt;code&gt;%%&lt;/code&gt; and the cell parameter will contain the rest of the cell contents.&lt;/p&gt;
</content:encoded></item><item><title>DimWorld</title><description>A game like Rim World / Dwarf fortress</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Mon, 30 Aug 2021 00:00:00 GMT</pubDate><guid isPermaLink="true">dim_world.html</guid><content:encoded>&lt;p&gt;I am totally fascinated by Dwarf Fortress and the detail it can achieve. I have huge respect for Tarn who is the programmer of the game (and his brother too, who designed the game and probably came up with a lot of those great ideas). It’s a masterpiece in procedural generation for sure. I wish I had the time to play it thoroughly but I only have the time to study it and try to understand it’s mechanics. To this end I even bought the book “Getting started with Dwarf Fortress”. The best way to learn and understand procedural generation is to try to copy the masters, so I started something new: Dim World, a base building game that is set on some planet where you tell your colonists what to do and they might eventually do it.&lt;/p&gt;
&lt;p&gt;The first thing is to get a map going so I ported over some cellular automata terrain generation code I had lying around to Swift. Refresher: Cellular automata basically generates or changes a tile based on the state of its neighbors. E.g If you have more than 4 neighbors that are alive the current cell dies and if you have 3 or less neighbors dead the cell becomes alive. This leads to interesting and natural-like patterns on the terrain.&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/dimworld1.png"&gt;dimworld&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The bright green and brown glyphs are trees and the blobs are forests. I had to augment the cellular automata generator with a flood fill algorithm to turn the blobs into things that resemble forests without holes. The trick here was to fill every hole except the largest one (which is the rest of the terrain).&lt;/p&gt;
&lt;p&gt;Here's a video of some keyboard controls and map generation:&lt;/p&gt;
&lt;p&gt;&lt;a href="/files/dimworld-21-08-30.mov"&gt;video&lt;/a&gt;&lt;/p&gt;
</content:encoded></item><item><title>Stock price data pattern matching</title><description>Using pattern matching to predict stock directions</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Thu, 22 Jul 2021 00:00:00 GMT</pubDate><guid isPermaLink="true">stock_price_pattern_matching.html</guid><content:encoded>&lt;p&gt;Playing around with stock data is always fun. &lt;em&gt;I think using any of the methods you see around here are a good way to lose money so only use for your self education or entertainment.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;So the basic idea around this a pattern matching approach is that history will repeat itself. That means for the stock we want to predict at time T, let's get all the data points from T-x and try to match the pattern that this produces against the history of other stock and then for all the matches at a point in time, say T' (which is before T) we can look at T'+1, T'+2, ... to see what that stock did. Is this a good way to trade? Probably not, but it's a fun little project for learning about vector similarities.&lt;/p&gt;
&lt;p&gt;So how do we know that a time series pattern is looks like another one? The idea is to match the shape of the series so we need to disregard the amplitude of the signal. E.g the following signals have the shape but are quite far away from each other&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;s1: [1,2,3,4,5]

s2: [1001, 1002, 1003, 1004, 1005]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The approach I'll describe here is a simple approach called manhattan distance similarity. The idea is to scale down the two signals so that their values are between 0 and 1. This way both signals become comparable for our distance metric. The distance is the sum of the absolute value of the difference of each element with the same index.&lt;/p&gt;
&lt;p&gt;So for a signal &lt;code&gt;[0.5, 0.7, 0.9]&lt;/code&gt; and &lt;code&gt;[0.4, 0.6, 0.8]&lt;/code&gt; the difference is &lt;code&gt;[0.1, 0.1, 0.1]&lt;/code&gt; and the sum is 0.3.
Taking the absolute value negates the fact that the signal could be above or below the other.&lt;/p&gt;
&lt;p&gt;This is a brute force approach and there are faster data structures for these types of queries such as KDTrees that are efficient if the signal length is short (maybe &amp;lt; 20 periods)&lt;/p&gt;
&lt;p&gt;There are other methods of time series comparison suck dynamic time warping that are resistant to phase shift etc and could be used to optimize the search.&lt;/p&gt;
&lt;p&gt;To start let's load all our stock data into a dictionary of dataframes.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import os
import pandas as pd

directory = &amp;quot;../../exo/Workbench/csv/&amp;quot;
dfs = {}
for filename in os.listdir(directory):
    dfs[filename.replace(&amp;quot;.csv&amp;quot;, &amp;quot;&amp;quot;)] = pd.read_csv(os.path.join(directory, filename), index_col=&amp;quot;date&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;dfs[&amp;quot;aapl&amp;quot;].head()
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;           symbol      open      high       low     close       volume
date                                                                  
1980-12-12   aapl  0.128348  0.128906  0.128348  0.128348  469033600.0
1980-12-15   aapl  0.122210  0.122210  0.121652  0.121652  175884800.0
1980-12-16   aapl  0.113281  0.113281  0.112723  0.112723  105728000.0
1980-12-17   aapl  0.115513  0.116071  0.115513  0.115513   86441600.0
1980-12-18   aapl  0.118862  0.119420  0.118862  0.118862   73449600.0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let's define some constants to make the code reusable with different parameters&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;WINDOW = 20
MAX_CANDIDATES = 5
TARGET_ENDDATE = &amp;quot;2021-07-14&amp;quot;
TARGET_STARTDATE = &amp;quot;2020-01-14&amp;quot;
TARGET_SYMBOL = &amp;quot;AAPL&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A class to hold the results of the matching&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
class SimResult:
    def __init__(self, symbol, score, start, end, past, future):
        self.symbol = symbol
        self.score = score
        self.start = start
        self.end = end
        self.past = past
        self.future = future
    def __repr__(self):
        return f&amp;quot;{self.symbol} {self.score} {self.start} {self.end}&amp;quot;

&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;import time
from sklearn.preprocessing import MinMaxScaler
start = time.time()
target_enddate = TARGET_ENDDATE
target_startdate = TARGET_STARTDATE
target_symbol = TARGET_SYMBOL.lower()

import numpy as np
src_df = dfs[target_symbol].loc[target_startdate:target_enddate].copy()
src_df['scaled_close'] = MinMaxScaler().fit_transform(src_df.close.values.reshape(-1, 1))
src_window = src_df[-WINDOW:].scaled_close
progress = 0
simres = []
mod = len(dfs) // 10
for symbol, df in dfs.items():
    if symbol == target_symbol:
        continue
    if progress % mod == 0:
        print(&amp;quot;.&amp;quot;, end='')    
    progress += 1

    tgt_df = dfs[symbol].loc[target_startdate:target_enddate].copy()
    if len(tgt_df.close) &amp;lt; WINDOW + 1:
        continue
    if df.iloc[-1].close &amp;lt; 10:
        continue
    tgt_df['scaled_close'] = MinMaxScaler().fit_transform(tgt_df.close.values.reshape(-1, 1))
    scores = tgt_df.scaled_close.rolling(window=WINDOW).apply(        
        lambda x: -sum([abs(x-y) for (x,y) in np.stack((x, src_window), axis=1)])
    )    
    index = scores.argmax()
    sr = SimResult(symbol, scores.max(), &amp;quot;&amp;quot;, &amp;quot;&amp;quot;, 
              tgt_df.iloc[index-WINDOW:index].scaled_close, 
              tgt_df.iloc[index:index+WINDOW].scaled_close)
    simres.append(sr)

simres.sort(key=lambda x: x.score, reverse=True)
print(&amp;quot;elapsed&amp;quot;, time.time() - start)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;...........elapsed 69.85303258895874

&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;import matplotlib.pyplot as plt
import numpy as np
y = src_window
plt.plot(y, label=target_symbol, color='black')
for i in range(0,5):
    both = np.concatenate([simres[i].past , simres[i].future])
    plt.plot(both, label=simres[i].symbol)
plt.axvline(x=WINDOW-1)    
plt.legend()
plt.show()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a href="/img/50cb457d6aac45bc899121d7dcdb66fe.png"&gt;/img/50cb457d6aac45bc899121d7dcdb66fe.png&lt;/a&gt;&lt;/p&gt;
</content:encoded></item><item><title>TechScan DevLog 2021-03-03</title><description>Backtesting and Engine development</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Wed, 03 Mar 2021 00:00:00 GMT</pubDate><guid isPermaLink="true">techscan_devlog_2021-03-03.html</guid><content:encoded>&lt;p&gt;So today I took some time to add type annotation to the code. Python is cool and all but untyped languages can get out of hand very very easily when the code base gets larger so I just went ahead and got that out of the way.&lt;/p&gt;
&lt;p&gt;Now that the core of the data sync is completed I started on the other components that will consume the data: The backtester and the engine. The back tester is responsible for invoking the engine with the correct data for each day of the back testing range and then consolidating the results from the engine with the wallet. The engine is just loading the strategies and executing them. I wanted the flexibility of writing the strategies with Jupyter so that I can debug and plot etc. while developing. I had put together a simple script called &lt;code&gt;jupdev&lt;/code&gt; that extracts the python code cells from a notebook and writes them as a python file, so that came in handy. One issue that I’m pondering is should the strategies be executed against each symbol one by one and their results applied to a wallet that’s dedicated to that symbol/strategy pair or would it make sense to have strategies return an action for multiple symbols and have a global wallet. The former option is a nice way of gauging how each strategy performs on a symbol but doesn’t support portfolio type strategies. Still exploring the differences on this.&lt;/p&gt;
&lt;p&gt;When the data syncer makes a request and gets back an error, it’s usually because Yahoo doesn’t track that symbol. I didn’t want the syncer making the same request over and over again for non-existent symbols so I added a black list. Everytime a symbol errors a counter is incremented in the list. When the counter reaches a certain value the symbol is blacklisted.&lt;/p&gt;
&lt;p&gt;I’m also pretty tired with the amount of TALib build that I need to do for docker images so I wanted a solution purely based on Pandas. I found a project on GitHub called Finta which is exactly this. So I created a fork of this as I want to add other stuff like Ehlers indicators and support/resistance detectors etc.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
&lt;/code&gt;&lt;/pre&gt;
</content:encoded></item><item><title>TechScan DevLog 2021-03-02</title><description>Data sync + pandas bug?</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Tue, 02 Mar 2021 00:00:00 GMT</pubDate><guid isPermaLink="true">techscan_devlog_2021-03-02.html</guid><content:encoded>&lt;p&gt;Ok, more work tonight went into improving the data synchronizer. I thought it would make sense to precompute the resampled values for tickers instead of computing them on-the-fly for an indicator because the most common resampled periods are known beforehand.  Pandas provides a convenient resampling function that supports aggregation to OHLC. I had always used the closing value of the most granular period when resampling say a 1 day OHLC to 1 week. But today I found out that using the following configuration makes much more sense&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;+        config = {'open': 'first',
+            'high': 'max',
+            'low': 'min',
+            'close': 'last',
+            &amp;quot;volume&amp;quot;: &amp;quot;sum&amp;quot;
+        }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I also refactored some of the persistence layer code and added support for providing the sample rate when saving CSV files. On the topic of CSV files I had to combat my way through DataFrames because of my ignorance. I was manually assigning the date field as the index when loading the CSV but there is a convenience method in the API that can make the reader parse the dates and also specify an index column. That’s neat. But then I had some other bugs when merging the data frame from the existing file with any new data from the APIs. Took a while to figure out exactly what was happening but got it working in the end.&lt;/p&gt;
&lt;p&gt;I also was plagued by bugs in Pandas DataReader. When I make a request that starts on current day and ends some date in the future the return data contains a duplicate.&lt;/p&gt;
&lt;p&gt;&lt;a href="attachment:Screen%20Shot%202021-03-06%20at%202.52.53%20PM.png"&gt;Screen%20Shot%202021-03-06%20at%202.52.53%20PM.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Took a while to narrow this down but having a Jupyter notebook came in handy. So to fix this I decided to make sure the end date is always on the us/eastern time zone and if the last row’s date is the same as the end date, no request needs to be made. This should prune any unnecessary requests and avoid this pandas bug.&lt;/p&gt;
&lt;p&gt;And last item for today was the implementing the data loader. This class will allow the backtester and signal generator to load the ticker data for a given date. The tricky part here was that weekends and holidays don’t exist in the index. So any request made with that date should return the data up to that date. This can be done easily with a binary search to get the insertion index and then calculate the slice of the data frame to return.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
&lt;/code&gt;&lt;/pre&gt;
</content:encoded></item><item><title>TechScan DevLog 2021-03-01</title><description>Re-re-rebooting</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Mon, 01 Mar 2021 00:00:00 GMT</pubDate><guid isPermaLink="true">techscan_devlog_2021-03-01.html</guid><content:encoded>&lt;p&gt;So it's been a while since I had a look into my TechScan project. I’ve decided to take another spin at the platform with a data repo that unifies data from different providers, the engine based on pandas dataframes with a back tester and a signal generator.&lt;/p&gt;
&lt;p&gt;My starting point was the data repo. This component syncs data from providers (like Yahoo, Bitfinex, etc) and stores them as a CSV file on disk. There are another couple of issues that need to be handled by this component too. For example resampling of the data to different time periods and making sure the provider isn’t slammed with requests that would not result in any new data. This caching of data makes it very convenient to run multiple strategies multiple times in a row without worrying about being banned from the provider.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
&lt;/code&gt;&lt;/pre&gt;
</content:encoded></item><item><title>Consumption 2021/02</title><description>What I consumed in 2021/02</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Mon, 01 Mar 2021 00:00:00 GMT</pubDate><guid isPermaLink="true">consumption-2021-02.html</guid><content:encoded>&lt;h2&gt;AirPods Max: An Audiophile Review&lt;/h2&gt;
&lt;p&gt;An article that goes deep into what the AirPod Max has to offer - from the perspective of someone who has been in the industry for a decade. I was considering buying these so I went through the article. Has it changed my mind? Not yet, I’m still contemplating it as it's expensive.&lt;/p&gt;
&lt;h2&gt;Amazon almost killed BestBuy&lt;/h2&gt;
&lt;p&gt;A look into how BestBuy recovered from the retail attacks by Amazon and how their CEO was very effective during this phase and how he transformed the company.&lt;/p&gt;
&lt;h2&gt;Building a personal data warehouse in Snowflake for fun and no profit.&lt;/h2&gt;
&lt;p&gt;An article that goes through ingesting 30M HackerNews comments and using “SnowFlake” to analyze data to figure out when time to post a link etc.&lt;/p&gt;
&lt;h2&gt;Parler’s epic fail: A crash course on running your own servers with a shoestring budget&lt;/h2&gt;
&lt;p&gt;This post goes into how to host your homelab in a co-location space. The author takes you from procurement of used hardware to wiring it up in the datacenter.&lt;/p&gt;
&lt;h2&gt;Seeking the productive life: Some details of my personal infrastructure&lt;/h2&gt;
&lt;p&gt;A long article on Stephan Wolfram’s blog about how he manages his personal and work data and what he uses to accomplish this.&lt;/p&gt;
&lt;h2&gt;The personal analytics of my Life&lt;/h2&gt;
&lt;p&gt;Another article on Stephen Wolfram’s blog that details the analytics he has stored and the insights he has extracted from all the data he has collected over the years. It’s an interesting read but he doesn’t really mention any actionable items or how he used this data to make interesting changes/decisions.&lt;/p&gt;
</content:encoded></item><item><title>Checkmate heat map</title><description>A look at the distribution of the squares that a checkmate occured</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Sat, 20 Feb 2021 00:00:00 GMT</pubDate><guid isPermaLink="true">checkmate_square_distribution.html</guid><content:encoded>&lt;p&gt;This is a small experiment on a visualization of the squares that had the most check mates delivered on. The dataset is from lichess and not filtered on rating. I guess that the most check mates would happen at the castled position at amateur level of play and the heat map confirms that.&lt;/p&gt;
&lt;p&gt;First off we need to do some pre-processing for our PGN files. This is not strictly necessary as you can use the excellent python-chess module to parse them but it's a lot faster if we turn it into a pattern matching problem rather that parsing the the whole game. We will use the &lt;code&gt;pgn-extract&lt;/code&gt; utility for this processing step:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;!pgn-extract --dropply -1 -V -C -N -F --notags --nomovenumbers -s --linelength 10000 -M lichess_db_standard_rated_2016-09.pgn &amp;gt; matefen
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The idea here is to goto the final position of the game &lt;code&gt;--dropply -1&lt;/code&gt;, suppress unnecessary output &lt;code&gt;--notags --nomovenumbers -V -C -N -s&lt;/code&gt;, output a FEN string &lt;code&gt;-F&lt;/code&gt;, make sure everything is on one line (for easier processing) &lt;code&gt;--linelength 10000&lt;/code&gt; and only export games that ended in a checkmate &lt;code&gt;-M&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Depending on your machine and the number of games you are processing this command could take a while. After it's complete you should have a file like this&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;dendiz@minipc-GN41:~/tmp$ head matefen
Qa7# { &amp;quot;8/q7/8/8/8/8/K1k5/8 w - - 16 69&amp;quot; } 0-1

Qdd1# { &amp;quot;1k6/8/pp6/8/P2p4/8/2q5/3q2K1 w - - 4 52&amp;quot; } 0-1

Rd8# { &amp;quot;3r3K/4q2p/6pk/5p2/8/8/8/8 w - - 15 70&amp;quot; } 0-1

Qxg7# { &amp;quot;rn3rk1/1p3pQp/p2q4/2pPp3/4N3/7P/PP1K4/R5R1 b - - 0 25&amp;quot; } 1-0

Qxc1# { &amp;quot;1kr5/1p4b1/p2p2b1/3Pp1N1/4P3/1P1B1P2/P6Q/1Kq5 w - - 0 33&amp;quot; } 0-1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The next step is to get rid of the extra bits.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cat matefen | cut -d'{' -f2| cut -d'}' -f1 | tr -d '&amp;quot;' |cut -d' ' -f2,3 | grep &amp;quot;\S&amp;quot; &amp;gt; slim-mate.fen
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;What happens here if that we cut between the &lt;code&gt;{}&lt;/code&gt; to get the FEN, then remove the &lt;code&gt;&amp;quot;&lt;/code&gt;, then split again on a space and get the second and third columns. Then we get rid of the extra empty lines (You could also chain all of these commands together if you wanted).&lt;/p&gt;
&lt;p&gt;After this step the file we have is&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;dendiz@minipc-GN41:~/app/jupyterhub/notebooks/Blog/files$ head slim-mate.fen
8/q7/8/8/8/8/K1k5/8 w
1k6/8/pp6/8/P2p4/8/2q5/3q2K1 w
3r3K/4q2p/6pk/5p2/8/8/8/8 w
rn3rk1/1p3pQp/p2q4/2pPp3/4N3/7P/PP1K4/R5R1 b
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This contains all the information we need (the side being checkmated and the state of the board) to start building a histogram of the squares the kings were checkmated.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import chess.pgn
import chess
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
import math
with open(&amp;quot;slim-mate.fen&amp;quot;,&amp;quot;r&amp;quot;) as infile:
    cols = list(&amp;quot;abcdefgh&amp;quot;)
    crows = list(&amp;quot;87654321&amp;quot;)
    histo = [0] * 64

    lines = infile.read().splitlines()
    for line in lines[:1000000]:
        king = &amp;quot;K&amp;quot; if line[-1] == &amp;quot;w&amp;quot; else &amp;quot;k&amp;quot;
        ## line is
        ## 1k6/8/pp6/8/P2p4/8/2q5/3q2K1 w
        fen = line[:-2]
        rows = fen.split(&amp;quot;/&amp;quot;)
        for idx, row in enumerate(rows):
            if king in row:
                col = 0
                for c in row:
                    if c.isnumeric():
                        col += int(c)
                    elif c == king:
                        hist_idx = 8 * idx + col
                        histo[hist_idx] += 1
                    else:
                        col += 1


## normalize the values for the heat map
maxl = max(histo)
histo = [x/maxl for x in histo]
histo = [math.floor(100*x)/100 for x in histo]

## create 8x8 matrix from the flat list
b = [histo[n:n+8] for n in range(0, len(histo), 8)]
b.reverse()
b = np.array(b)

fig, ax = plt.subplots()
ax.set_xticks(np.arange(8))
ax.set_yticks(np.arange(8))
ax.set_xticklabels(cols)
ax.set_yticklabels(crows)
im = ax.imshow(b)
for i in range(8):
    for j in range(8):
        text = ax.text(j, i, b[i, j],
                       ha=&amp;quot;center&amp;quot;, va=&amp;quot;center&amp;quot;, color=&amp;quot;w&amp;quot;)
fig.tight_layout()
plt.show()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a href="/img/eaa68c29b4e5a31141fe56b70deb818a.png"&gt;/img/eaa68c29b4e5a31141fe56b70deb818a.png&lt;/a&gt;&lt;/p&gt;
</content:encoded></item><item><title>Jupyter notebooks as a todo list manager</title><description>My journey in Jupyterizing my life continues with moving todo lists to Jupyter</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Sat, 20 Feb 2021 00:00:00 GMT</pubDate><guid isPermaLink="true">jupyter_as_todo_list.html</guid><content:encoded>&lt;p&gt;I have been working on moving all of my digital notes and blog to Jupyter and I'm really liking the flexible environment it is providing for me. I have completed the move of all my writings on my blog to Jupyter and wrote a publishing scripting (again in a Jupyter notebook) that even has a client side search engine.&lt;/p&gt;
&lt;p&gt;The next thing to do (pun intended) was to move my to-do lists to Jupyter. For this I thought that I would have a single notebook (called very imaginatively &lt;code&gt;todo.ipynb&lt;/code&gt;) and that every cell in the note book would represent something that I wanted to do. This is OK until you want to check off an item. I thought I'd just delete the completed items but I don't like throwing away things I spent time writing so I wanted a way to mark them as complete, then eventually move to an archive so they don't clutter the main notebook. The best way I could think of this was to add &lt;code&gt;todo&lt;/code&gt; tag to the item. If the items is pending it has the &lt;code&gt;todo&lt;/code&gt; tag if it's not then it's done. I might actually convert this to be the other way around where if the item does not have a tag it's a &lt;code&gt;todo&lt;/code&gt; and then add a &lt;code&gt;done&lt;/code&gt; tag when it's done. The reason for this is that it's easy to forget to add the tag when you add a new item.&lt;/p&gt;
&lt;p&gt;&lt;a href="attachment:todolist-fs8.png"&gt;todolist-fs8.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This tagging method makes it kind of OK to work with items but there is still a lot of clutter because completed items are intertwined with pending items. I was using the down and up arrow to move the cells but that's a lot of clicking when you have a lot of to-do items and there is no &amp;quot;send to bottom&amp;quot; button. So I wrote a small script that does this for me. It traverses the notebook and moves cells with no &lt;code&gt;todo&lt;/code&gt; tag to the end of the list, adds a &lt;code&gt;done&lt;/code&gt; tag (which is used by the archiving script) and also adds a green text to indicate that it's done. Guess what that text reads? Yes, &amp;quot;done&amp;quot;.&lt;/p&gt;
&lt;p&gt;The script can the triggered from a python cell in the to-do notebook which is convenient but requires a reload because it modifies the notebook.&lt;/p&gt;
&lt;p&gt;I also have a script that I added as a scheduled job that moves the completed items in the to-do notebook to an archive notebook once a week to reduce clutter. The archive notebooks are per month.&lt;/p&gt;
&lt;p&gt;It's not always easy to add an item to your list when you are not in front of a computer or not at home (I don't open my homelab to the outside world) so I added another script that monitors an email  account and creates to-do items from the email.&lt;/p&gt;
</content:encoded></item><item><title>Book review: On Basilisk station</title><description>A review of my first book in the Honorverse</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Wed, 17 Feb 2021 00:00:00 GMT</pubDate><guid isPermaLink="true">on_basilisk_station_review.html</guid><content:encoded>&lt;p&gt;I've been looking into reading more fiction books and what better place to start than sci-fi. I actually came across this series when I was browsing the Aurora 4x game forums trying to get an idea behind what inspired Steve Whimsley to create the game. Anyways the Honor Harrington books were recommended reading so and since the first book in the series was free for the Kindle I got it. It's a long book with 32 chapters and 422 pages but the it's very easy reading. The language is simple and the chapters flow. It took me about 6 weeks to finish the book as I tried to read a chapter every evening. The characters and the relations between the characters are described in detail and the reader can empathize and understand them. There aren't too many characters so things don't get complicated. One thing I would have liked to see would have been more epic ship to ship battles and more introduction into the physics and technology of the era. I had to refer to a wiki to get an understanding of what they were talking about.&lt;/p&gt;
&lt;p&gt;All in all I enjoyed reading the book and will continue with the rest of the series.&lt;/p&gt;
</content:encoded></item><item><title>Brooks Ghost 13 running shoes review</title><description>A review after 75 miles with these shoes</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Wed, 17 Feb 2021 00:00:00 GMT</pubDate><guid isPermaLink="true">brooks_ghost13_review.html</guid><content:encoded>&lt;p&gt;After injuring my knee because I was running with the New Balance 990v4 shoes that were worn out, I decided to get a new pair. After hours and hours of research on Amazon reading countless reviews and reading running sites and best running shoe articles, I was left with 2 options.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Asics Gel Kayano 27&lt;/li&gt;
&lt;li&gt;Ghost Brooks 13&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Both had stellar reviews and it basically came down to the price and I went with the Ghost 13.&lt;/p&gt;
&lt;p&gt;The first thing I thought when I put these on for the first time was &amp;quot;Wow, that is soft&amp;quot;. The cushioning is sublime, just what I was looking for with my injured knee. But the cushioning came with a trade-off: stability. It felt like my foot was &amp;quot;wobbling&amp;quot; and I could feel the slightest incline (left/right) on the sidewalk. I got used to this feeling after a couple of miles in the shoes and they feel pretty comfortable. The overall fit is also pretty snug and my foot doesn't move around in the shoe. After about 75 miles there is minimal ware and tear on the sole even though I do mixed road and trail jogging.&lt;/p&gt;
&lt;p&gt;Here are some images:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="/img/brooks-side.png"&gt;side-opt.png&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="/img/brooks-top.png"&gt;top-opt.png&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content:encoded></item><item><title>Client side search engine</title><description>The internals of the mini search engine that powers the search feature on this static blog</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Mon, 15 Feb 2021 00:00:00 GMT</pubDate><guid isPermaLink="true">client_side_search.html</guid><content:encoded>&lt;p&gt;Searching statically generating sites can be a bit unusual. You don't have a server side component that will execute the search so you either need to have an external search engine index your site or you need to have the client perform the search on an index that you provide for download. Having an external search engine index needs your site to provide the HTML for crawler requests and web application don't usually work well with this. You should probably have a fully rendered version of your site for SEO purposes but I'm not about SEO. So I went ahead and wrote a mini search engine for this purpose.&lt;/p&gt;
&lt;p&gt;So when exporting the content from the source (it could be a markdown source etc.) the script also needs to generate the search index. The most basic structure for this index could a JSON file that contains the document URL mapped to it's content.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docs = {
    &amp;quot;file1.html&amp;quot;: &amp;quot;this is some document with text. Crime never pays.&amp;quot;,
    &amp;quot;file2.html&amp;quot;: &amp;quot;this is another document. If crime paid things would be different.&amp;quot;
}
docs
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;{'file1.html': 'this is some document with text. Crime never pays.',
 'file2.html': 'this is another document. If crime paid things would be different.'}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Just this would be enough to whip up a Javascript grep engine. But just grepping isn't a great search experience. You need to enhance the search engine with some language understanding to get better results. So for example in our 2 documents a search for &amp;quot;pays&amp;quot; would only result in document 1 if we were grepping. But document 2 actually also contains relevant information. The best way to capture this type of language understanding is to add lemmatization to the index.&lt;/p&gt;
&lt;p&gt;First step in this process is to tokenize the input. I'm using the python &lt;code&gt;nltk&lt;/code&gt; package for all the NLP stuff.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from nltk.stem.wordnet import WordNetLemmatizer

lem = WordNetLemmatizer()
stop_words = set(stopwords.words(&amp;quot;english&amp;quot;))
words = []
for k, v in docs.items():
    words += word_tokenize(v)
words
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;['this',
 'is',
 'some',
 'document',
 'with',
 'text',
 '.',
 'Crime',
 'never',
 'pays',
 '.',
 'this',
 'is',
 'another',
 'document',
 '.',
 'If',
 'crime',
 'paid',
 'things',
 'would',
 'be',
 'different',
 '.']
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There are duplicates, stop words and mixed case words in the result list, so let's clean it up.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;words = [w.lower() for w in words if w not in stop_words]
words
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;['document',
 'text',
 '.',
 'crime',
 'never',
 'pays',
 '.',
 'another',
 'document',
 '.',
 'if',
 'crime',
 'paid',
 'things',
 'would',
 'different',
 '.']
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That's better. Now we'll need a map to store the root (lemma) of the word and it's versions that were present in the text. On the client side we'll use this map to enhance our search.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;lemma_map = {}
for w in words:
    if w in lemma_map: continue
    lemmas = list(set([lem.lemmatize(w, mode) for mode in list(&amp;quot;avsn&amp;quot;)]))
    if w in lemmas:
        lemmas.remove(w)
    if len(lemmas) == 1 and lemmas[0] == w: continue
    for lemma in lemmas:
        if lemma not in lemma_map:
            lemma_map[lemma] = []
        if w not in lemma_map[lemma]:
            lemma_map[lemma].append(w)
lemma_map
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;{'pay': ['pays', 'paid'], 'thing': ['things']}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we have the ability to enhance our search on the client side to include both &amp;quot;pays&amp;quot; and &amp;quot;paid&amp;quot; for the query. How is that going to work? We are going to lemmatize the input query. So if the user were to search for &amp;quot;paying&amp;quot; the root would be &amp;quot;pay&amp;quot; and we would search for &amp;quot;paid&amp;quot;, &amp;quot;pay&amp;quot;, &amp;quot;paying&amp;quot;, &amp;quot;pays&amp;quot;. Why not just lemmatize the whole body and just send that as the index file to the client? Well we want to highlight and show a snippet of the document to the user for the search results and we can't show that from the lemmatized version of the document body, so the original document needs to be in the client. There is a trade-off between the index size and the amount of processing the client has to do and the time it takes for the results to render. In my experiments I tried pushing the lemmatization process on the client using the same WordNet lemmatizer for JavaScript and the results were pretty bad. On a i9 Macbook Pro it took around 5 seconds to render the page (this doesn't not include the network time spent downloading the index).&lt;/p&gt;
&lt;p&gt;On the client we lemmatize the search query and add the results to a list of extended search terms. Then for each of these terms we look up more terms from the &lt;code&gt;lemma_map&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;search_term = &amp;quot;paying&amp;quot;
extended_terms = list(set([lem.lemmatize(search_term, mode) for mode in list(&amp;quot;avsn&amp;quot;)]))
for w in extended_terms:
    if w in lemma_map:
        extended_terms += lemma_map[w]
extended_terms
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;['pay', 'paying', 'pays', 'paid']
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;What's left is now to search through the contents of the documents for each of these terms.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;for file, body in docs.items():
    for t in extended_terms:
        if t in body.lower():
            print(&amp;quot;found &amp;quot;, file, &amp;quot;for term&amp;quot;,t)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;found  file1.html for term pay
found  file1.html for term pays
found  file2.html for term paid

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There is some duplicate detection and search term highlighting that's also done on the client but it's not integral to the way the search index is built, so I won't be going into those details.&lt;/p&gt;
</content:encoded></item><item><title>Blogging with jupyter notebooks</title><description>How I use jupyter notebooks to run this blog</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Sat, 13 Feb 2021 00:00:00 GMT</pubDate><guid isPermaLink="true">jupyter-notebook-blogging.html</guid><content:encoded>&lt;p&gt;After I read Stephen Wolfram's very nerdy blog post about his productivity tools I was very intrigued by the idea that he was using Wolfram notebooks for almost everything he was producing. From documentation for his business to blog posts. The reason I find this a really cool idea is that you can include runnable in a post with it's output formatted as data frames or a mathplotlib graph. Jupyter is pretty flexible in the way it will allow you to produce output so you can go pretty wild like rendering your own SVG's etc.&lt;/p&gt;
&lt;h3&gt;Migration from hugo&lt;/h3&gt;
&lt;p&gt;I had been using hugo for a while now and everything I wrote was in markdown and Jupyter has built-in support for markdown. The only thing I needed to do was write a small python script that would embed the markdown files from hugo into jupyter notebooks (which are JSON and easy to understand). The only tricky part here was that hugo uses front matter to keep the metadata for posts while jupyter doesn't have such a feature. I ended up with creating a raw cell that holds this metadata and the second cell is the markdown cell that has the content.&lt;/p&gt;
&lt;h3&gt;Notebook to HTML&lt;/h3&gt;
&lt;p&gt;I had a couple of different options for generating the HTML from notebooks.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Use the built-in HTML generation.&lt;/li&gt;
&lt;li&gt;Get the markdown and export it to hugo or another markdown parser for the HTML&lt;/li&gt;
&lt;li&gt;Use a different notebook viewer&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The built-in HTML generation is the easiest and most straight forward option but the resulting HTML was huge. A notebook with no image attachments was around 575Kb. I took a look at the templating system to see if I could optimize it but there was a lot of css compiled into the page and it looked pretty complicated so I didn't want to invest too much time into exploring this.&lt;/p&gt;
&lt;p&gt;The markdown export was also a good idea but the main issue with this approach was processing the attachments. I tried a tool called &lt;code&gt;nbdev&lt;/code&gt; which exports all the attachments to files but the links in the markdown document were not converted to the proper URL. It could be working for inline image generated by code cells but it will not work for attached images.&lt;/p&gt;
&lt;p&gt;I also considered writing a script to extract the attachments and update the markdown links myself but that's also a lot of work and I would also have manage all the different cell types etc.&lt;/p&gt;
&lt;p&gt;Then I explored the route of in-browser rendering. And not surprisingly there is a project called &lt;code&gt;notebook.js&lt;/code&gt; which renders the notebook given the &lt;code&gt;ipynb&lt;/code&gt; source. I ended up choosing this project and embedding the source file into the HTML.&lt;/p&gt;
&lt;h3&gt;Index page generation&lt;/h3&gt;
&lt;p&gt;There is no &amp;quot;index page&amp;quot; in the world of jupyter notebooks. You get a file explorer like interface and you choose your notebook. I needed something that displays the title, description and tags of the articles in a list. So I put together a script that traverses the notebooks and extracts the metadata from the first cell to create the index page.&lt;/p&gt;
&lt;h3&gt;Tag pages and menu&lt;/h3&gt;
&lt;p&gt;One of the great features of the hugo theme I was using before was the tag pages. But I couldn't be bothered to modify the theme to support a navigation bar with the tags. So I implemented both these features in the script I wrote for the notebook extractor.&lt;/p&gt;
&lt;h3&gt;Microblog imap&lt;/h3&gt;
&lt;p&gt;I recently shutdown my mastodon server because I could not justify paying 50$ for a server each month. But I don't like to post the occasional micro update and using a notebook for a short update is not practical. So I created a script that will monitor my email account for a certain email format and use it to create a new notebook with the content and publish it to the micro section on my website.&lt;/p&gt;
&lt;h3&gt;Search&lt;/h3&gt;
&lt;p&gt;Search is always complicated with static sites. When there is no server side code to power the search it stops making sense to create a reverse lookup index. So the method I came up with is to create the a mapping of the source for the posts to the file names and store that as JSON data to be processed by the client. So when you go to the search page you are basically downloading the entire text content of the posts in a single huge JSON along with the lemmatizations of the tokens in the body. Something like this&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-json"&gt;
{
...
&amp;quot;implement&amp;quot;: [&amp;quot;implemented&amp;quot;, &amp;quot;implements&amp;quot;, &amp;quot;implementing&amp;quot;], 
&amp;quot;pay&amp;quot;: [&amp;quot;paying&amp;quot;, &amp;quot;pays&amp;quot;, &amp;quot;paid&amp;quot;]
...
}

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then lemmatizing the input query to get the extended versions of the term and running a search for all these terms seems to yield good results and is fast enough. E.g if you were to search for &amp;quot;paid&amp;quot; the process would get the stem as &amp;quot;pay&amp;quot; then augment the search to include &amp;quot;paying&amp;quot;, &amp;quot;pays&amp;quot;, &amp;quot;paid&amp;quot; and return all the docs that contain these words too.&lt;/p&gt;
&lt;p&gt;The ordering of the search results is something that needs more work but the there aren't that many documents to it's not that big of a deal.&lt;/p&gt;
&lt;p&gt;Having a powerful environment that can evaluate and execute code will be great for technical writing!&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;for i in range(3):
    print(&amp;quot;More power!&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;More power!
More power!
More power!

&lt;/code&gt;&lt;/pre&gt;
</content:encoded></item><item><title>All-free non-alcoholic beer</title><description>A beer substitute for people who watch calories</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Sun, 31 Jan 2021 00:00:00 GMT</pubDate><guid isPermaLink="true">allfree_beer-2021-01-31.html</guid><content:encoded>&lt;p&gt;Lately I have been watching my calorie intake to lose some weight and improve my health in general. 
When you are constrainted in this way and you can't cut the bad stuff cold-turkey you start looking
for healthier/low calorie substitutes. I had actually substituted coke zero for regular soda years ago
but there are downsides to sweeteners too so this year I decided to ditch the sweetened drinks too. La Croix
was a great option so I stuck with it for sometime. Even though it has a variety of different flavors to 
choose from it doesn't provide a deep/bold flavor. It's more like someone is cutting a piece of the fruit 
in the kitchen and you can smell it in your drink. This made me look for other alternatives for fizzy drinks
with more body to them and I came across this product &amp;quot;All free&amp;quot; on Amazon.&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/allfree1.jpeg"&gt;1&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This is a zero calorie, zero sweetener, low sodium drink. It's not your average non-alcoholic beer with 60 calories.
The reviews were mixed but it had a decent rating of ~4 stars, so I ordered a 6 pack.&lt;/p&gt;
&lt;p&gt;Visually I think it looks exactly like beer (even though I usually drink it straight from the can)&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/allfree2.jpeg"&gt;2&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The taste resembles lager beer quite a bit. The initial effect on the palate and the fizziness is definitely on par
with regular beer but the after taste is where you can that it's a substitute. I'm not really a beer snob but the 
best way I can describe it is that it lacks the body and affect that a true beer would leave on the palate. 
But for zero calories, I don't really care. I think it's a great drink and I'll keep buying it.&lt;/p&gt;
</content:encoded></item><item><title>Consumption 01/2021</title><description>What I consumed in 01/2021</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Sun, 31 Jan 2021 00:00:00 GMT</pubDate><guid isPermaLink="true">consumption-01-21.html</guid><content:encoded>&lt;h2&gt;Investing legend James Simon's record won't be beat&lt;/h2&gt;
&lt;p&gt;A nice article on how Renaissance technologies beat the market and the strategies they used to keep
the competitive advantage. It's interesting to know that they didn't allow investors to keep all their
money in the fund and had a forced profit distribution and thus keeping the money managed at the fund
at a certain level.&lt;/p&gt;
&lt;h2&gt;That XOR trick&lt;/h2&gt;
&lt;p&gt;A fun piece about how using XOR can accomplish little tricks such as in-place substitution
and figuring about the missing number or two in a list of sequential numbers.&lt;/p&gt;
&lt;h2&gt;Your legacy database is outgrowing itself&lt;/h2&gt;
&lt;p&gt;An insight into how chess.com restructured their database and application to accommodate for the
growth caused by people stuck at home in quarantine.&lt;/p&gt;
&lt;h2&gt;Time of use, time of check (TOUTOC)&lt;/h2&gt;
&lt;p&gt;An article in wikipedia that explains how race conditions can occur when code is checking for say
permission to a file and then based on the return code of a system call accessing that file. It turns
out that this problem is not at all trivial and easy to solve.&lt;/p&gt;
&lt;h2&gt;Against essential and accidental complexity&lt;/h2&gt;
&lt;p&gt;A reponse to Brooks claim in the 60's that tooling isn't going to make developers more productive.&lt;/p&gt;
&lt;h2&gt;How and why I stopped buying laptops&lt;/h2&gt;
&lt;p&gt;A look at why the old ThinkPads were the best machines around. I can resonate with this claim even though
I don't use one anymore.&lt;/p&gt;
&lt;h2&gt;How to stop endless discussion&lt;/h2&gt;
&lt;p&gt;An idea that writing documents (RFCs) stops the endless meetings with ambigious outcomes and forces the people
who are proposing the idea to be clear, concise and accountable for the idea.&lt;/p&gt;
&lt;h2&gt;My year in data&lt;/h2&gt;
&lt;p&gt;A wacko experiment of a data scientist who logged their life in 15 minute intervals. They came up with a couple
of different categories for their activities during the day and put then in an excel sheet. After a year they
drew some conclusions (like how does my leisure time vary over months, how much do I work, etc)&lt;/p&gt;
</content:encoded></item><item><title>Tracking hydration (for free)</title><description>Stitching some iOS apps to track water intake and be reminded to do so, for free</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Sat, 23 Jan 2021 00:00:00 GMT</pubDate><guid isPermaLink="true">free_hydration.html</guid><content:encoded>&lt;p&gt;Lately I've been into calorie counting and water consumption tracking. I'm using the MyNetDiary app for the calorie tracking but I hadn't been able to find a free app that's good for water tracking. I tried the app DrinkWaterReminder which has a weird UI and takes some time to understand how to use such a simple app. I also hate that it constantly nags you to upgrade and displays add (both in-app and fullscreen).&lt;/p&gt;
&lt;p&gt;Instead of using a crappy app to track water, I wanted to use the built-in health app but it's not practical to launch the app, find the water component, press add data, input data and save. That's a lot of steps. This is where the ShortCuts app comes in very handy. I found a shortcut called &amp;quot;Log water&amp;quot; (or found it in the gallery, I don't recall exactly as I had been playing around with this a long time ago) and modified it to show the sizes of the glasses I use the most. Then I added the short cut to my home screen, and that's it. I still use the app I mentioned to get the push notifications to remind me to drink, but at least I'm not seeing any ads. I could replace this with a push notification app (like PushOver) and a cron that's sends the notification but no need for that now.&lt;/p&gt;
</content:encoded></item><item><title>Book review: Procedural generation in game design</title><description>A look at the world of procedural generation</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Wed, 13 Jan 2021 00:00:00 GMT</pubDate><guid isPermaLink="true">procedural_generation_in_game_design.html</guid><content:encoded>&lt;p&gt;I’ve been looking into rogue like games and the generation of levels done 
using procedural generation is something that I found to be interesting. 
A book on the subject edited by the creator of dwarf fortress look like a 
good read so I got it from Amazon on May 28, 2020 for 50$ as a hard copy. 
The book is a compilation of articles ranging from some what procedural 
generation is and isn’t to the ethics in the output of the generated content.
It’s an interesting read though nothing that is too enlightening.&lt;/p&gt;
&lt;p&gt;There is only one chapter that provides some pseudo-code about the idea but the
rest of the chapters are more around discussions and ideas in PCG. So if you are
looking for implementations of PCG techniques look else where.&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/procedural_generation_in_game_design.png"&gt;/img/procedural_generation_in_game_design.png&lt;/a&gt;&lt;/p&gt;
</content:encoded></item><item><title>Book review: Rocket science for traders</title><description>Can DSP be the silver bullet for trading systems?</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Wed, 13 Jan 2021 00:00:00 GMT</pubDate><guid isPermaLink="true">rocket_science_for_traders.html</guid><content:encoded>&lt;p&gt;This book takes an interesting approach to technical analysis in that it treats 
the price data as time series data and tries to apply digital signal processing 
techniques to reduce the noise. It’s of course not a silver bullet and you won’t 
get rich by applying these but it gives good explanations on the logic and 
reasoning behind such filters (like moving averages etc).&lt;/p&gt;
&lt;p&gt;The maths behind required to understand what's going on is pretty advanced
(Fourier transforms, phase shifts, etc) so it's not super easy to following along
and the reasoning behind the applications is usually omitted or not explain in detail
or in laymans terms.&lt;/p&gt;
&lt;p&gt;The results of the systems presented in the book seem to the on the profitting side
but there is not indication that the testing system is based on simulating real
transactions with comissions, slippage, etc. Also the commodities chosen as examples
could very well be selected to match the system to yield good looking results. I'm
pretty sure the author is not faking any results but I would still need to independently
run and reproduce these results on his data set and other sets to begin trusting and 
invest time in tuning the given systems.&lt;/p&gt;
&lt;p&gt;Overall I think it's an interesting book and the author is taking a fresh approach 
on applying DSP techniques to a different type of signal.&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/rocket_science_for_traders.png"&gt;/img/rocket_science_for_traders.png&lt;/a&gt;&lt;/p&gt;
</content:encoded></item><item><title>Book review: Game coding complete</title><description>A short review on the game engine development book.</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Wed, 13 Jan 2021 00:00:00 GMT</pubDate><guid isPermaLink="true">game_coding_complete.html</guid><content:encoded>&lt;p&gt;This book is aimed at taking a deeper dive into the neglected parts of game 
engine developerment such as asset loading management, event handling, caching 
and an architecturally sounds design. It does go throught the topics of 
rendering, scene graphs and the linear algebra behind 3D programming too but 
not at a great level of detail such as books that explain OpenGL. The APIs 
used in the book are DirectX and C++ and all the code examples are in that 
language. The book isn't using very advanced features of C++ and it is easy 
to follow along the example even if you don't know C++ (like I don't). 
I would say it's a good book that touches a broad set of topics regarding game
engine development but doesn't go into discussions on various implementations 
or details in those topics. Overall I would recommend it to anyone who is 
interested in game engine programming.&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/game_coding_complete.png"&gt;/img/game_coding_complete.png&lt;/a&gt;&lt;/p&gt;
</content:encoded></item><item><title>Uses this 2020</title><description>The hardware and software I used in 2020</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Sat, 19 Dec 2020 00:00:00 GMT</pubDate><guid isPermaLink="true">2020-uses-this.html</guid><content:encoded>&lt;h3&gt;Hardware&lt;/h3&gt;
&lt;p&gt;This year has seen some changes in the way I do my computing. I'm bound by my day job to a certain manufacturer and their software, which is not something I'm complaining about but given the choice I would probably use a Thinkpad and Linux just because I prefer the tiling window manager paradigm. This year I've been mainly using my iMac pro with 2 external monitors for a total of 3. I think this setup is great because I always have a ton of windows open at any given time and I usually need to see some bit of information in one to make progress in the other. During the first half of the year I was using a single 4k monitor with a Macbook Pro but I found that to be less efficient.&lt;/p&gt;
&lt;p&gt;I'm one of those lucky few that didn't run into any issues with the butterfly keyboards on the Mac. I think it's a pretty sweet keyboard and used it exclusively for the first half of this year. But after I switched to the iMac it was back to the good old mechanicals. The craziest thing I did this year was to get a 60% Royal Kludge keyboard. It has cherry browns -- my favorite. The user manual that came with it was pretty bad so I had a hard time understanding how to configure it properly and replaced it with something else after a while. Later this year I gave it another chance and did some experimentation to understand how the modes are supposed to work and eventually came up with a configuration I liked. It's a nice board once you get used to the missing arrow keys (macOS really helps there with the universal emacs keybindings) but it becomes difficult to use other boards once you adjust. This was reason enough for me to stop using it as I can't spend brain cycles on remembering what keyboard I'm typing with right now.&lt;/p&gt;
&lt;p&gt;I've been using the same cheap-o mouse since 2019 which is still working after a year, a nice surprise. These white label electronics usually crap out after a while. I'm not really playing 1|0 bullet anymore so the mice get to survive longer I guess.&lt;/p&gt;
&lt;h3&gt;Software&lt;/h3&gt;
&lt;p&gt;The majority of my time is spent in Xcode, Safari and the terminal. I use an almost vanilla bash config with git auto completion stuff that I added manually. I stated using emacs a lot more this year but haven't completely switched over from vim. The best app I've purchased this year is GoodNotes. The pencil support is so much better than Apple notes app. I started importing my PDFs into GoodNotes to use the pencil to annotate stuff. I was using Apple notes to keep my journal and notes but I decided to find a better replacement for it. The idea behind roam and the zettel kasten method lead me to org-roam. I've known for a while the power of org was legendary but never gave a serious try as it looked more like a todo list and schedule manager. But with org-roam it's very easy to take notes, link them and add images. I could not find a great way to have them sync over to my mobile devices but it's not that big of a deal. I can use a plain text editor with iCloud support to manually edit them if the needed arises. I had migrated all my journal entries to an intranet Wordpress instance but have decided to switch to org-roam's daily feature for journaling to reduce to the number of apps. I'm still in the progress of migrating them (there is a lot to migrate).&lt;/p&gt;
&lt;h3&gt;Servers&lt;/h3&gt;
&lt;p&gt;I've been running 2 VMs and a bare metal fan-less mini PC for some time now as my home servers. These boxes hosted various dockerized services but I have decided to shutdown the box hosting the VMs. This year around May or June my Mastodon instance basically ate my Comcast quota by federating all the media attachments etc from the 15 or so Reddit and Twitter relay bots that I had setup so I decided to move Mastodon to a VPS on a provider. I got a machine with 8 cores and 16GB for 45$/month and let Mastodon run on that. I setup up a Jenkins pipeline to backup this machine and it was all good until I decided that spending that much money so that I can rant wasn't something I could justify anymore after a couple of months. So I'm shutting mastodon down and basically stepping away from posting on social media. I wasn't posting anything on corporation owned sites anyway and now that Mastodon is gone social media is going to be out of my life for good. The other services I was hosting on that machine were a bunch of TechScan related services, the local journal Wordpress and a drawio instance. I'm migrating my journals to org-roam, drawio can be replaced by Omnigraffle or GoodNotes + Apple pencil. I was also using Miniflux to read RSS but have now moved to Feedly which doesn't show me any obtrusive ads and I still get all my feeds from any device. I think that technical analysis is a sham so no need for TechScan. There's basically nothing left for the machine to host so I'm retiring it. The mini PC will still live in the new 16U server rack that I got next to my Synology NAS and TP-Link switch hosting my Gitlab instance (which is the only service that I really need at the moment).&lt;/p&gt;
&lt;h3&gt;What's next&lt;/h3&gt;
&lt;p&gt;I plan on moving to a more client focused setup that still allows for synchronization over the cloud, and want to step away from using cloud apps that have access to all your data. I'm tired of the amount of maintenance that goes into hosting your own services especially from home with a wonky internet (thanks Comcast). During these quarantine times that may not seem like an issue but I don't want to get dependent on some service that I later need to carry to a VPS in a data center and pay 45$/month for it ;)&lt;/p&gt;
</content:encoded></item><item><title>What happened in 2020</title><description>A look back at the most interesting events of 2020 in my life</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Sat, 19 Dec 2020 00:00:00 GMT</pubDate><guid isPermaLink="true">2020-summary.html</guid><content:encoded>&lt;h3&gt;Good old days&lt;/h3&gt;
&lt;p&gt;Let's take a trip down memory lane for a year that was like no other:&lt;/p&gt;
&lt;p&gt;January was the last time we had date night. I cannot believe almost a whole year has gone by without us getting to dine at a nice restaurant. I'm a typical stay-at-home introvert but this is hard to believe even for me.&lt;/p&gt;
&lt;h3&gt;Looting&lt;/h3&gt;
&lt;p&gt;Then struck the whole COVID madness. Scenes like this&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/loots.jpg"&gt;/img/loots.jpg&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;became the norm throughout the country. Luckily for us we never got in a dire situation because of the hoarding that people were doing. It's crazy that people act the way that they do when they are panicking but I think the intervention from the authorities (e.g super markets) came too late. They should have started limiting purchases of certain items a lot sooner. Not strictly limiting, e.g keeping track but discouraging people from buying more than they need. I think Costco made a great move by saying they are not going to accept returns for toilet papers.&lt;/p&gt;
&lt;h3&gt;Day care issues&lt;/h3&gt;
&lt;p&gt;The impact of COVID is felt by all and I think we were extremely lucky to not contract a virus and were minimally affected by the changes caused by the virus. The most significant changes in our lives were that we started working from home and that our daughter had to start at a different day care. Ironically the new day care she started was the day care that we had considered and decided against last year. The main reasons we decided against it was that it was farther away from where we lived, they didn't provide diapers and my wife thought it was an inconvenience she wasn't willing to put up with and it was 30% more expensive. Well after COVID hit our original day care (which is sister schools with this day care) said that attendance was not enough to justify keeping the school open and that their corporate HQ decided to merge schools in the region. Unfortunately we can't afford not to send our kid to school because we both work and it's just impossible to have her around the house and get any work done. I really do feel for the families that are in this situation due to school shutdowns and wish them all the strength in the world so that they can maintain their sanity. Anyways this change in day care turned out to be a good change. The new place had a much better program with more engagement and more STEM oriented curriculum (yes day cares have  a curriculum). The updates and reports that the teachers were providing via the app were very detailed and she has learned so much after she started here. After some time the old day care announced through the app that they were reopening but we decided to keep her at the new care permanently.&lt;/p&gt;
&lt;h3&gt;A forgotten drink&lt;/h3&gt;
&lt;p&gt;I made my first &amp;quot;Churchill&amp;quot; drink since moving to the US.&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/curcil.jpg"&gt;/img/curcil.jpg&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This is a simple cocktail made from mineral water, lemon juice and salt. The reason this is important is that the mineral water I got from a Middle Eastern market sat there in the fridge for months and months before I actually remembered to make this drink (which I actually like quite a lot) and became a symbol of my procastination.&lt;/p&gt;
&lt;h3&gt;A new house&lt;/h3&gt;
&lt;p&gt;I guess the biggest change for this year is that we bought a house. Buying a house in Seattle, WA is a very long and tedious process. We actually started our search in fall 2019 but actually managed to buy a house in June 2020.&lt;/p&gt;
&lt;p&gt;The house is in a great neighborhood ideal for a toddler. We even have a play set in the back yard so I guess she's a lucky kiddo.&lt;/p&gt;
&lt;p&gt;The house was built in the early 90s and the interior reflected that era with it's oak heavy cabinetry so a remodeling was needed. We decided to go with a small family business that our Realtor recommended and they did a pretty good job, albeit at an extra cost. I was very impressed with the work ethic that contractors have here. When they say they are going to be there at Xpm they are actually there at that time. I've seen all sorts of inexcusable behavior such as being hours late to not showing up at all in a previous life, so this was good experience.&lt;/p&gt;
&lt;p&gt;Moving is never fun. Moving from an apartment to a house was manageable but moving from a house to a new house was very very exhausting. It's incredible to amount of crap you accumulate through the years.&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/packing.jpeg"&gt;/img/packing.jpeg&lt;/a&gt;
&lt;em&gt;packing at the end of the first day. 3 more days of packing followed&lt;/em&gt;&lt;/p&gt;
&lt;h3&gt;A blind test&lt;/h3&gt;
&lt;p&gt;I have always come across people who claim that they can tell the difference between Coke Zero and Diet Coke. I personally think it's not possible as the difference is very subtle (if it even exists). One of these people was my wife. So I put her to the test. Here's the setup:
There are 5 glasses with coke in them. Find the ones that are Diet Coke. Pretty simple, 1/32 chance of guessing correctly which is good enough to rule that out. So we did the test. She scored 3 out of 5 and declared her self a winner. I guess it's my fault that I didn't explain before the test that she would have to do 100%. I mean, I can tell the difference between coke and water and I would score 100% every time I took such a test so it seemed pretty evident to me that only a full score would pass. But apparently she has a different idea.&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/coketest.jpeg"&gt;/img/coketest.jpeg&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Worst weeks&lt;/h3&gt;
&lt;p&gt;I think 2020 has been a year that is going to be memorable for the bad things that happened. The COVID situation is the most obvious one but it doesn't stop there for me. Our daughter dislocated (or broke can't be sure because it was a hidden fracture) her elbow this year. She had her arm in a cast for 2 weeks. This is not super critical but all this happened after 2 weeks of day care shutdown on the day it was opening back. Having her home all that time was very challenging to say the least. As if all this wasn't enough a cherry tree in the neighbors yard broke and fell on the play set in our yard. Luckily there were no injuries.&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/tree.jpeg"&gt;/img/tree.jpeg&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Best buy of 2020&lt;/h3&gt;
&lt;p&gt;I had to buy a lot of tools for the new house this year. I think the best piece I got this year is the Sun Joe pressure washer. It's very satisfying to see that grime being removed.&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/sunjoe.gif"&gt;/img/sunjoe.gif&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I did not get any electronics this year. There is simply nothing worth buying that will provide a trace of utility in my life. So the best buy has to go to my new server rack and the switch (the computers I already had.)&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/serverrack.jpeg"&gt;/img/serverrack.jpeg&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Another big purchase this year was a car. I was having back pain putting our kid into the car seat in the back everyday and we needed something with a larger cargo capacity to haul things for the back yard and the house from Home Depot so we got an 7 seater SUV.&lt;/p&gt;
&lt;h3&gt;Future&lt;/h3&gt;
&lt;p&gt;This was a weird and unusual year indeed and I think the old normal will not be the normal. Things in all aspects of life are going to change and adapt to the new findings caused by the events of 2020.&lt;/p&gt;
&lt;p&gt;Here's a piece of play-doh art that summarizes 2020&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/playdoh2020.jpeg"&gt;/img/playdoh2020.jpeg&lt;/a&gt;&lt;/p&gt;
</content:encoded></item><item><title>Consumption 12/2020</title><description>What I consumed in 12/2020</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Fri, 18 Dec 2020 00:00:00 GMT</pubDate><guid isPermaLink="true">consumption-2020-12.html</guid><content:encoded>&lt;p&gt;I've decided to write about the articles and other interesting media I have consumed each month.
This is the first post in that series and it covers the months of November and December 2020&lt;/p&gt;
&lt;h2&gt;3 takes aways from Quantopian shutting down&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;You can't crowd source alpha - The business models was to see if the masses could come up with a way to beat the markets&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;given the tools. Apparently they couldn't.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If depending on software make sure you pay for it - This is a take from the other perspective, traders that were using Quantopian to make trading decision now have to find another platform&lt;/li&gt;
&lt;li&gt;The trading software market favors smaller companies - The reasoning behind this is that there are different markets and each trader has a different strategy and needs. This makes the economics of producing trading/analysis software more beneficial for smaller companies.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Before Mac OSX: What was NeXTSTEP and why did people love it?&lt;/h2&gt;
&lt;p&gt;This article explains how NeXTSTEP stood out from the competition in the 90s with elegant usage of fonts, icons
and visuals and an easy to use object oriented programming API and networking stack. An interesting and fun fact is that the level editors for Quake were programmed for NeXTSTEP because of it's easy API.&lt;/p&gt;
&lt;h2&gt;Self limitation due to software simplification&lt;/h2&gt;
&lt;p&gt;PIM expert Karl Voit writes about how users are limiting themselves by not investing the time into learning the full
functions of the programs they use. There are 2 interesting references in this article&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Bruce Tognazzini talking about how his take on the two approaches of search vs browse and how Apple has tackled this&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;UX question&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Jeff Atwood has a blog post in how he thinks that it's only the mediocre users that matter as they will constitute the highest percentage of people using the program&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Dwarf Fortress creator Tarn Adams talks about simulating the most complex magic system ever&lt;/h2&gt;
&lt;p&gt;That's a long title for an article. Wes Fenlon interviews Tarn and he starts with his vision of a teleportation system and goes on to describe a magic system that evolves with the game progression&lt;/p&gt;
&lt;h2&gt;My talk at Microsoft - Richard Stallman&lt;/h2&gt;
&lt;p&gt;I was surprised that RMS would even set foot in a Microsoft campus but apparently he gave a talk to some MS folks. He made
a bunch of suggestions that promotes freedom of software (duh). He also defends him self against some allegations made by
others because of this talk.&lt;/p&gt;
&lt;h2&gt;How I collected debt from an unscrupulous merchant&lt;/h2&gt;
&lt;p&gt;The author shares his story of how a policy with hidden fine print prevented him from collecting his cut from referrals
made via his site and the &amp;quot;Organized professional method&amp;quot; he used to implement this.&lt;/p&gt;
&lt;h2&gt;Digital tools I wish existed - Jonathan Borichevsky&lt;/h2&gt;
&lt;p&gt;The author summarizes some of the missing things in today's PIM and additions that would make managing the vast of information
that we consume today. I like his ideas for a single search platform to search all of the media that you have consumed.&lt;/p&gt;
&lt;h2&gt;Retrieval of similar chess positions&lt;/h2&gt;
&lt;p&gt;This is a novel paper that explores the usage of text based information retrieval techniques for a query by example request that fuzzy matches positions. The idea of similarity is rooted in adjusting the score based on the pieces distance from their position in the query and also the connectivity of the pieces expressed by the attacks and defense they provide. I was planning on using this technique to develop a chess bot that plays similar to a chess celebrity.&lt;/p&gt;
&lt;h2&gt;Hiding messages in chess games - James Stanley&lt;/h2&gt;
&lt;p&gt;This is an article that describes a method that the author came up with to encode a string in a valid PGN. The main idea is that the possible moves 
at a given position are used as the base for the next character to be encoded.&lt;/p&gt;
&lt;h2&gt;Body composition and diabetes risk&lt;/h2&gt;
&lt;p&gt;This was an article that outlines the risks of being overweight and how they contribute to diabetes mellitus.&lt;/p&gt;
&lt;h2&gt;Reverse engineering the source code of the BioNTech/Pfeizer SARS-CoV-2 vaccine&lt;/h2&gt;
&lt;p&gt;A great insight on how the manufactured vaccines RNA sneaks past the immune system to produce DNA for the body to train against. 
Really interesting things on programming molecules and proteins.&lt;/p&gt;
&lt;h2&gt;Chess2Vec - Andreas Stockl&lt;/h2&gt;
&lt;p&gt;A short tutorial on an interesting idea: representing chess moves as vectors to calculate similarity between moves.&lt;/p&gt;
</content:encoded></item><item><title>Stars and Lasers: DevLog #2</title><description>A computer port of the table top game Stars and Lasers. Latest progress on getting a basic game going</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Fri, 04 Dec 2020 00:00:00 GMT</pubDate><guid isPermaLink="true">stars_and_lasers_devlog_2.html</guid><content:encoded>&lt;p&gt;Ok I made some progress in getting adding the correct player activation method. 
I was locked in on just selecting a random ship from the available ships in the 
grid but the correct thing was to have a weighted probability from the existing 
ships for each side to decide the winner of the roll and have the player choose 
which ship to activate. This also lead the way to start a new turn 
(if the weight total is 0 all ships have played).&lt;/p&gt;
&lt;p&gt;I added a stupid AI class as a place holder so that I could complete the turn 
sequence related work. The rule book actually has a simple rule based AI 
description which I could add and have semi-playable game.&lt;/p&gt;
&lt;p&gt;No changes with regards to the UI so I’m not adding any new screenshots or 
videos.&lt;/p&gt;
</content:encoded></item><item><title>Stars and Lasers: DevLog #1</title><description>A computer port of the table top game Stars and Lasers. Getting started.</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Sat, 28 Nov 2020 00:00:00 GMT</pubDate><guid isPermaLink="true">stars_and_lasers_devlog_1.html</guid><content:encoded>&lt;p&gt;Well I’ve probably wrote this a million times: I have interest cycles when it 
comes to hobby programming. The cycles alternate between FinDev and GameDev. 
In this GameDev cycle I’ve decided to take a more pragmatic approach to a new 
project (one that I know will be abandoned like the million others). It all 
started with a news letter that I get from WarGamingVault. This is a website 
that sells rule books for table top games. I was looking through the best 
sellers of the month and I saw a rule book that was advertised as “simple to 
play star ship battles”. I knew that figuring our the game mechanics is a ton 
of work running hundreds maybe thousands of test play to tune those numbers and 
rules to get a balanced game, so I though why not just stand on the shoulders of
some one that has already put in that work? There was only one comment on the 
book from a guy who bought a lot of books from that site and wrote reviews for 
them. The author also had a blog where he published action reports and he 
seemed pretty active so I went ahead and purchased it for $14.&lt;/p&gt;
&lt;p&gt;The book is about 50 pages and can be condensed to maybe 30 with the actual 
mechanics of the game play. They do seem simple enough for a table top game but 
putting those rules in a program and adding the polish to it is going to be a 
lot of work. I went through the rules and took notes on the sequence of the play
as a starting point. I had some open questions and sent an email to the author 
who answered them the next day. With a basic understanding of the game I started
working on an iOS version. I started out with UIKit but soon realized that 
it’s a lot of unnecessary work when you don’t use a game engine for a game so 
I switched to Godot. I didn’t really like the dynamic python like scripting 
language from my previous experiences building join5 and ITTB but decided the 
stick with GDScript even though Godot officially supports C# now because of the 
deeper integration with the editor and the simplicity of the game. I’m thinking 
that I’ll continue with GDScript for at least the 2D prototype.&lt;/p&gt;
&lt;p&gt;Ok, enough preamble now to what I’ve been doing. I started out with a quick 
refresher of Godot and went through their official documentation. Then I created
the new project and added the scene. Next I added some simple GUI elements for 
each of the steps in the turn sequence and the code that transitions between 
these states. For now it’s pretty manual and hardcoded but it should be enough. 
The worst part about building games is that I have to work in GIMP to make 
sprites and things which I’m really not good at, but I still managed import a 
space ship sprite from opengamearts.org and made a target selector sprite by 
myself. I added the code that make the ship move and turn based on the mechanics
in the rule book. The calculations are pretty simple in 2D but porting to 3D 
will probably have me scratching my head for days with the vector math.&lt;/p&gt;
&lt;p&gt;Here are 2 screenshots of what I currently have:&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/SAL1.png"&gt;/img/SAL1.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/SAL2.png"&gt;/img/SAL2.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I haven't been able to play the table top version of the game because I don't
have the props but from the rules and the action reports I've read on the authors
site at https://littlewargamingworlds.com the game is action packed and fast for
a tactical board game.&lt;/p&gt;
&lt;p&gt;If you want to purchase the rule book it's here: 
https://www.wargamevault.com/browse/pub/11423/Mac&lt;/p&gt;
</content:encoded></item><item><title>Turkiye'den s.ktir olup gitmek</title><description>🇹🇷Leaving Turkey behind</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Mon, 09 Nov 2020 00:00:00 GMT</pubDate><guid isPermaLink="true">turkiyeden_siktir_olup_gitmek.html</guid><content:encoded>&lt;p&gt;Bos beles ve bir o kadar les bir troll yuvasi olan eksisozluk ve diger 
“product sensin sana kafam girsin” business modeli ile calisan content. 
hostingcileri zengin etmemek adina artik internette kendim sahibi olmadigim 
hic bir platforma byte harcamiyorum. Ama bazen guzel konular denk geliyor bir 
iki bir sey yazmak istedigim oluyor, o zaman da ver elini blog diyorum. Neyse 
olaya geri donelim. Bu baslik sozlugun en populer basliklarindan ve binlerce 
entrysi var. Genel olarak gitmek icin kasanlar, hadi artik bir siktirin gidin 
kafamizi sikmeyinciler ve gidip de tecrubelerini paylasanlar oluyor. Ben 3. 
kategoriden biraz bilgi vereyim. Yaklasik 5 senedir pacific north west tarafinda
yasiyoruz. Bundan 7 sene once esim “ya yurt disina ya da timarhaneye gidecem” 
diyerek buyuk bir risk ile bu macerayi baslatti. Bundan once de gitme 
girisimlerimiz olmustu ama x veya y nedeni ile gidememistik, ama bu sefer oldu.
Dunyanin top 10 MBA programlarindan birine kabul aldi. O 2 sene Pittsburgh 
PA’da okurken ben Istanbul’da kalip calistim ve okulu finanse ettim. Buna 
kalkismadan once en yakin arkadaslarim “boyle evlilik olmaz, olay boyle degil” 
filan gibi nasihatlerle beni sorguladi ama ben pek takmadim. Evet riskli bir 
haraket evlilik acisindan ama Turkiye’de kalip timar/hapishanede biten bir 
evlilik olmasinin sansi o riskten daha buyuk geldi bana. Benim meslek evrensel 
ama esimin degil ve o da kariyerinden vaz gecmek istemiyor diye, onun MBA yapip
bir kariyer degisimi yapmasi en optimal cozum gibi gelmisti.&lt;/p&gt;
&lt;p&gt;O 2 sene bohunca 3 ayda bir 2-3 haftalik ziyaretlerle idare edip hatri sayilir 
bir miktarda para harcadik. O zamanlar usd/try daha insancil seviyelerde oldugu 
icin karsilayabildik. Bugun olsa muhtemelen yapamazdik. Neyse esim programi 
bitirdikten sonra amazondan is teklifi aldi. ben de yanci olarak 5 sene once 
yanina temelli tasindim ve boylece sikitirp gitmis olduk.&lt;/p&gt;
&lt;p&gt;Ilk iki sene sehirin gobeginde deniz manzarali bir daire tuttuk. Ben gunduzleri 
evde takilip oyun oynadim, kendi hobi projelerime baktim, aksamlari da 
istanbuldaki musterilerin islere bakip eve 3-5 kurus katkida bulundum. Herhalde
o zamanlar esim benim 2x katim daha cok kazaniyordu. Medeni bir yasam, medeni 
insanlar, herkes kafasina gore takiliyor kimse birbirine karismiyor. En buyuk 
dert alt kattaki hintlilerin aksamlari curry yapip evi kokutmasiydi. Turk/middle
east marketlerinde her bok var, Turk restoranlarinda rakisindan begendili 
kebabina kadar her sey var. Tek ozledigim aile ve arkadaslardi. Onlarla da 
facetime ve instant messaging ile her gun konusuyorduk zaten, senede bir tatile 
gidince de gorusuyorduk.&lt;/p&gt;
&lt;p&gt;ikinci senemizin basinda hamile kaldik ve sehirin disinda mustakil bir eve 
ciktik. Bundan sonra bir daha asla apartman dairesine donmem. Senenin sonuna 
dogru bir kizimiz oldu ve bir Amerikan vatandasi olarak bizim cektigimiz bu 
sacmaliklarin hic birini cekmeyecek. bahceli bir evde (hatta bahcede kendine 
ozel salincakli kaydirakli parki var) buyuyecek, sokakta bisikletine binip 
arkadaslari ile oynayacak, Halloweende kostumunu giyip trick’r treat yapacak. 
Benim gibi kurban bayraminda musluman olmadigi halde zorla sabah namazina 
goturulup, kanli sokaklardan merserize corap festivali akraba toplasmalarina 
gitmek zorunda kalmayacak.&lt;/p&gt;
&lt;p&gt;cocuk olduktan sonra benim de calisma iznimin cikmasi ile ben de dunyanin onde
gelen bir firmasinda yazilim muhendisi olarak ise basladim ve su an finansal 
olarak rahat bir hayatimiz var. Tek sikayetim aile destegi olmadan cocuk 
buyutmenin zor olmasi, ayni zamanda cocugumun buyuk anneleri ve babalari ile 
yakin bir iliskisi olmamasi. Bir sikintim da bu salgin boku zamaninda esim ve 
bana bir sey olursa yardima gelecek birinin cok uzak oldugumuz icin en erken 
24 saat icinde gelebilmesi.&lt;/p&gt;
&lt;p&gt;Sonuc olarak biz sansliydik, buyuk risk aldik ve tuttu. Ama hesaplanarak 
alinan bir riskti bu.&lt;/p&gt;
</content:encoded></item><item><title>Animation pipeline for an ASCII roguelike game</title><description>Tackling the problem of animations in ASCII graphics</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Sat, 29 Aug 2020 00:00:00 GMT</pubDate><guid isPermaLink="true">animation_pipeline.html</guid><content:encoded>&lt;p&gt;Animations are an important part of an immersive experience so I wanted to incorporate some combat animations into the game. Cogmind has exceptional animations and downloaded some of the animation gifs that were in the devblog and analyzed them frame by frame to get a better idea on how to create good animations. I'll go over the animations themselves in a different section but in this doc I want to outline a system that will manage the rendering of each individual animation on the screen.&lt;/p&gt;
&lt;h2&gt;Architecture&lt;/h2&gt;
&lt;p&gt;There are going to be different kinds of animations: explosion, fire, beam weapon charging, etc. All these animation will contain the procedural logic to play the animation within it self, but there needs to be a rendering pipeline that accepts these animations and plays them in sequence. The computations of the animations need to happen in a background thread and the actual rendering needs to happen it the UI thread so we are talking about async execution. This means the pipeline needs to synchronize these animations to play in sequence. This is accomplished by using DispatchGroup and a semaphore that controls the number of animations allowed to run. A simple Animating protocol defines the interface that the pipeline will need to run any given animation.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-swift"&gt;class AnimationPipeline {
    var game: Game
    var animations = [Animating]()
    private let semaphore = DispatchSemaphore(value: 1)
    private let dispatchQueue = DispatchQueue(label: &amp;quot;taskQueue&amp;quot;, qos: .default)

    init(game: Game) {
        self.game = game
    }
    func execute() {
        let group = DispatchGroup()
        for a in animations {
            group.enter()
            self.dispatchQueue.async {
                self.semaphore.wait()
                a.run()
                self.semaphore.signal()
                group.leave()
            }
        }
        group.notify(queue: DispatchQueue.main) {
            self.game.render()
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here the various components that have animations queue up all their Animating classes in and then call execute once they are ready to have the animations played. The pipeline iterates through all the animations in the queue and waits on the semaphore until the animation is completed. Once every animation has been player it clears the screen to return to the original state.&lt;/p&gt;
&lt;h2&gt;Update 1&lt;/h2&gt;
&lt;p&gt;An shortcoming that I discovered today with the pipeline was that the current animation has to finish before the next one can start and this is not always the desired effect. When you shoot a laser it's more realistic and better looking if the target starts bursting out sparks at contact rather then waiting for the beam animation to finish. This means that the architecture had to change into a model that allows creation of a chain of animations with the running animation having some means of triggering the next animation in the and continue running. I implemented this by adding an index and a closure parameter to the run function of the Animating protocol. When the pipeline calls run on the animation it passes in the current index and a reference to a method called trigger of itself. When the animation has done its initial work (e.g the beam animation has reached the target) it calls the method reference with the index parameter plus 1 indicating the next animation should start. This signal is captured by the pipeline and the animation with the index received from the current animation is added to the running queue.
There are other ways of accomplishing the same synchronization by using semaphores inn the pipeline but this approach seemed cleaner and totally non blocking.&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/km1.gif"&gt;/img/km1.gif&lt;/a&gt;
&lt;a href="/img/km2.gif"&gt;/img/km2.gif&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Update 2&lt;/h2&gt;
&lt;p&gt;I ran into an issue with the sequence of the scheduled actors and the animations. Since these two are running in different queues some of the actors were getting scheduled to move before the explosion or destruction animations were being completed. I didn't want to use a single serial queue to synchronize the animations and scheduled actions to I implemented a DispatchGroup on the AnimationPipeline to block until the animation is completed.&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/km11.gif"&gt;/img/km11.gif&lt;/a&gt;&lt;/p&gt;
</content:encoded></item><item><title>A renderer for roguelike games on iOS/macOS</title><description>A method for using GameKit to render ASCII graphics on apple devices</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Sat, 25 Jul 2020 00:00:00 GMT</pubDate><guid isPermaLink="true">roguelike-renderer.html</guid><content:encoded>&lt;h1&gt;Renderer&lt;/h1&gt;
&lt;p&gt;22nd June 2020 at 9:47pm&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This code is taken from the brogue &lt;a href="https://github.com/tmewett/BrogueCE"&gt;source code&lt;/a&gt; and slightly modified.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Rendering the map on screen is maybe the most important part of the game. I chose to develop this game on the iOS platform (possibily also on macOS) and use the libraries provided by Apple. The architecture should be portable to other platforms as most game development platforms are built around the same core concepts of scene graphs, and nodes with textures (sprites) that draw objects on the screen. Coordinate system maybe different (e.g the origin may be the top left of the screen or bottom left) but the basics are the same.&lt;/p&gt;
&lt;p&gt;The idea is simple:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;create a cache of textures for each glyph that will be used in the game&lt;/li&gt;
&lt;li&gt;create a scene graph with empty sprite nodes&lt;/li&gt;
&lt;li&gt;adjust each cell by updating it's texture, colors and illumination based on the level map.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I take a layered approach to rendering the map by first rendering the level, then characters and FoV for the player.&lt;/p&gt;
&lt;h2&gt;Texture Cache&lt;/h2&gt;
&lt;p&gt;The texture cache generates an image dynamically with the glyph that is requested and caches the result internally as it will be used over and over again. A detail here is that you need to calculate a scaling factor to make sure the glyphs are scaled correctly to fit any screen size and map size.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;private func createTexture(glyph: String, size: CGSize) -&amp;gt; SKTexture {
    let fontSize = CGFloat(130)
    var scaleFactor: CGFloat {
        let font = UIFont(name: &amp;quot;Menlo&amp;quot;, size: fontSize)!
        let attr = [NSAttributedString.Key.font: font]
        let opts = NSStringDrawingOptions.usesFontLeading
        let bounds = glyph.boundingRect(with: CGSize(width: 0, height: 0), options: opts, attributes: attr, context: nil)
        let factor = min(size.width / bounds.width, size.height / bounds.height)
        return factor
    }
    let font = UIFont(name: &amp;quot;Menlo&amp;quot;, size: fontSize * scaleFactor)!
    UIGraphicsBeginImageContext(size)
    let fontAttr = [NSAttributedString.Key.font: font, NSAttributedString.Key.foregroundColor: SKColor.white]
    let realBounds: CGRect = glyph.boundingRect(with: CGSize(width: 0, height: 0),
                                        options: [.usesFontLeading],
                                        attributes: fontAttr,
                                        context: nil)
    let stringOrigin = CGPoint(x: (size.width - realBounds.width)/2 - realBounds.origin.x,
                               y: font.descender - realBounds.origin.y + (size.height - realBounds.height)/2)
    glyph.draw(at: stringOrigin, withAttributes: fontAttr)
    let surface = UIGraphicsGetImageFromCurrentImageContext()

    UIGraphicsEndImageContext()
    let texture = SKTexture(image: surface!)
    self.textureMap[glyph] = texture
    return texture

}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Scene graph&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;We need some nodes in the scene graph that will contain these textures. This is pretty straight forward and we generate row x col empty nodes for the backgroun, the same number for the foreground and add them as children to the root of the graph with the same location but different z-index values. The background node doesn't need a texture as we won't be printing a glyph on it but we'll just be adjusting its color. It's also a good idea to wrap these 2 nodes in a Cell object as we have an illumination attribute that will effect these nodes.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;static let defaultIllumination: CGFloat = 0.3
let foreground: SKSpriteNode
let background: SKSpriteNode
var illumination: CGFloat
var glyph: SKTexture? {
    set(newGlyph) {
        foreground.texture  = newGlyph
    }
    get {
        return foreground.texture
    }
}
var fgcolor: SKColor {
    set(newColor) {
        let rgba = newColor.rgba
        foreground.color = SKColor(red: CGFloat(rgba.red * illumination),
                                   green: CGFloat(rgba.green * illumination),
                                   blue: CGFloat(rgba.blue * illumination),
                                   alpha: CGFloat(rgba.alpha))
    }
    get {
        return foreground.color
    }
}
var bgcolor: SKColor {
    set(newColor) {
        background.color = newColor
    }
    get {
        return background.color
    }
}
init(x: CGFloat, y: CGFloat, size:CGSize) {
    foreground = SKSpriteNode(color: .white, size: size)
    background = SKSpriteNode(color: .clear, size: size)
    foreground.colorBlendFactor = 1
    background.colorBlendFactor = 1
    foreground.position = CGPoint(x: x, y: y)
    background.position = CGPoint(x: x, y: y)
    foreground.zPosition = 1
    foreground.anchorPoint = CGPoint.zero
    background.anchorPoint = CGPoint.zero
    illumination = Self.defaultIllumination
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Drawing a cell&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Now in the game scene we add the nodes that the Cell object exposes to the scene graph&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;for x in 0..&amp;lt;cols {
    var row = [Cell]()
    for y in 0..&amp;lt;rows {
        let newCell = Cell(x: CGFloat(x) * cellWidth,
                           y: CGFloat(rows - y - 1) * cellHeight,
                           size: CGSize(width: cellWidth, height: cellHeight))
        row.append(newCell)
    }
    cells.append(row)
}

for x in 0..&amp;lt;cols {
    for y in 0..&amp;lt;rows {
        addChild(cells[x][y].background)
        addChild(cells[x][y].foreground)
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;At this point we can refer to any node by cells[x][y].{foreground,background} to update its glyph, texture or illumination value. It's worth putting this update in its own function as it will be used in different places when rendering:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public func setCell(x: Int, y: Int, code: UInt32, bgColor: CGColor, fgColor: CGColor, illumination: CGFloat = 1.0) {
    cells[x][y].illumination = illumination
    cells[x][y].fgcolor = SKColor(cgColor: fgColor)
    cells[x][y].bgcolor = SKColor(cgColor: bgColor)

    if let glyph = UnicodeScalar(code) {
        cells[x][y].glyph = textureCache.getTexture(glyph: String(glyph))
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Further thoughts&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This is an efficient way of rendering the level on the screen as there is minimal scene graph manipulation and we are just updating textures and colors. I have not looked in detail into how illumination and lighting could be implemented to be more realistic but this simple method of multiplicatively modifying RGB values seems to result in an OK result.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Update 2 - Graph based rendering&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I mentioned that I took a layered approach to rendering which meant that there was a render method in GameScene that would take all the objects to be rendered as parameters and render them in order. The ordering is important because things overwrite each other. If you render the FoV before the player you will not see the player symbol '@' as it will be overwritten by a bright dot (the location of the player is always in the FoV). I decided that it would be a cleaner approach to have all the object render themselves and keep track of their dependencies that also need rendering. E.g the player now has a FoV object that it will ask to render itself before rendering itself (A lot of it selves there ...).&lt;/p&gt;
&lt;p&gt;This is accomplished by having a Renderable protocol that takes the GameScene which contains the actually methods to manipulate textures on the screen. The Game object has a reference to the GameScene object to it can pass it along to the objects that are Renderable.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Update 3: Animation overlay&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;After starting work on the animations I realized that using the illumination system to render explosion effects with alpha channel was going to be a pain because of the transparency required. I would need to find the glyphs for the tiles that have the explosion effect and adjust illumination to give a transparency / lighting effect. Even with this approach I still wouldn't get exactly what I wanted as the effects that illumination provide even when applied to the background is not really what an explosion or laser charing effect look like. So I decided to add another NxM array of cells to the scene as the overlay. This is where all the animation rendering happens and it sits at a higher Z index than the tile cells. Now when the animation is rendered on this layer I can adjust the transparency of the background for the cell to get great effects.&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/5.gif"&gt;/img/5.gif&lt;/a&gt;&lt;/p&gt;
</content:encoded></item><item><title>My backup strategy</title><description>How I setup Jenkins + Borg for scheduled incremental backups</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Tue, 21 Jul 2020 00:00:00 GMT</pubDate><guid isPermaLink="true">backup-strategy.html</guid><content:encoded>&lt;p&gt;I've always backuped my files and folders for as long as I can remember. But up until a couple of months ago my backup strategy was ad-hoc. I would manually copy important files to a networked computer, cloud storage or before those existed to a USB drive. It was mostly not automated or very poorly automated by a couple of lines of bash scripts creating zip/tar.gz archives of directories and copying them over. This is kind of works but is very inefficient and not really sustainable as the data you need to backup accumulates over time. So about 2-3 months ago I decided to invest the time to look into some existing solutions in this area. My requirements were pretty simple:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Support incremental backups&lt;/li&gt;
&lt;li&gt;Support encrypted backups&lt;/li&gt;
&lt;li&gt;Support for sending backups to another machine on the network&lt;/li&gt;
&lt;li&gt;Easy to configure a new directory to backup&lt;/li&gt;
&lt;li&gt;CLI driven&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;After some research the simplest program that would support all these requirements seemed to be Borg backup. I paired Borg with Jenkins for scheduled backups and a Synology NAS with CloudSync for off-site encrypted backups on the cloud.&lt;/p&gt;
&lt;p&gt;The process is pretty simple.&lt;/p&gt;
&lt;h3&gt;Initial setup&lt;/h3&gt;
&lt;p&gt;There are 2 types of backups for me:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Backups of files that I only need to keep on-site&lt;/li&gt;
&lt;li&gt;Backups of files that are super important and need to be backed up on the cloud (encrypted)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Different projects may live on different servers on the network and each host on the network gets it's own Borg repository. The initial repo setup is done manually but it's not really worth automating this as I haven' added a new machine to the network in ages (I don't think I've added a new machine after I started using Borg)&lt;/p&gt;
&lt;h3&gt;Backup process&lt;/h3&gt;
&lt;p&gt;I use Jenkins to schedule the backups, so each app/data store gets its own backup job in Jenkins.&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/jenkins-backup-jobs.png"&gt;jenkins&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Scripting Borg commands via the Shell execution block in Jenkins makes everything pretty simple:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;NFS_MOUNTS=$(mount -l | grep nfs | wc -l)
if [ $NFS_MOUNTS -eq 0 ]; then
 echo &amp;quot;NFS not mounted&amp;quot;
 return -1
fi

sudo BORG_PASSPHRASE=&amp;lt;password&amp;gt; borg create -v --stats --compression zlib /mnt/backup/cloud-synced/borg-s1::ctp-data-{now} /tmp/ctp-data/

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Borg doesn't support putting stuff on a networked machine natively but that's not really a blocker. I just mount a directory on the NAS to all the hosts. The first couple of lines in the script checks that the NAS is mounted or fails. The next line is borg command that doest the backups. There are 2 directories on the NAS&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The &lt;code&gt;unsynced&lt;/code&gt; directory&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;cloud-synced&lt;/code&gt; directory&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I've setup Synology CloudSync to send the files in the &lt;code&gt;cloud-synced&lt;/code&gt; directory over to a cloud hosting provider.&lt;/p&gt;
&lt;p&gt;I also use some plugins in Jenkins to coordinate the backup process. Some app that I host like the wiki require frequent backups and sometimes depending on system load the duration of the backup may exceed the frequency. I also don't want multiple Borg jobs writing to the same repository as this may lead to race conditions. So I use the Lockable Resources plugin in Jenkins to synchronize these jobs.&lt;/p&gt;
&lt;p&gt;There are multiple hosts that need backups so I need a Jenkins runner on each host that has access to the directories on that machine so I also need a plugin that makes sure that a job can only run on a host that I specify.&lt;/p&gt;
&lt;p&gt;This works pretty well for data that's residing on my servers but for files on laptops etc it's not really convenient. I still copy documents and files manually from client to the NAS when I want to keep a backup of those. But as I'm moving my apps to self hosted web app based solutions I find that the need to do this manual copying is pretty minimal.&lt;/p&gt;
</content:encoded></item><item><title>NextCloud installation with docker + full text search</title><description>Steps needed to make a nextcloud docker based installation work with full text searching</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Mon, 20 Jul 2020 00:00:00 GMT</pubDate><guid isPermaLink="true">nextcloud-elastic.html</guid><content:encoded>&lt;p&gt;There are multiple options when installing nextcloud but I always install my self hosted services through docker just to keep everything isolated and easy to backup. I will publish a post on the back strategy I use with docker in another post but for this post here's how I managed to get nextcloud working with docker (docker-compose actually) and the full text search capability.&lt;/p&gt;
&lt;p&gt;Why would you want full text search? Because the search capability for nextcloud out of the box is pretty naive in that it only searches for the query in the file name, which is OK sometimes, but most of the time you need the search to be in the contents of the file. This capability is provided by an external search server, in this case via ElasticSearch (which is an excellent search server albeit resource hungry). Ok, so here is the docker-compose file I use to setup everything:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;version: '2'

services:
  db:
    image: mariadb
    command: --transaction-isolation=READ-COMMITTED --binlog-format=ROW
    restart: always
    volumes:
      - ./db:/var/lib/mysql
    environment:
      - MYSQL_ROOT_PASSWORD=
      - MYSQL_PASSWORD=
      - MYSQL_DATABASE=nextcloud
      - MYSQL_USER=nextcloud

  app:
    image: nextcloud
    ports:
      - 90:80
    links:
      - db
      - es
    volumes:
      - ./nextcloud:/var/www/html
    restart: always

  cron:
    image: nextcloud
    links:
     - db
     - es
    volumes:
      - ./nextcloud:/var/www/html
      - ./crontab:/var/spool/cron/crontabs/www-data
    restart: always

  es:
    build: ./elastic-docker/.
    environment:
      - discovery.type=single-node
    volumes:
      - ./elastic:/usr/share/elasticsearch/data
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The first two services are from the standard docker-compose file in the nextcloud documentation page. I've added another service that runs the cron scripts (you can delete this is you have a different way to run crons) and then there is elastic search service. I use local directories for persistent storage as it's super easy for backups. The elastic search image requires a bit of customization so here is the &lt;code&gt;Dockerfile&lt;/code&gt; for the service&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;FROM docker.elastic.co/elasticsearch/elasticsearch:7.6.2
RUN /usr/share/elasticsearch/bin/elasticsearch-plugin install --batch ingest-attachment
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Elastic search wants a plugin to index content from nextcloud.&lt;/p&gt;
&lt;p&gt;After these files are in place, spin up the stack with &lt;code&gt;docker-compose up -d&lt;/code&gt;. Make sure you see all services up and running. You can ignore the warnings from the ElasticSearch image.&lt;/p&gt;
&lt;p&gt;After the containers are up install the following apps for Nextcloud&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;full text search&lt;/li&gt;
&lt;li&gt;full text search - elastic platform&lt;/li&gt;
&lt;li&gt;full text search - files&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Now you can test the installation using&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker-compose exec --user www-data app php occ fulltextsearch:test
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;if everything goes well you can start the indexing&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker-compose exec --user www-data app php occ fulltextsearch:index
&lt;/code&gt;&lt;/pre&gt;
</content:encoded></item><item><title>Roguelike FOV 2</title><description>Shadowcasting for roguelike field of vision</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Sat, 18 Jul 2020 00:00:00 GMT</pubDate><guid isPermaLink="true">roguelike-fov2.html</guid><content:encoded>&lt;h1&gt;Shadow casting&lt;/h1&gt;
&lt;p&gt;I was thinking that the ray casting method above would be sufficient but I have since seen some quirks in the highlighted tiles in the FoV that made me want to ditch it. Another reason for implementing a more efficient algorithm is that the enemies and neutral characters in the level also have a field of view that will make them react to other actors, props, etc. that they can see. This meant that the FoV calculations will be triggered over and over for potentially tens to hundreds of actors per turn.&lt;/p&gt;
&lt;p&gt;Shadow casting is actually a reversal in a sense that you don't try to figure out the cells that are visible but try to find the cells that are shadowed by obstacles. After some research on previous implementations I was able to grasp the logic behind the algorithm and want to go over it here with hopes to explain it better.&lt;/p&gt;
&lt;p&gt;Ultimately we want to have a 360 degree FoV but breaking up the whole into 8 pieces of 45 degrees each will make it much more simpler as the algorithm is basically the same for each octant with just the increments of the rows and columns differing by octant.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#################f
#.......11111...#e
#.......1111....#d
#.......111.....#c
#.......11......#b
#.......@.......#a
#...............#
#################
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;the first octant marked by 1's&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;we will scan each row in the octant and mark it as visible if there is no object that is cast a shadow, starting for row a working out way up to row f. You should terminate processing if the FoV radius is reached before the end of the map. So without any blocking tiles this is rather straight forward.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;for row in 1..&amp;lt;actor.fovRadius {
 for col in 0...row {
   y = player.position.y - row
   x = player.position.x + col
   map[y][x] = 1
 }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then we need to repeat the same for the remaining 7 octants. The part that will change is the player.position.y - row and player.position.x + col. For the octant that covers [-45;0] you would want to subtract the column instead of adding it. A nice way of implementing this would be to store the increment deltas in a list and apply them based on the octant number&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;let octants = [
 [XY(x: 0, y: -1), XY(x: 1, y: 0)],
 [XY(x: 1, y: 0), XY(x: 0, y: -1)],
 [XY(x: 1, y: 0), XY(x: 0, y: 1)],
 [XY(x: 0, y: 1), XY(x: 1, y: 0)],
 [XY(x: 0, y: 1), XY(x: -1, y: 0)],
 [XY(x: -1, y: 0), XY(x: 0, y: 1)],
 [XY(x: -1, y: 0), XY(x: 0, y: -1)],
 [XY(x: 0, y: -1), XY(x: -1, y: 0)]
]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now the increments can be accessed as&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;let rowInc = octants[octant][0]
let colInc = octants[octant][1]
and we can iterate over this list for each octant we want to process
let fov = (0..&amp;lt;8).flatMap { processOctant(actor: actor, octant: $0) }
with the
private func processOctant(actor: Character, octant: Int) -&amp;gt; [XY] {
...
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ok, so how can we calculate the shadows? The idea is to keep a list of shadow angles that are being cast from an opaque object. We'll define the angle to be a value between 0 and 1 where 0 represents 0 degrees and 1 represents 45 degrees in the first octant. This will have different values for the other octants but that's not important. We're not really dealing with the angles but the slope of the ray that touches from the top left of the obstacle and the bottom right proceeding upwards and right (for the 1st octant) that is originating from the player.&lt;/p&gt;
&lt;p&gt;Here's a zoomed in version&lt;/p&gt;
&lt;p&gt;&lt;em&gt;light rays shooting from the player&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Any tile that has a projection (lights shooting from the player touch the top left and bottom right) that falls within the range of already calculated projections cannot be seen by the player. This is due to the fact that any tile further away from the player will have a narrower angle between the left and right slopes because all of the tiles are the same size and shape.&lt;/p&gt;
&lt;p&gt;Calculating the slopes for the projection is basically finding the ratio of the columns to rows of the top left and bottom right parts of the tile. By rows and columns I mean the length of the line from the player tile to the target tile.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;private func getProjection(row: Int, col: Int) -&amp;gt; Shadow {
    let topLeft = Double(col) / Double(row + 1)
    let bottomRight = Double(col + 1) / Double(row)
    return Shadow(start: topLeft, end: bottomRight)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;for the lop left calculation the nominator is col as the player location is zero so target location - player location is just the column of the target. The denominator has 1 added to its row because the it's actually the bottom of the row above it. For the bottom right calculation we need to add 1 to the column as it's actually the corner of the next column.&lt;/p&gt;
&lt;p&gt;As we are processing row by row we need to keep track of all the shadows (left and right slopes) to filter out tiles that fall into this range. We could keep a list of all the left/right slopes we have seen thus far and linearly search each one but there is a better way: we can actually merge any new projections that we encounter into a list of existing projections. This works like this:&lt;/p&gt;
&lt;p&gt;Let's say our shadow list is&lt;/p&gt;
&lt;p&gt;[(0...0.2), (0.6...0.7)]&lt;/p&gt;
&lt;p&gt;and we get the projection (0.8...0.9). We check out list and see that it doesn't intersect with any existing projections so we can just append it to our list. Out new list is&lt;/p&gt;
&lt;p&gt;[(0...0.2), (0.6...0.7), (0.8...0.9)].&lt;/p&gt;
&lt;p&gt;Lets say our next tile has the projection [0.4...0.85]. This fits right into the middle of and covers the existing (0.6...0.7) projection entirely and also partially covers (0.8...0.9) so we can go ahead and merge. Our new list is now&lt;/p&gt;
&lt;p&gt;[(0...0.2), (0.4...0.9)]&lt;/p&gt;
&lt;p&gt;Instead of having 4 items we have 2 now that we merged. If we ever reach a state where we have only one element in the shadows list and the left slope is 0 and right slope is 1 then we have the whole octant covered and every object in the rows after this row will be covered by the shadow so we can stop processing.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;private func processOctant(actor: Character, octant: Int) -&amp;gt; [XY] {
    let rowInc = octants[octant][0]
    let colInc = octants[octant][1]
    var fullShadow = false
    var result = [XY]()
    shadows = [Shadow]()
    for row in 1..&amp;lt;actor.fovRadius {
        var pos = actor.location + (rowInc * row)
        guard actor.game.scene.viewPort.contains(point: pos) else { break }
        for col in 0...row {
            if fullShadow {
                continue
            } else {
                let projection = getProjection(row: row, col: col)
                if !isInShadow(projection: projection) {
                    result.append(pos)
                }
                if actor.game.level.map[pos.y][pos.x].blocking {
                    fullShadow = addShadow(shadow: projection)
                }
            }
            pos = pos + colInc
            guard actor.game.scene.viewPort.contains(point: pos) else { break }
        }
    }
    return result
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So how would this merging algorithm look like? Here are the steps we need to consider&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Find out the correct index to put our new item in. It could be with or without a merge.&lt;/li&gt;
&lt;li&gt;Find if our new item overlaps with the previous entry or the next entry. We'll use this to do any necessary merges.&lt;/li&gt;
&lt;li&gt;handle the 4 conditions of&lt;ol&gt;
&lt;li&gt;overlaps with previous and next&lt;/li&gt;
&lt;li&gt;overlaps with next but not previous&lt;/li&gt;
&lt;li&gt;overlaps with previous but not next&lt;/li&gt;
&lt;li&gt;there is no overlap at all&lt;/li&gt;
&lt;li&gt;based on the overlapping situation adjusting the start/end (left/right) slope will take care of the merging.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;var index = 0
 for curShadow in shadows {
     if curShadow.start &amp;gt; shadow.start {
         break
     }
     index += 1
 }
 //let index = shadows.firstIndex { $0.start &amp;gt; shadow.start } ?? shadows.count

 let overlapsPrev = (index &amp;gt; 0) &amp;amp;&amp;amp; (shadows[index - 1].end &amp;gt; shadow.start)
 let overlapsNext = (index &amp;lt; shadows.count) &amp;amp;&amp;amp; shadows[index].start &amp;lt; shadow.end

 if overlapsNext {
     if overlapsPrev {
         shadows[index - 1].end = max(shadows[index-1].end, shadows[index].end)
         shadows.remove(at: index)
     } else {
         shadows[index].start = min(shadows[index].start, shadow.start)
     }
 } else {
     if overlapsPrev {
         shadows[index - 1].end = max(shadows[index - 1].end, shadow.end)
     } else {
         shadows.insert(shadow, at: index)
     }
 }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here are 2 images of a ray casting and shadow casting to compare:&lt;/p&gt;
</content:encoded></item><item><title>Roguelike FOV</title><description>Raycasting for roguelike field of vision</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Sat, 18 Jul 2020 00:00:00 GMT</pubDate><guid isPermaLink="true">roguelike-fov.html</guid><content:encoded>&lt;h1&gt;Field of vision&lt;/h1&gt;
&lt;p&gt;FOV is the area that is visible to the player. Making the whole level visible would lead to boring games so the area is limited to a certain radius. There are a couple of different algorithms that can be used to implement FoV. I choose to go with the simplest which is ray casting from the player position towards the outer rim of a circle that is defined by the how far the player can see.&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/fov1.jpg"&gt;image&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Ray casting&lt;/h2&gt;
&lt;p&gt;The algorithm is pretty straight forward. Calculate the rim of the circle defined by the radius R that corresponds to the maximum distance the player can see. Don't forget to clamp the coordinates returned by this function to the limits of the map. You can get negative coordinates (or more generally out of bounds coordinates) if the player is standing at the top left edge of the map. The ide&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;private static func rim(origin: XY, radius: Int) -&amp;gt; [XY]{
    var result = [XY]()
    var x = radius, y = 0
    var P = 1 - radius
    result.append(XY(x: origin.x, y: origin.y + radius))
    result.append(XY(x: origin.x, y: origin.y - radius))
    result.append(XY(x: origin.x + radius, y: origin.y))
    result.append(XY(x: origin.x - radius, y: origin.y))
    while x &amp;gt; y {
        y += 1
        if P &amp;lt;= 0 {
            P = P + 2 * y + 1
        } else {
            x -= 1
            P = P + 2*y - 2*x + 1
        }
        if x &amp;lt; y {
            break
        }
        result.append(XY(x: origin.x + x, y: origin.y + y))
        result.append(XY(x: origin.x - x, y: origin.y + y))
        result.append(XY(x: origin.x + x, y: origin.y - y))
        result.append(XY(x: origin.x - x, y: origin.y - y))

        if x != y {
            result.append(XY(x: origin.x + y, y: origin.y + x))
            result.append(XY(x: origin.x - y, y: origin.y + x))
            result.append(XY(x: origin.x + y, y: origin.y - x))
            result.append(XY(x: origin.x - y, y: origin.y - x))
        }
    }
    return result
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we have a bunch of target coordinates that we can shoot rays at. When shooting the rays the only thing that you need to check for is to make sure you don't penetrate blocking tiles like walls. This is a simple check when we are drawing a virtual line from the origin to the target. We stop drawing if we hit a wall. Drawing a line uses Bresenham's rasterized line drawing method.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public static func bresenham(x0: Int, y0: Int, x1: Int, y1: Int) -&amp;gt; [XY] {
    var result = [XY]()
    var dx = x1 - x0
    var dy = y1 - y0
    let xsign = dx &amp;gt; 0 ? 1 : -1
    let ysign = dy &amp;gt; 0 ? 1 : -1
    dx = abs(dx)
    dy = abs(dy)

    var xx: Int, xy: Int, yx: Int, yy: Int
    if dx &amp;gt; dy {
        xx = xsign
        xy = 0
        yx = 0
        yy = ysign
    } else {
        let t = dx
        dx = dy
        dy = t
        xx = 0
        xy = ysign
        yx = xsign
        yy = 0
    }
    var D = 2*dy - dx
    var y = 0
    for x in 0...dx {
        result.append(XY(x: x0 + x * xx + y*yx, y: y0 + x*xy + y*yy))
        if D &amp;gt;= 0 {
            y += 1
            D -= 2 * dx
        }
        D += 2*dy
    }
    return result
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now that we have a way of casting the rays, we just need a loop that sends a ray to each of the targets.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;static func naiveFov(origin: XY, radius: Int, level: [[Tile]]) -&amp;gt; [XY] {
    let rows = level.count
    let cols = level[0].count
    let rim = Set(Self.rim(origin: origin, radius: radius)
      .map { XY(x: clamp($0.x, min: 0, max: cols), y: clamp($0.y, min: 0, max: rows)) })
    var lit = [XY]()
    for target in rim {
        let ray = Bresenham.bresenham(x0: origin.x, y0: origin.y, x1: target.x, y1: target.y)

        for path in ray {
            if level[path.y][path.x].blocking {
                lit.append(path)
                break
            }
            lit.append(path)
        }
    }
    return lit
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is a rather inefficient way in terms of complexity as it processes the same tiles over and over but in practice is fast enough. There are other more sophisticated ways of determining FoV with different permissiveness properties like shadow casting which I will explore in the future.&lt;/p&gt;
&lt;p&gt;The code here only calculates the coordinates that fall in the FoV but doesn't do any highlighting. Thats part of a different post.&lt;/p&gt;
</content:encoded></item><item><title>Roguelike time system</title><description>A method for sequencing time in a roguelike</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Sat, 11 Jul 2020 00:00:00 GMT</pubDate><guid isPermaLink="true">roguelike-time-system.html</guid><content:encoded>&lt;p&gt;&lt;em&gt;This post contains a series of updates to an algorithm that show the evaluation and rationale. You don't end up with what you started.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The most naive scheduler in a rogue like is just assuming that every character moves at the same speed and iterating over the list to make them move. But that is boring and diminishes the tactics in the game. A huge slug should be slower than the player and a vampire bat should be faster.&lt;/p&gt;
&lt;p&gt;A simple way of accomplishing this is to use a priority queue. Each character in the world has a plan function that calculates the move it will make and enqueues it with the scheduler to be executed at a certain time. This time should be the current time + the cost to execute the action. For the human player this plan function is partly when the human is thinking what to do and partly in the input handler for the (when the action is sent to the queue).&lt;/p&gt;
&lt;p&gt;After a player input is received the scheduler starts dequeuing the items and executing them. The current time is updated to the time of the action that was executed. This works because of the priority queue and the first item dequeued is the item with the lowest timestamp value. This goes on until a player action is dequeued and executed. One thing to note here is that of actions with the same timestamp the player action should be the last so that other characters actions don't spill over to the next tick.&lt;/p&gt;
&lt;h2&gt;Example execution&lt;/h2&gt;
&lt;p&gt;Player (P) movement cost is 50
Monster (M) movement cost is 25&lt;/p&gt;
&lt;p&gt;So we expect the M to move 2 tiles when the player moves 1.
The queue is initially empty and the game asks all entities to plan their move. M plans it's move based on it's AI output and queues it with the scheduler&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[M(25)]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we are waiting for player input. Let's say the player pressed a movement key so we schedule that&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[M(25), P(50)]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The input from the player also triggers the scheduler execution. The scheduler gets the first item in the queue and executes the action and updates the current time from 0 to 25. After execution it asks for the owner of that item to run its planning again. So the monster again consults its AI and plans another move. The move is scheduled so the queue is now&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[M(50), P(50)]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The scheduler hasn't yet seen a command that belongs to the player so it keeps on dequeuing. The next item is again a monster action so it's dequeued and executed, current time is updated to 50 and another plan is requested. The plan is added to the queue so it is now&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[P(50), M(75)]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next up is the player action which is dequeued and executed and the scheduler loop can be terminated, leaving the queue as&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[M(75)]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;which is the same state as our initial queue.&lt;/p&gt;
&lt;h2&gt;Update 2: Remove planning phase&lt;/h2&gt;
&lt;p&gt;The plan &amp;amp; execute system has a design flaw that requires the action code to perform checks which kind leads to either poor code structure or unfair scheduling behavior.
The issue first surfaced when I saw that 2 monsters would end up occupying the same tile. Consider the following map setup&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;########
....M...
###N####
  #.#
  #.#
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Assume that M wants to go left and N wants to go up. When the scheduler asks M for the next M moves, M checks the location on the left and sees thats it's empty so plans a move it that direction. Next N sees that the same location is empty and also plans a move in that direction. Now in the action phase you need to check whether the target location is empty before making the move otherwise the monsters end up being on top of each other. But what does N do if the location is not empty in the action phase? N already spent credits to plan the turn so either N would have to choose an action with the same cost (to make it cost fair) or choose some other action that could cost less or more (or maybe skip the action). All of these seem like unfair solutions. The same unfairness happens when M plans to attack the player but the player isn't there because they got more turns than M. So this type of plan and then execute model is not really suitable.
I came up with an alternate model where all the actors in the world are added to priority queue again. But this time around there is no planning phase there is only an action phase. Once the actor executes their action, the action function returns the cost of the action, which is then used to determine the place of the action in the queue. Again queue processing terminates when it's the players turn so we can get input.&lt;/p&gt;
&lt;p&gt;Here is an example run:&lt;/p&gt;
&lt;p&gt;initially everybody is waiting in the queue&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[P(0), M(0), N(0)]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Player moves with cost 100&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[M(0), N(0), P(100)]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;M moves with cost 50&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[N(0), M(50), P(100)]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;N moves with cost 50&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[M(50), N(50), P(100)]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;M moves with cost 50&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[N(50), P(100), M(100)]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;N moves with cost 50&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[P(100), M(100), N(100)]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;now we are at the player again, so M, N moved twice for each player move which is correct since their movement cost is half that of the player.&lt;/p&gt;
&lt;h2&gt;Update 3: Sentinel&lt;/h2&gt;
&lt;p&gt;With the new turn system an issue that came up is when the turn processing stops with the player any other actor that was scheduled to act on the same tick gets delayed for a turn. This again leads to unfair time sharing situations. The fix is relatively easy: add a new actor called the TurnSentinel that acts as the demarcation between turns. It has a fixed action cost of the turn length which should be the same as the players movement cost to avoid situations where the player would move more or less than 1 square per turn. With this update the queue structure becomes like this&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[P(0), M(0), N(0), TS(100)]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;say all the actors took actions that cost 100 points, then the queue becomes&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[TS(100), P(100), M(100), N(100)]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;we calculate the sentinel action put it to the back of the queue and we terminate the scheduler processing loop because we see the sentinel and wait for player input.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[P(100), M(100), N(100), TS(200)]
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;Update 4: Credit system&lt;/h2&gt;
&lt;p&gt;I still ran into unfairness issues or other weird behavior with monsters moving more than they should in a turn because of their place in the queue so I decided to switch to an energy based system. It's still similar to the time based execution system but now each actor gets N credits each tick and action costs are deducted from their available credits. I didn't want to change the action api to allow for a credit check as that would mean running the AI twice. One for possibly selecting the action to see the cost then actually running it. This also imposes limits on the actions and NPCs would be could be biased on efficient credit usage rather than best actions. If the actor has a positive credit the scheduler will execute their actions until they run out of credits. This implies that they could end up with a negative balance. The next tick they will get N more credits and can execute their action if they end with a positive balance otherwise they'll have to wait for the next turn. The waiting is ok for the npcs but not the player. You can't have the player press a key and nothing happen because they had a negative credit balance. The solution to this issue is to recursively run the scheduler if the player credits are below -N. Why -N and not zero? Because if they have more than -N they will get N more in the next tick and the player action will execute. That means the last action will be executed twice which is not what we want.&lt;/p&gt;
&lt;p&gt;Let's say the action cost is 150, default charge per turn is 100. Every body started with 0 credit.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Charge: credits 100&lt;/li&gt;
&lt;li&gt;Spend: credits -50&lt;/li&gt;
&lt;li&gt;Charge: credits 50&lt;/li&gt;
&lt;li&gt;Spend: credits -100&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Now when you charge the next tick, the player will have 0 credits and not move. To prevent this a recursive call is made so every other actor gets their action and the player is now 0.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Charge: credits 100&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;and the player can move again.&lt;/p&gt;
&lt;h2&gt;Update 5&lt;/h2&gt;
&lt;p&gt;The credits system is working pretty good except for a couple of conditions that arisen due to the position of the player in the queue and animations. This was mainly related to the displacement mechanic that I wanted to implement and how I could have the user perceive that displacement. The player has to be in first position in the queue because when they do a ranged target, I want to calculate if the shot hit the target first. If the player is not first to go, then the monsters could change their location and the shot would miss. This could be accomplished by a preemptive scheduler that queue the shot as a &lt;code&gt;Schedulable&lt;/code&gt; then the player could go last but I have to think about that a bit more. A side from that I also changed the implementation to a round robin traversal instead of consuming all the credits of the current actor. I put all the &lt;code&gt;schedulables&lt;/code&gt; in to a local queue in the tick function and process that queue. If the current actor has any credits left after their action they get put back in the queue in last position and the processing continues until the queue is empty.&lt;/p&gt;
&lt;p&gt;My initial design for the time system was running on the main thread sequentially and the game would render the level at the end of a scheduler tick. This seemed to work well but if an actor gets more than 1 movement action per tick it would look like they jumped around. I decided that this can get hard to judge and predict the next monster location for fast monsters. One turn the monster is far away the next turn it jumped right next to the player. So I wanted to animate the monster movements so it's clear how the enemies are moving. This seems to be a bit more fair in terms of time sharing for all the actors and makes the queue position a bit less important.&lt;/p&gt;
</content:encoded></item><item><title>Kogmind Devlog #4</title><description>Dealing with some weird rendering issues</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Mon, 15 Jun 2020 00:00:00 GMT</pubDate><guid isPermaLink="true">kogmind_2020-06-15.html</guid><content:encoded>&lt;p&gt;I was using a fixed seed during the development up until now for the RNG but I thought it would be a good time to start seeing how different seeds affect level generation and weapon rolls. So I started randomizing the seed for the RNG but I also log the selected seed in case I need to reproduce something.&lt;/p&gt;
&lt;p&gt;Yesterday I wrote about the ranged targeting line running through walls. It was replacing the wall tiles completely and looked a bit weird so I decided to use the overlay rendering layer to render the targeting line. I also changed the background to green with some transparency so that the wall tiles can be seen. This makes for a better visual.&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/km20200615.png"&gt;/img/km20200615.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;With the panning implementation the viewport updates needed to be changed and this has caused some new issues that I discovered today. When the player was alternating directions per turn (left, right, left, right,..) the viewport would update before the level rendered and produced a perception of sluggish rendering. I moved the viewport update to happen after the level rendered in the scheduler tick.&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/km7.gif"&gt;/img/km7.gif&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Another annoying bug I introduced by trying to be clever and not rendering cells that are not in FoW caused some quirks. Pay attention to the corridor on the middle left (the last one before the void). As the player moves down it looks like it’s replicating itself to become a thick wall.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; if skipFow {

     target[y][x].illumination = illumination

 } else {

     if game.level.fog[y + viewPort.y][x + viewPort.x]  {

         target[y][x].illumination = illumination

     } else {

         //return //this is wrong and causes tiles to hang around

         target[y][x].illumination = 0 //this is correct

     }

 }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a href="/img/km8.gif"&gt;/img/km8.gif&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;It took quite a while until I understood what was causing the issue as I was thinking that some how a viewport update was getting out of sync with a render call.&lt;/p&gt;
</content:encoded></item><item><title>Kogmind: Devlog #3</title><description>Fixing animations, adding the first neutral bot, bug bashing</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Sat, 13 Jun 2020 00:00:00 GMT</pubDate><guid isPermaLink="true">kogmind_2020-06-13.html</guid><content:encoded>&lt;p&gt;With the new animation layer now in place I thought that I’d tweak the animations a bit more. The object explosion animation was not fading out properly so I added a color lerping function that fades the background from the explosion color to black. This makes for a better, more realistic effect.&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/km9.gif"&gt;/img/km9.gif&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;All the animation related code was living in the BeamBlaster class as it was convenient to modify stuff, I moved those to their respective classes. Not much problems since no refactoring really required for this reorganization.&lt;/p&gt;
&lt;p&gt;Next up was setting the scene for more the first neutral bot. I had only implemented a concrete class for AI agents so I went ahead and extracted a protocol and a base class for NPCs. This process was pretty straight forward as XCode provides a way to automatically rename things across the project. An interesting swift quirk is that array.removeAll(where:) doesn’t work with protocols. I had to refactor there into array = array.filter(where:) and all was good again. With the basics in place I implemented the WallRepairBot. The idea for this bot is that it will search the level for walls that were destroyed and now lead into the void and repair these. They become a wall themselves to it’s an ‘honorable’ mission for them, they are martyrs. Initially I thought that each bot would search the map to find a wall that needs repair but that turned out to be super slow and a noticable performance bottle neck as scanning the map to get a tile, then checking the bots to see if anyone is already decided to repair that tile takes a long time. This made me think that a class that is responsible for assigning work to these janitors of the level could be a better way to go. I also set up some code that keeps tracks of the tiles that are destroyed so I don’t have to scan the whole level each turn. This architecture also requires the need for synchronization between the bots as they are racing to find a tile to repair. After some play testing I realized that assigning a wall to repair to an agent also needs some additional checks as the player may kill the bot assigned to that task and the BotMind should reassign that repair task to another bot if that happens.&lt;/p&gt;
&lt;p&gt;A funny bug I found was that when I destroyed a floor a repair bot would go there and build a wall. The reason was that I wasn’t filtering based on the tile type that was destroyed and adding them all to the destroyed objects list. It was an easy fix but I did chuckle when I first saw it.&lt;/p&gt;
&lt;p&gt;I also ran into an issue where the player was aiming a bot and even though the weapon had a 100% hit chance it was missing the bot and the bot continued along it’s path. I figured that the bot was being scheduled to move before the player but I was pretty certain that I had put the player as the first actor in the scheduler queue. After checking multiple places in the code I found a call from the older version of the scheduler that was shuffling the queue.&lt;/p&gt;
&lt;p&gt;I realized after watching some Cogmind videos that I wasn’t labeling the bots but just the props. I dived into get section and saw that Props were embedded into the level tile data but bots weren’t. So I had to given them their own labeling pass. There is an issue of overlapping labels that needs some thought on a good solution and is something that I’m not really keen on doing right now. It’ll have to wait in the backlog.&lt;/p&gt;
&lt;p&gt;Another issue was in tne fog reveal. If an unexplored area was behind a prop and not in the players FOV it would not be revealed even though most of the tiles around it would. This seemed inconsistent so I switched to revealing every tile that’s in the rectangle around the player within the fovRadius parameter. It’s way better like this.&lt;/p&gt;
&lt;p&gt;Caching for the FOV calls was in the back of my mind for some time now so I added that. You can cache it in definitely as props and walls get blown up so they change and adding something too sophisticated that recalculates based on this seemed overkill. The simple cache just keeps the calcuted values around for a single turn as there multiple calls to this function per turn and invalidates the cache after a move in the scheduler. I didn’t see a super gain in performance though as the calculations are pretty simple.&lt;/p&gt;
&lt;p&gt;A huge annoyance was the keyboard beeping after each key press because nobody was registered as a responder to the event. I spent a couple of hours a couple of days ago researching a solution for this but only got to a working one today. The trick was to override keyDown and not call the super method. Such a hacky workaround but gets the job done.&lt;/p&gt;
&lt;p&gt;I also added ammo tracking to the ranged weapon. Melee weapons don’t have ammo so they are a special case. I added the ammo status to the info pane and disabled ranged targeting if none of the weapons have any ammo.&lt;/p&gt;
&lt;p&gt;It’s amazing how many bugs related to clamping and out of bounds coordinates have surfaced in the last couple of days. Another on was when the roll for a ranged weapon failed a new target location selected randomly from the neighboring tiles could turn up to be a void tile and the npcs trying to navigate there would error out because a path could not be found. The fix was simple, just filter out those bad location before picking the new one.&lt;/p&gt;
&lt;p&gt;I also came across another issue where a cell that was illuminated could not be picked as a target because it was reported to not be in the LOS. Thid was happening because LOS is calculated using Bresenham and in some cases the line would need to pass through a neighboring wall tile and that was not considered to be in LOS. I solved this by changing the definition of LOS to be a cell in the FOV. With the the targeting line can sometimes appear to cross walls but that’s okay.&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/km10.gif"&gt;/img/km10.gif&lt;/a&gt;&lt;/p&gt;
</content:encoded></item><item><title>Kogmind: Devlog #2</title><description>Animation pipeline work, bugs</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Thu, 11 Jun 2020 00:00:00 GMT</pubDate><guid isPermaLink="true">kogmind_2020-06-11.html</guid><content:encoded>&lt;p&gt;I realized today that the animation pipeline that I have doesn’t support animations that need to overlap. Shooting a beam into a wall should trigger the wall destruction animation as soon as it hits the wall and fade out for the beam should play in parallel with the explosion animation. This meant rearchitecting the pipeline code into a daisy chain of animations triggering each other.&lt;/p&gt;
&lt;p&gt;I tried to get rid of the beep that happens when I press a key to move the player but had no luck. It’s happening because the view doesn’t support the key being pressed and is not registered as the first responder but I could not get it teamwork even after setting it to be the the first responder. Will look into this a bit more.&lt;/p&gt;
&lt;p&gt;Object destruction is now live👌 I also downloaded the animated gifs of some of the cogmind effect and will try to model the animations after those. I also want to look into sqaure aspect ratios for the textures as they seem to look a lot better.&lt;/p&gt;
</content:encoded></item><item><title>Kogmind: Devlog #1</title><description>Porting to macOS, Renderer work, scheduler updates</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Wed, 10 Jun 2020 00:00:00 GMT</pubDate><guid isPermaLink="true">kogmind_2020-06-10.html</guid><content:encoded>&lt;p&gt;Today I decided that a roguelike on an iPad doesn’t really work when it’s ascii based. Just because the symbols are too small to accurately touch on the screen and buttons on the touch screen are annoying to tap continously. You need a keyboard, period. I had the game working with Mac Catalyst but that just seemed weird, so I ported the code base to macos. I tried modifying the existing project in place but that lead to weird configuration errors so I just started a new macos project and copied over most of the code.&lt;/p&gt;
&lt;p&gt;I ran into issues with setting color on the tile textures due to NSColor not liking the color space when I used SKColor built in enum values so I had to create and instance for the coloring. Resizing the window was also much harder than I would have imagined but I got it working with some research. The rest was pretty straightforward substituting UIKit stuff with NS stuff. I had to do the keyboard input handling code again as that was also not compatible.&lt;/p&gt;
&lt;p&gt;I discovered some unfairness issues with the scheduler so I rewrote that part to use a credit based system instead of the future scheduling time line system. It looks to be a lot better now.&lt;/p&gt;
&lt;p&gt;I also had the chance to dive into the animation pipeline that runs async code sequentially. The trick was to use a dispatch group and a semaphore to coordinate the queued animations. I still feel like there is an issue with the delay timing in the animations like the sleep calls aren’t waiting the correct amount of time that I need to look into.&lt;/p&gt;
</content:encoded></item><item><title>Dungeon Generation Revisited</title><description>Some more on procedural dungeon generation</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Wed, 03 Jun 2020 00:00:00 GMT</pubDate><guid isPermaLink="true">dungeon-generation-revisited.html</guid><content:encoded>&lt;h2&gt;Dungeon generation&lt;/h2&gt;
&lt;p&gt;There are a couple of different ways I've seen around the web for dungeon generation for rectangular rooms&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Tunneler&lt;/li&gt;
&lt;li&gt;Relative Neighborhood graphs&lt;/li&gt;
&lt;li&gt;BSP&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;It's safe to say you can breakdown dungeon generation into 2 base components&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Room placement&lt;/li&gt;
&lt;li&gt;Room connection&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;Room placement&lt;/h3&gt;
&lt;p&gt;The placement can be done at a random fashion by generation of room at random x,y with random width and height. The coordinate selection can be normally distributed, the w/h generation can be normally distributed or have a gaussian distribution. It's likely that rooms generated this way will intersect. To deal with the you can either discard a room that overlaps with another room and continue generation until &lt;code&gt;MAX_TRIES&lt;/code&gt; or the desired number of rooms has been reached. Another method is to space out rooms until non are overlapping and discard any rooms that have &amp;quot;fallen off&amp;quot; the edge of the map.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;method 1 - discard overlapping rooms&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;for _ in 0...maxRooms {
    let w = Int.random(in: minRoomSize...maxRoomSize)
    let h = Int.random(in: minRoomSize...maxRoomSize)
    let x = Int.random(in: 0..&amp;lt;cols - w)
    let y = Int.random(in: 0..&amp;lt;rows - h)
    let newRoom = Room(id: roomId, xy: XY(x: x, y: y), wh: WH(w: w, h: h))
    roomId += 1
    let failed = rooms.contains { newRoom.intersects(other: $0) }
    if !failed {
        renderer.drawBox(x: x, y: y, w: w, h: h)
        rooms.append(newRoom)
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;method 2 - push out rooms until they don't intersect anymore&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;var touching = true
while touching {
    touching = false
    for i in 0..&amp;lt;numRooms {
        for j in (i+1)..&amp;lt;numRooms {
            let a = cells[i]
            let b = cells[j]
            if a.intersects(other: b) {
                touching = true
                var dx = min(a.bottomRight.x - b.topLeft.x + padding, a.topLeft.x - b.bottomRight.x - padding)
                var dy = min(a.bottomRight.y - b.topLeft.y + padding, a.topLeft.y - b.bottomRight.y - padding)
                if abs(dx) &amp;lt; abs(dy) {
                    dy = 0
                } else {
                    dx = 0
                }
                let dxa = Int(-dx / 2)
                let dxb = dx + dxa
                let dya = Int(-dy / 2)
                let dyb = dy + dya
                a.shift(dv: XY(x: dxa, y: dya))
                b.shift(dv: XY(x: dxb, y: dyb))
            }
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;Room connection&lt;/h3&gt;
&lt;p&gt;Connecting rooms can be done by connecting the current room with the one before it. You can have a X% chance of initiating the connection from the top of the room or the side of the room to add some flavor. This method guarantees that the dungeon is fully connected and usually as the number of rooms increase you get a cyclic connection structure which is more interesting than a non-cyclic structure. Using this method can lead to a direct connection from the start room to the end room. There are checks that could be implemented to mitigate this and the game mechanics may also give incentive to exploration to make this a non-issue. I call this the “n-1” connection/tunneler method.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;if !failed {
    renderer.drawBox(x: x, y: y, w: w, h: h)
    let newX = newRoom.centerX
    let newY = newRoom.centerY
    if rooms.count != 0 {
        let prevX = rooms.last!.centerX
        let prevY = rooms.last!.centerY
        if Int.random(in: 0...10) &amp;lt; 5 {
            horTunnels.append((x0: prevX, x1: newX, y0: prevY))
            vertTunnels.append((y0: prevY, y1: newY, x0: newX))
        } else {
            vertTunnels.append((y0: prevY, y1: newY, x0: prevX))
            horTunnels.append((x0: prevX, x1: newX, y0: newY))
        }
    }
    rooms.append(newRoom)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The example code just stores the coordinates of the halls that are created and doesn't store the connection graph but that pretty trivial to implement but it's not needed as the level map provides this data after the tiles are laid on the map.&lt;/p&gt;
&lt;p&gt;Another method of connecting the rooms is to use Relative Neighborhood Graphs. This is a subgraph of the Delauny Triangulation and tries to connect rooms that appear to be close and produce nice results. If this type of graph feels to strongly connected creating a MST for the rooms and then selectively adding X% percent of the RNG connections that may also yield good results.&lt;/p&gt;
&lt;h2&gt;Halls&lt;/h2&gt;
&lt;p&gt;The connecting halls them selves can either be straight, L shaped or meandering like a maze. Maze algorithms may lead to dead ends which may not be desirable but can easily be pruned (just remove any hall tile that surrounded by at least 3 empty tiles).&lt;/p&gt;
&lt;p&gt;&lt;em&gt;a map generated by random intersecting prune placement and n-1 tunneling&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/a.jpeg"&gt;img_bad7f5982307-1.jpeg&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;another map generated by the same algorithm as above (someone else wrote this, I saw their post on reddit in /r/roguelikedev but can't find it anymore so I can't properly credit them)&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/b.png"&gt;1.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;BSP made room placement with n-1 connection&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/c.png"&gt;2.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Maze based tunnelling&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/d.png"&gt;screen_shot_2020-05-23_at_10.29.49_pm.png&lt;/a&gt;&lt;/p&gt;
</content:encoded></item><item><title>Local dns server</title><description>how I setup my custom in house domain</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Wed, 01 Apr 2020 00:00:00 GMT</pubDate><guid isPermaLink="true">local-dns-server.html</guid><content:encoded>&lt;p&gt;I have a bunch of self hosted services running in containers on my docker host and it was getting pretty hard to keep track of which port was assigned to what. I wanted to setup an nginx proxy that would be the front end to all these services and also wanted to use human friendly addresses. The simple option would be to add all the hostnames to my &lt;code&gt;etc/resolv.conf&lt;/code&gt; file but I use 5 different devices daily and some of them don't even allow me to change that file. So I needed to run my own DNS server. The idea was to capture requests made to &lt;code&gt;*.dendiz.lan&lt;/code&gt; and resolve them to my docker host and forward all other requests to my usual DNS servers.&lt;/p&gt;
&lt;p&gt;DNS configs can be tricky but a project called coredns makes it very simple. The DNS itself is also a docker container which keeps things even cleaner. So I spun up a coredns container with following dns records file&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ORIGIN dendiz.lan.
@	3600 IN	SOA sns.dns.icann.org. noc.dns.icann.org. (
    			2017042745 ; serial
    			7200       ; refresh (2 hours)
    			3600       ; retry (1 hour)
    			1209600    ; expire (2 weeks)
    			3600       ; minimum (1 hour)
    			)

    3600 IN NS a.iana-servers.net.
    3600 IN NS b.iana-servers.net.

*.dendiz.lan.     IN A     192.168.0.60
          IN AAAA     192.168.0.60
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and the config file&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;dendiz.lan:53 {
    file db.dendiz.lan
    errors
    log
}

. {
    any
    forward . 8.8.8.8:53
    errors
    log
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;so any requests to dendiz.lan are resolved using my dns record file which uses a wildcard to resolve them to my docker hosts ip. I built the executable, created the docker image and started the container. Ran a bunch dig requests like&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;dig @localhost -p 53 www.dendiz.lan A
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and got back an answer section. Nice! Next up creating the proxies... I found a nice project called nginx proxy manager that provides a web interface for creating proxy configs which also runs in a container. I installed that and created proxy hosts for all the services that I use and everything was looking good. one caveat with this setup is that I had manually set the DNS servers in the network settings on my devices. The solution to this issue was to configure my routers internet settings and put in my DNS server as the first server to use. Now all the devices that use DHCP can resolve my local domain.&lt;/p&gt;
</content:encoded></item><item><title>A simple query evaluator</title><description>Evaluating a query against a graph of objects</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Mon, 27 Jan 2020 00:00:00 GMT</pubDate><guid isPermaLink="true">a_query_evaluator.html</guid><content:encoded>&lt;p&gt;For a feature that I’m building I needed to code up a parser that will take in a
JSON structured query and run it against a graph of objects to get the ones that
match.&lt;/p&gt;
&lt;p&gt;The query format is similar to the MongoDB query format and looks something like
this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;let input:[String: Any] = [

&amp;quot;p1&amp;quot;: 1,

&amp;quot;or&amp;quot;: [[&amp;quot;p2&amp;quot;: 1], [&amp;quot;and&amp;quot;: [ [&amp;quot;p5&amp;quot;: 5], [&amp;quot;p3&amp;quot;: 3]]]]

]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This means I need the nodes that have p1 property set to 1 AND either p2 set to 
1 or p5 and p3 set to 5 and 3 respectively.&lt;/p&gt;
&lt;p&gt;The format of the query is already a AST so just need to traverse it and 
evaluate the result as we do the traversal.&lt;/p&gt;
&lt;p&gt;Here’s an example node&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;let model:[String: Int] = [

&amp;quot;p1&amp;quot;: 1,

&amp;quot;p2&amp;quot;: 2,

&amp;quot;p3&amp;quot;: 4,

&amp;quot;p5&amp;quot;: 5

]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;Solution&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Here’s the traversal code (simplified for the article but the main idea is there)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;func resolve(input: [String: Any], model: [String: Int]) -&amp;gt; [Bool] {

 return _resolve(input: input, model: model).allSatisfy { $0 }

}

func _resolve(input: [String: Any], model: [String: Int]) -&amp;gt; [Bool] {

 var results = [Bool]()

 for (key, value) in input {

  if let value=value as? Int {

   let result = model[key] == value

   results.append(result)

 }

switch key {

case &amp;quot;$and&amp;quot;:

 if let value = value as? Array&amp;lt;[String: Any]&amp;gt; {

  let result = value.allSatisfy() {

   _resolve(input: $0, model: model)

  }

  results.append(result)

  } else {

   print(&amp;quot;$and needs an array&amp;quot;)

   throw Error

  }

case &amp;quot;$or&amp;quot;:

 if let value = value as? Array&amp;lt;[String:Any]&amp;gt; {

  let result = value.contains {

   _resolve(input: $0, model: model)

  }

  results.append(result)

 } else {

  print(&amp;quot;$or needs an array&amp;quot;)

  throw Error

 }

default:

 break

 }

}

return results

}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With the example model the result will be false. But change the query to&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;let input:[String: Any] = [ &amp;quot;p1&amp;quot;: 1, &amp;quot;or&amp;quot;: &amp;quot;p2&amp;quot;: 1], [&amp;quot;and&amp;quot;: [ [&amp;quot;p5&amp;quot;: 5], [&amp;quot;p3&amp;quot;: 4]] ]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and it will be true.&lt;/p&gt;
&lt;p&gt;The idea here is to reduce each sub query in the $or/$and keys down to a single 
boolean value and at the end reduce that down to a single value as the top level
predicates have an implied and.&lt;/p&gt;
&lt;p&gt;so&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;let input:[String: Any] = [

&amp;quot;p1&amp;quot;: 1,

&amp;quot;or&amp;quot;: [[&amp;quot;p2&amp;quot;: 1], [&amp;quot;and&amp;quot;: [ [&amp;quot;p5&amp;quot;: 5], [&amp;quot;p3&amp;quot;: 4]]]]

]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;becomes&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;let input:[String: Any] = [

&amp;quot;p1&amp;quot;: true,

&amp;quot;or&amp;quot;: [[&amp;quot;p2&amp;quot;: 1], [&amp;quot;and&amp;quot;: [ [&amp;quot;p5&amp;quot;: 5], [&amp;quot;p3&amp;quot;: 4]]]]

]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;then&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;let input:[String: Any] = [

&amp;quot;p1&amp;quot;: true,

&amp;quot;or&amp;quot;: [true, [&amp;quot;and&amp;quot;: [ [&amp;quot;p5&amp;quot;: 5], [&amp;quot;p3&amp;quot;: 4]]]]

]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;then&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;let input:[String: Any] = [

&amp;quot;p1&amp;quot;: true,

&amp;quot;or&amp;quot;: [true, true]

]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;next&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;let input:[String: Any] = [

&amp;quot;p1&amp;quot;: true,

&amp;quot;or&amp;quot;: true

]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and finally the top level is calculated as true.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
&lt;/code&gt;&lt;/pre&gt;
</content:encoded></item><item><title>RK61 keyboard review</title><description>first time using a 60% keybaord</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Thu, 15 Aug 2019 00:00:00 GMT</pubDate><guid isPermaLink="true">rk61-keyboard.html</guid><content:encoded>&lt;p&gt;I was quite skeptical about getting a 60% keyboard just because it doesn’t provide the arrow keys which some programs just assume. But using MacOS which does have global Emacs bindings across the OS encouraged me to go ahead and try one.  There are quite a lot of models available on amazon including brands keyboards like Vortex, etc but I wanted a cheaper no-name keyboard with cherry switches, as I think the switches are the most important part of a keyboard. I found the RK61 to be a great fit for this. Cherry Brown MX switches and RGB lights. Even though I would never use RGB as I’m not a high school teenager. It’s a good portable keyboard and the typing feel is great. The missing arrow keys take some time to get used to, but it is doable. There is function key that makes the alt/ctrl to the right of the space bar double as arrow keys when needed. The up arrow coincides with the forward slash key which is a bummer as it is one of the most frequently used keys for me. The bluetooth connection procedure is a bit cumbersome as there is really no proper indication of the pairing status. I always have to refer to the user manual to figure out how to pair it. It does support different bluetooth profiles for different computers but the instructions seemed complicated so I didn’t bother with them. Overall it’s an OK keyboard but it didn’t become my go to keyboard. I got it for 65$ on Jun 16, 2019 from Amazon.&lt;/p&gt;
</content:encoded></item><item><title>Yarasali gece</title><description>🇹🇷Gece gece guzel bir macera</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Wed, 14 Aug 2019 00:00:00 GMT</pubDate><guid isPermaLink="true">yarasali_gece.html</guid><content:encoded>&lt;p&gt;Gece 10:30 gibi garaj kapisini kapatiyim dedim, artik gec oldu yatacaz. 
Hava 100 bin derece oldugu icin garaj kapisi yatana kadar acik duruyor. 
Duvarda golge gibi bir sey gordum, gecti gitti. Dedim “Eh gene o buyuk sivri 
sinek benzeri boceklerden girmis iceri, neyse…”. Ev halki yatmaya hazirlik 
yapiyor, ben de bilgisayarin basina oturdum, youtube’dan bir iki video download 
edip plex’e koyacak olan bir script yaziyordum, ona bakacagim. Bir 10 dakika 
sonra tekrar bir golge oldu duvarda ve kayboldu gitti. Onemsemedim pek, iseme 
baktim. Derken onumden serce boyutunda siyah bir sey sorti yaparak gecti, 
“anani skym, noluyor” dedim; kendimi zor attim sandalyemden. Adrenalin bir anda
tavan yapti. Yerde Ada’nin bir cocuk kitabi vardi silah olarak onu kaptim ve
odanin disina kactim. Yuzumu tekrar odaya donmemle beraber yaratik ucarak 
onumden gecti ve ust kata dogru gitti. O sirada daha net bir bicimde gorme
firsatim oldu ve anladim ki iceri yarasa girmis. Hic sevmem bu tarz ucan 
fareleri cunku kuduz vs. gibi hastalik tasima ihtimalleri var.&lt;/p&gt;
&lt;p&gt;Aklima ilk gelen  Ada’nin odasina girerse yan basariz oldu ve hemen ust kata ciktim. Tam
merdivenin agzina gelmistim yarasayi salona ucarken gordum. Firsat bu firsat 
diyip Ada’nin orasinin kapisini kapattim ve bizim yatak odasina dogru yoneldim. 
Burcin’e “iceri yarasa girmis” dedim ve kapiyi cektim. Ust katta isiklar kapali, 
alt kattan gelen az biraz aydinlanma ile zar zor goruyorum onumu. Bir yandan da
surekli tavani scanliyorum ucup bu tarafa gelir diye. Bir sekilde kendimi 
mutfaga attim ve kapilarini kapattim. Acele ile telefonu asagida birakmistim ama
neyse ki iPad mutfak masasinin uzerinde duruyor. Baktim hemen yarasa nasil def
edilir diye. Bir yere konmasini bekleyin, uzerine bir kapak yapin, sonra da
alttan karton ile alip atin diyor. Oldu amk!&lt;/p&gt;
&lt;p&gt;Kek uzerine koymak icin plastik 
bir kapak gibi bir sey vardi onu aldim. Bu sirada Burcin geldi iceri, o da ayni
siteye bakmis ayni seyleri soyluyor. Mutfak kapsini araladim gozlerim yarasa 
ariyor. Stresten deli gibi terlemeye basladim. Sanki gerilim filmindeyim, her an
bir yerden bir katil cikacak ve bicagi saplayacak gibi. Surekli sagimi, solumu, 
onumu, arkami kolluyorum. Alexa’ya isiklari ac diye fisildadim. Ee cocuk uyuyor, 
bir yandan da onu uyandirmamanin gayreti icindeyim. Ben salona bakiyorum, burcin
arka odalara bakiyor. Gorunurde herhangi bir sey yok. Derken alt kattan son surat
yukariya dogru bir sey geldi, bir tur sorti yapti bana dogru, sonra tekrar alt 
kata dogru geri dondu. “Anani” diyemeden oldu bitti butun bunlar. Alt kata indigini
gorunce Burcin’e soyledim ve merdivenlerin ilk kismini inerek ana giris kapisinin 
orada elimde kalkanim konumlandim.&lt;/p&gt;
&lt;p&gt;Aklima evin kapisini acip oradan disari cikmasini 
saglamak geldi. Bir yandan da surekli alt kat koridoruna bakiyorum. Bir iki kere 
yukari cikma tesebbusunde bulundu elimdeki kapak ile kistirmaya calistim ama engel 
oldugunu anlayinca geri donup tekrar asagiya iniyor. Biraz daha geri cekildim ki
cikis kapisini bloklamayayim ama bu sefer de nereye dogru uctugunu goremiyorum.&lt;/p&gt;
&lt;p&gt;Bir 10 dakika bu sekilde bekleme ile gecti ve yaratik ucmaz oldu.
Oyle olunca “ben asagiya iniyorum” dedim ve elimde kalkanim yarasanin pesinden 
gittim. Surekli arkami kolluyorum, terden t-shirtum siril siklam oldu. Calisma 
odasina girdim. Tavana bakiyorum, asilacagi yada konacagi bir yer yok. Odanin 
dort bir yanina baktiktan sonra ciktim ve kapisini kapattim. Orasi temiz. Sirada 
ivir zivir esyanin durdugu kucuk oda var. O odaya girdim. Bir ton sacma sapan 
esya, valizler, kamp sandalyesi, kutular filan var her yerde. Bunlarin herhangi
birinin icine girmis olabilir diye dusunuyorum ve tetikteyim. Giysi dolabinin 
kapisi acik, oraya da girmis olabilir. Dolabin surgulu kapilarindan birini siper 
alarak elimdeki kalkan ile giysileri durtukledim. Icerden kanat cirpmalari ile 
firlayacak diye bekliyorum ama bir sey olmadi. Biraz daha etrafi inceledikten 
sonra o odadan da cikip kapisini kapattim.&lt;/p&gt;
&lt;p&gt;Sirada camasir odasi var. Icerisi 
karanlik ve saklanabilecegi bir suru bosluk mevcut. Kapisini aralayip elimdeki 
nesne ile isik dugmesine bastim. Aralik kapidan iceriyi suzuyorum. Gozume bir 
sey carpmiyor. Saklanabilecegi o kadar cok yer var ki, acaba hic kasmayip 
kapisini cekip artik kac gun ac sussuz dayaniyorsa bu meretler orada kaderine 
biraksam mi diye dusunuyorum. Kafami iceri uzatip son bir kez daha bakip cektim
kapsini.&lt;/p&gt;
&lt;p&gt;Sirada kucuk tuvalet var. Burasi kolay, 30 saniye bir suzdum iceriyi 
orada yoktu. Son yer garaj. Kapiyi acip isiklari actim ve aninda iceride daire 
cizerek ucmaya basladi. Bir “oh” cektim, en azindan buldum diye. Garaj buyuk 
oldugu icin uzerime dogru ucma ihtimali de dusuk o yuzden rahatim. Bir iki
turdan sonra garajin dis kapisinin uzerine kondu. Bu arada garaj anahtarinin 
dugmesine basip garajin dis kapisini actim. Ses olunca tekrardan ucusmaya 
basladi. Deli danalar gibi tur atip duruyor garajin icinde. Burcin’e seslendim 
“dis kapiyi kapat, buldum!” diye. Bir iki tur daha atip bir disari dogru cikti 
ama tekrar girdi iceri. “Hay senin anani avradini” diye kufur ediyorum icimden.
Neyse bir deneme ile daha disari cikti ve gecenin karanliginda kayboldu gitti.&lt;/p&gt;
</content:encoded></item><item><title>Calculation of support/resistance zones</title><description>A simple clustering method for calculation of support/resistance zones in price data</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Tue, 23 Jul 2019 00:00:00 GMT</pubDate><guid isPermaLink="true">efficient_calculation_of_support_resistance_zones.html</guid><content:encoded>&lt;p&gt;support/resistance zones are quite essential when trading breakouts. Support is 
a line below the price on the charts that the price bounced back from a couple 
of times. Resistance is the same, but above the price. When a human looks at a 
chart, it’s pretty easy for them to see these points on the chart:&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/ecosrz1.png"&gt;/img/ecosrz1.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;the shaded are is a support/resistance zone, as the price tries multiple times 
to go past that point and succeeds with that long green candle. How to get the 
computer to recognize these points it an interesting exercise in programming. 
The logic is this:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;gather all open, high, low close prices in an array and sort them.&lt;/li&gt;
&lt;li&gt;define a parameter, called epsilon that will be the sensitivity for the zone.&lt;/li&gt;
&lt;li&gt;start from the first price and group all prices less than epsilon away from this in a list.&lt;/li&gt;
&lt;li&gt;remove the added prices from the original array and continue group the remaining prices.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;in the end you will have a list of lists. The more items in the list, the 
stronger the support/resistance around that area.&lt;/p&gt;
&lt;p&gt;The worst case running time for the above algorithm is n^2 if all the prices are 
more than epsilon away from each other, which is not very good. So we need to 
improve on that.&lt;/p&gt;
&lt;p&gt;We can build the groups as we are iterating the original array like this:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;maintain a list of groups, initialized with a single group containing the first price.&lt;/li&gt;
&lt;li&gt;as we are iterating over the array, if the current element is less than epsilon away from the head&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;of the group we add it to that group. Otherwise we create a new group and add it into that group.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Collections.sort(data);

        SuperList&amp;lt;SuperList&amp;lt;Double&amp;gt;&amp;gt; groups = new SuperList&amp;lt;&amp;gt;();
        groups.add(new SuperList&amp;lt;&amp;gt;());
        groups.get(0).add(data.get(0));
        for (int i = 1; i &amp;lt; data.size(); i++) {
            SuperList&amp;lt;Double&amp;gt; group = groups.getLast();
            Double x = data.get(i);
            if (Math.abs(x - group.get(0)) &amp;lt; epsilon) {
                group.add(x);
            } else {
                SuperList&amp;lt;Double&amp;gt; newList = new SuperList&amp;lt;&amp;gt;();
                newList.add(x);
                groups.add(newList);
            }
        }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I finally had the chance to plot the results of this, so I updated the post:&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/ecosrz2.png"&gt;/img/ecosrz2.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The red zones are the resistance which is all tuples with price above the last 
close price and the green zones are the support zones.&lt;/p&gt;
</content:encoded></item><item><title>N-Gram sentence splitting</title><description>Using n-grams to figure out multiple item insertion to a list</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Sat, 29 Jun 2019 00:00:00 GMT</pubDate><guid isPermaLink="true">ngram-sentence-split.html</guid><content:encoded>&lt;p&gt;&lt;strong&gt;The Idea&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;one of the biggest annoyences in adding items to reminder app using voice is that the agent can't figure out if there are multiple items in that utterance. Here is an example:&lt;/p&gt;
&lt;p&gt;&amp;quot;add bananas oranges and lemons to my list&amp;quot;&lt;/p&gt;
&lt;p&gt;on the current (12) version of iOS this will result in a single item with the content &amp;quot;bananas oranges and lemons&amp;quot; to be added. This is pretty annoying. If we assume we have some magical NLP that figures out the content it should not be that hard to figure out there are multiple items to be added to the list in this utterance. Here is very simple way of achieving this:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;assume we have a dicitionary of all the words/items without stop words.&lt;/li&gt;
&lt;li&gt;create all N-grams of the input string, starting with the number of words in the sentence for the N in the first N-gram&lt;/li&gt;
&lt;li&gt;search the dictionary for the words in the N-gram list, if found add it to the result list and remove from input string.&lt;/li&gt;
&lt;li&gt;decrease the number N and repeat the search until N = 0&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;For the example above let's say our dictionary is:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;bananas
banana
oranges
orange
lemons
lemon
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Our first n-gram will be&lt;/p&gt;
&lt;p&gt;&lt;code&gt;[&amp;quot;bananas oranges and lemons&amp;quot;]&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;This is not in the dictionary so nothing to do.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;[&amp;quot;bananas oranges and&amp;quot; , &amp;quot;oranges and lemons&amp;quot;]&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Nothing from this list in the dictionary so continue.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;[&amp;quot;bananas oranges&amp;quot;, &amp;quot;oranges and&amp;quot;, &amp;quot;and lemons&amp;quot;]&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;...&lt;/p&gt;
&lt;p&gt;&lt;code&gt;[&amp;quot;bananas&amp;quot;, &amp;quot;oranges&amp;quot;, &amp;quot;and&amp;quot;, &amp;quot;lemons&amp;quot;]&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;3 of the items in the list our in our dictionary so we can add them as items in our result list.&lt;/p&gt;
&lt;p&gt;How is this different from just splitting based on a space character? Well there are some words like &amp;quot;orange juice&amp;quot; that have to be a single item in the result list. If we did have this in the input sentence then we would have detected it in the 2-gram phase
and added it to the result list.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Some implementation optimization thoughts&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;First thing is that when creating the N-grams we are using a sliding window of decreasing lengths. So instead of creating the N-grams for each index from scratch each time, adding the next word to the window and removing the first will yield a linear time algorithm for constructing the list.&lt;/p&gt;
&lt;p&gt;Second thing is that there is no need to keep the whole dictionary in memory. Using a bloom filter will be enough because we can make our decision based on failure to be contained in the set.&lt;/p&gt;
</content:encoded></item><item><title>Build Pipeline duration calculation</title><description>calculating the length of jobs with parallel execution</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Thu, 09 May 2019 00:00:00 GMT</pubDate><guid isPermaLink="true">build-pipeline-duration.html</guid><content:encoded>&lt;p&gt;While browsing the GitLab pipeline documentation I came across this:&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/58af854b801d0.png"&gt;/img/58af854b801d0.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;this got me thinking about how this calculation could be done. I'm assuming here that there is an unlimited number of CPUs so tasks can run in parallel.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;sort the input pair by arrival time&lt;/li&gt;
&lt;li&gt;push the first pair on a stack&lt;/li&gt;
&lt;li&gt;for each of the remaining pairs do these&lt;ol&gt;
&lt;li&gt;if current pair start &amp;lt; stack top end push it on the stack&lt;/li&gt;
&lt;li&gt;else update the stack top ending time to cur end time&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;at the end of this the stack will contain the mutually exclusive intervals. Now iterate over this stack and subtract end time from the start time and sum up the results.&lt;/p&gt;
&lt;p&gt;So for the input&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; A (1, 3)
 B (2, 4)
 C (6, 7)

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;which is &lt;code&gt;[(1,3), (2,4), (6,7)]&lt;/code&gt; and sorted, push the first one on the stack&lt;/p&gt;
&lt;p&gt;&lt;code&gt;S = (1,3)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;next item is &lt;code&gt;(2,4)&lt;/code&gt; and its start is &amp;lt; stack top end so update the stack top&lt;/p&gt;
&lt;p&gt;&lt;code&gt;S = (1,4)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;next item is &lt;code&gt;(6,7)&lt;/code&gt; and its start is &amp;gt; stack top so push it&lt;/p&gt;
&lt;p&gt;&lt;code&gt;S = (1,4) (6,7)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;no more elements left to pop the stack&lt;/p&gt;
&lt;p&gt;element (6,7)-&amp;gt;difference 1, sum 1&lt;/p&gt;
&lt;p&gt;&lt;code&gt;S = (1,4)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;element (1,4)-&amp;gt;different 3, sum 4&lt;/p&gt;
&lt;p&gt;&lt;code&gt;S = []&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;total duration is 4.&lt;/p&gt;
&lt;p&gt;Here is the java code:&lt;/p&gt;
&lt;p&gt;&lt;a href="buildpipeline.java"&gt;buildpipeline.java&lt;/a&gt;&lt;/p&gt;
</content:encoded></item><item><title>TechScan DevLog 2018-12-11</title><description>Techscan updates</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Tue, 11 Dec 2018 00:00:00 GMT</pubDate><guid isPermaLink="true">techscan_devlog_2018-12-11.html</guid><content:encoded>&lt;p&gt;So some more progress this week, mostly optimization to existing jobs – I
needed to get things running smoothly before I can concentrate on the new
features I have planned. The issues for the new features are on gitea waiting
to be tackled but accumulating too much technical debt makes in harder in the
long run to get a smooth running system. Here’s a summary of this devlog:&lt;/p&gt;
&lt;h2&gt;Bugfixes&lt;/h2&gt;
&lt;p&gt;– stoch overfiring
– fix premature exit in predictions&lt;/p&gt;
&lt;h2&gt;Optimization&lt;/h2&gt;
&lt;p&gt;– Perf Eval runs in parallel now
– parallel scans, ohlcv
– Module run optimizations: don’t run if no new data, don’t sync if no data on
IEX
– Skip untriggered events in perf eval
– Class property connections on dao
– Parallel correlation proc
– sql2o batching sux, implement grouped insert
– Save ohlcv to KV store for faster access
– track last scan date
– extract exchange param (job pipeline optimization)&lt;/p&gt;
&lt;h2&gt;Experiments&lt;/h2&gt;
&lt;p&gt;– Turtle exit for predictions
– BBSqueeze detection change&lt;/p&gt;
&lt;h2&gt;New features&lt;/h2&gt;
&lt;p&gt;– Bollinger/ma/ohlcv in KV store, display charts for scans&lt;/p&gt;
&lt;h2&gt;Bugfixes&lt;/h2&gt;
&lt;p&gt;First off, a couple of bug fixes. Finding bugs in this system notoriously
difficult as testing isn’t done on behaviors but generated data. Verifying the
data against a source of truth is quite time consuming and I only have a
certain amount of time I can dedicate to manual testing. One of the defects
that caught my attention this week was stochastic signals firing for both
oversold and overbought on the same day, which is absolute non-sense. At first
I thought it a date issue because the symbols I checked were from the top
gainers and had huge increases that could pull up the stochastic from oversold
to overbought in a day. My estimate was that the stochastic was oversold on day
T-1 and became overbought on day T. But deeper investigation and hours of
debugging showed that this was not the case. The triggering code for the
indicator is fairly straight forward&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;if (def.srt.contains(“overbought”) &amp;amp;&amp;amp; d[len – 2] &amp;lt; ob &amp;amp;&amp;amp; ob &amp;lt; d[len – 1]) {

return new ScanResult(data, def);

}

if (def.srt.contains(“oversold”) &amp;amp;&amp;amp; d[len – 2] &amp;gt; os &amp;amp;&amp;amp; os &amp;gt; d[len – 1]) {

return new ScanResult(data, def);

}

if (def.srt.contains(“neutral”) &amp;amp;&amp;amp; (d[len – 2] &amp;gt; ob &amp;amp;&amp;amp; ob &amp;gt; d[len – 1]) ||

(d[len – 2] &amp;lt; os &amp;amp;&amp;amp; os &amp;lt; d[len – 1])) {

return new ScanResult(data, def);

}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There is subtle bug in this code even though it looks quite simple. The 3rd
condition: a &amp;amp; b | c. The precedence order is equal for both operators so it
would trigger for both overbought and oversold&lt;/p&gt;
&lt;p&gt;￼&lt;/p&gt;
&lt;p&gt;The correct code is a &amp;amp; (b | c). Yet again the great syntax of Java produces a
bug that is easy to miss and will make you go blind in the process. Well it did
cost a couple of hours but at least it was an easy fix.&lt;/p&gt;
&lt;p&gt;Another bug that I introduced during the performance evaluator developments
came to light after I tackled some optimization tasks on that module. I was
expecting way more scans to be score than there were which led me to
investigate the scoring code that revealed a premature exit from the evaluation
loop. A misplaced return statement instead of a continue statement was causing
the loop to terminate early and not score the remaining predictions. Another
easy fix at least.&lt;/p&gt;
&lt;h2&gt;Optimizations&lt;/h2&gt;
&lt;p&gt;Optimizations were the meat of this weeks work. Originally I thought that
running the modules on a single thread with good caching would suffice in terms
of performance but I was wrong.&lt;/p&gt;
&lt;p&gt;So I went ahead to parallelize the portions of the modules that made sense.
These were&lt;/p&gt;
&lt;p&gt;– Performance Evaluations
– Scans
– Correlations processing&lt;/p&gt;
&lt;p&gt;Thanks to Java 8 parallel streams this turned out to be quite easy. I just had
to make sure that critical sections in code were atomic, and used classes that
were thread safe. One aspect to take into consideration is to preserve the
locality of the cache and not to evict items that from the cache only to have a
second loop query that item again. So the order of processing is important.&lt;/p&gt;
&lt;p&gt;symbols -&amp;gt; combos -&amp;gt; dates&lt;/p&gt;
&lt;p&gt;will make sure that the cache contains the symbol data ready to be processed
and will not run a DB query. Initially I had just parallelized the dates loop
but that loop doesn’t contain enough data to make it worth while. The CPU cores
were only busy at 60% which is not ideal. So I moved the parallel streaming up
2 levels to the symbol level which now utilized all cores at 100%. PerfEval and
Scans use the same code base so that was a bit easier than the Correlation
Processor that needed some extra attention due to memory issues. I operate
under a RAM constraint (because I need to keep server costs to a minimum) so I
needed to implement a specific cache for correlation calculations that just
holds the last 30 closing prices and symbols.&lt;/p&gt;
&lt;p&gt;The seconds area of optimization was for syncing data from IEX and running
scans on the synced data. I currently orchestrate the module jobs via Jenkins
and the pipeline only supports triggering based on a fail/success return code.
This means that every time I run a sync job, a scan job will trigger on success
– even if there is no new data. It will just calculate the same results over
and over again. This wasn’t really a problem when the scan job only took a
couple of minutes to complete with 1 years worth of data but it doesn’t work
with 5 years of data. So I implemented a check on the scan module that will
only run the scans if the latest scan date for a symbol is less than the latest
OHLC date. The job will still run but it will just skip the scans so it takes
only about 3 – 4 minutes to complete as opposed to 1 – 1.5 hours. Another issue
is with IEX not clearly defining when they will update the API with the days
stock data. Previously I was fetching the data at 7 pm and 11 pm local time and
processing the data even if the data was old (the one at 7 pm, they would have
the data updated by 11 pm for sure). But this means that the new scans/signals
are not shown until almost 12 am which is less than ideal. I didn’t want to
check every hour or two because it would trigger the whole job pipeline and
it’s a lot of data to download. My solution to this came after I discovered an
API endpoint that listed the symbols, which had a date field that showed the
time it was updated. Why didn’t I just check a symbol for the last date?
because at any given date a symbol may not be traded. The probability that AAPL
not being traded is rather low, but still I prefer a robust solution if there
is one. The cost of making this API call to the symbol list is low, so now I
poll every hour for new data between 4 pm – 11 pm on the week days. There is
still no way to abort the pipe line without a failure on Jenkins but with the
scan checking this is now less of a problem.&lt;/p&gt;
&lt;p&gt;A huge pain point was the duration of the Performance evaluation. I realized
this week that I was doing a lot unnecessary processing that was causing the
job to take forever. I only needed to calculate performance for the scans that
had been triggered for that symbol, and I was running all the scans for that
symbol. Duh!&lt;/p&gt;
&lt;p&gt;￼&lt;/p&gt;
&lt;p&gt;With a new filter that skips scans that are not relevant and parallel
processing the performance evaluation now takes 1 hour to complete which is
reasonable. Even though I won’t be running this job that often it kind of
became my holy grail to optimize this. So looking back at the comments on the
issue on gitea the first iteration resulted in 1K scored scans and 6K unscored
(this was due to the bug I mentioned previously, which at the time I didn’t
know). This was way to little so I thought I’d throw more data at it and
increased the data interval to 5 years from 1. This increase resulted in 2.4K
vs 6K. Still not good enough. After fixing the premature loop termination issue
the final ratio is 5K/6K which to me looks OK. It is possible that some scans
just didn’t occur frequent enough to be scored.&lt;/p&gt;
&lt;p&gt;The DAO layer also got some love this week. I had previously implemented the
DAO’s in a way that each operation would open a new connection to the DB even
though this is not good practice. I didn’t want to integrate a connection
pooling solution as the processes are not long lived so I just refactored the
connection objects to be reused class wide. I’m using a relatively new SQL
library called sql2o which has a nice plain API for DB operations but the way
they implemented batch insertions is not optimal. It just wraps the inserts
around a transaction and still inserts each row individually. MySQL’s grouped
insert performs much better than this so I refactored batch inserts to generate
a grouped insert query. This increased performance of the inserts quite a bit,
even though I didn’t measure by how much.&lt;/p&gt;
&lt;p&gt;After examining the MySQL advisor on PhpMyAdmin I saw that it complained about
a lot of row sorting. The culprit was that each query to the OHLCV table needed
a sort by date for the caching and range query to work properly. The problem
here is that I already got the data sorted from the data API and lost that
information after the insertion into the OHLCV table. I though about getting
rid of the table and querying from the JSON data directly but some of the
functions in the TOP module and market overview module take advantage of this
table to reduce the amount of code and off load processing to the database, so
the table had to stay. I stored the API response in K/V store only for query by
the ChartData component for caching. I also saw that selecting the last scan
date from the scan_result table for doing full table scans so I save those in
the K/V store too. This type of optimization can be good for performance but
it’s important not to let these data points get out of sync. I also implemented
a fall back mechanism to querying the DB if the value was not found in the K/V
store. This case can occur if a symbol is introduced and the last scan date is
not yet inserted.&lt;/p&gt;
&lt;p&gt;The Jenkins job pipeline also needs to be separated by exchange to reduce the
amount of processing. This can be achieved by extracting the exchange parameter
as a CLI parameter to the jobs. No need to run scans for IEX after BFX data
synced, just run the BFX scans&lt;/p&gt;
&lt;p&gt;￼&lt;/p&gt;
&lt;h2&gt;Experiments&lt;/h2&gt;
&lt;p&gt;I decided to change the way the prediction checker scores scans. My initial
implementation was exit on +/- 2 x ATR of the symbol. This yielded around 50%
average scores. Next I tried a 15 period low/high exit strategy. There is
really no correct way of doing this, as strategy is very personal. My reasoning
was that on an up trend the 15 period low would still decent gains and on a
down trend it would exit quite early to cut losses. After the performance
evaluation runs the average score was 0.23959762958591568 and average error was
0.17946781069881107 for a 95% confidence.&lt;/p&gt;
&lt;p&gt;I will still run the strategies of 2xATR, 3xATR and a percentage based exit to
determine their outputs. Maybe running multiple strategies and selecting the
best performing one and showing that could also be a nice feature, but again
it’s very personal. I believe a 1:1 take profit / stop loss ratio will result
in an average score of around 50%, and 2:1 will result with an average score of
33% as it’s basically based on expected value since the price changes are
distributed randomly.&lt;/p&gt;
&lt;p&gt;I also changed the way the Bollinger Bands squeeze scan was working. It was
scanning the last N periods and triggering if the last period bands were within
a certain limit of the minimum band width of the last N periods. This is kind
of over complicated as I just want to get the periods were the bandwidth is
low, so now it will trigger if the bandwidth is &amp;lt; 4%.&lt;/p&gt;
&lt;h2&gt;New features&lt;/h2&gt;
&lt;p&gt;As I was sifting through the scans I realized that I was looking for a chart to
see the relevant data that triggered the scan. If the scan is a Bollinger Bands
squeeze I wanted to the bands on the chart. So I added this feature. This
required me to store the band data in the K/V store because that’s the only
storage the API will access. To be consistent I also stored the last 100 period
OHLC data in the K/V store to generate the candle stick data for the chart. The
K/V store is backed by MySQL but this may change in the future. Redis is a
strong contender for K/V storage, but I’ll cross that bridge when I get there.
I added a new field to the scan definitions file that defines which indicators
will shown on the chart when that scan is triggered.&lt;/p&gt;
&lt;p&gt;Here is a screenshot of this new feature in action:&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/ts1.png"&gt;/img/ts1.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Wow, yet another very long post for a short week. Looks like a lot has been
done and development is going full steam ahead.&lt;/p&gt;
</content:encoded></item><item><title>Cosmic conquest</title><description>A simple RTS game in space</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Tue, 04 Dec 2018 00:00:00 GMT</pubDate><guid isPermaLink="true">coscon.html</guid><content:encoded>&lt;p&gt;Cosmic Conquest is a real time strategy game available for Mac OSX, iOS, Android, Windows and Linux.&lt;/p&gt;
&lt;p&gt;The downloads for the latest releases are available &lt;a href="https://1drv.ms/f/s%21AvhnLreYwL-P2Cnkt9dMWYsnXO-8"&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;{{&amp;lt; youtube _DuQdKtXsA8 &amp;gt;}}&lt;/p&gt;
&lt;p&gt;Check out some of the tips and tricks and nuances of the game to beat the computer in a battle through the stellar system.
The game starts with a number of planets ranging from 5 to 8 (you can configure this from the options menu). Each player has a home planet with 10 production points. Your home world and planets that you have conquered are shown with a green ring around them. Production points are used to make ships that are spawn on that planet and can be sent to other planets to conquer them. To send a ship click the source planet then the target planet. If you click on the planet and select the same planet as the target, you will initiate a planet defense which I explain later. Once you order your ships they will start traveling towards their destination. If they encounter enemy ships on their path they might engage the enemy. You will notice that their movements and directions change when they start dog fighting with enemies. Once they destroy the enemy they will continue on their mission to the target planet. When they reach the planet, if the planet is yours they will add to the production points. If the planet is an enemy planet they will reduce the production points. If its neutral the planet will be yours with all its production points. The aim of the game is to conquer all the planets in the stellar system.&lt;/p&gt;
&lt;h3&gt;Planets&lt;/h3&gt;
&lt;p&gt;Each player starts with a home planet. The home planet starts with 10 production points and gains 1 point / second. The maximum points it can produce is 10. That means after the points are greater than 10 it will not produce anything. But if you send reinforcements to the galaxy they will still be added to the points, but it won’t grow. There are 12 different types of planets each with different growth rates and max points. An important part of your strategy should be conquering planets that produce fast and a lot of points.&lt;/p&gt;
&lt;h3&gt;Ships&lt;/h3&gt;
&lt;p&gt;There are 4 types of ships with different speeds, shield, costs, and firepower. When you send ships from a planet to another one the planet will spend half of its points to create these ships. The planet must have at least 80% of its max points to produce a battle ship and at least 60% of its max points to produce a heavy cruiser. The light cruiser and fighter can be produced if there is enough points. The production of ships is influenced by the heavy/light setting.&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/coscon1.png"&gt;/img/coscon1.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;If you don’t want to produce any battle ships or heavy cruisers switch to light mode. If you want these heavy class ships switch to heavy mode. There is on guarantee that the heavy ships will be produced even if there are enough points but the chances are significantly higher in heavy mode that they will.
At the beginning of the game, it doesn’t make much sense to produce heavy ships as the opponents will be far away and you will most likely not be engaging in dog fights but will be trying to conquer planets. After you have a couple of planets and are attacking enemy planets heavy ships will be useful as they will destroy enemy ships with power. If your ships attacks an enemy planet it will decrease the planets points by it it’s hull size, but if you send it as a reinforcement to one of your planets it will only increase the planet points by 1. So be careful when sending reinforcements.
The ships have the following properties:
All ships are indestructible for 2 seconds after they are created.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Beams/sec – The firing rate of the ship if it is combat with an enemy.&lt;/li&gt;
&lt;li&gt;Attack range – The maximum distance they ships lasers are effective.&lt;/li&gt;
&lt;li&gt;Damage HP – The amount of damage on the enemy armor in case of a hit.&lt;/li&gt;
&lt;li&gt;Seek range – The maximum distance the ship will sense an enemy ship to engage.&lt;/li&gt;
&lt;li&gt;Speed – The distance the ship travels per time.&lt;/li&gt;
&lt;li&gt;Armor – The protection around the ship. If the armor is destroyed the ship will explode.&lt;/li&gt;
&lt;li&gt;Shield chance – The probability that the enemy laser will be deflected by the shield.&lt;/li&gt;
&lt;li&gt;Hull size – The cost in production points of building this ship, and the damage it will do to enemy planets.&lt;/li&gt;
&lt;/ol&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
  &lt;th&gt;Type&lt;/th&gt;
  &lt;th&gt;Beams/s&lt;/th&gt;
  &lt;th&gt;Range&lt;/th&gt;
  &lt;th&gt;HP&lt;/th&gt;
  &lt;th&gt;Seek&lt;/th&gt;
  &lt;th&gt;Speed&lt;/th&gt;
  &lt;th&gt;Armor&lt;/th&gt;
  &lt;th&gt;Shield p&lt;/th&gt;
  &lt;th&gt;hull&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
  &lt;td&gt;battle ship&lt;/td&gt;
  &lt;td&gt;3&lt;/td&gt;
  &lt;td&gt;12&lt;/td&gt;
  &lt;td&gt;20&lt;/td&gt;
  &lt;td&gt;15&lt;/td&gt;
  &lt;td&gt;1.5&lt;/td&gt;
  &lt;td&gt;40&lt;/td&gt;
  &lt;td&gt;0.8&lt;/td&gt;
  &lt;td&gt;4&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;td&gt;fighter&lt;/td&gt;
  &lt;td&gt;1&lt;/td&gt;
  &lt;td&gt;7&lt;/td&gt;
  &lt;td&gt;5&lt;/td&gt;
  &lt;td&gt;10&lt;/td&gt;
  &lt;td&gt;2.5&lt;/td&gt;
  &lt;td&gt;10&lt;/td&gt;
  &lt;td&gt;0.2&lt;/td&gt;
  &lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;td&gt;heavy cr.&lt;/td&gt;
  &lt;td&gt;2&lt;/td&gt;
  &lt;td&gt;10&lt;/td&gt;
  &lt;td&gt;15&lt;/td&gt;
  &lt;td&gt;15&lt;/td&gt;
  &lt;td&gt;1.7&lt;/td&gt;
  &lt;td&gt;30&lt;/td&gt;
  &lt;td&gt;0.4&lt;/td&gt;
  &lt;td&gt;3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;td&gt;light cr.&lt;/td&gt;
  &lt;td&gt;1.5&lt;/td&gt;
  &lt;td&gt;7&lt;/td&gt;
  &lt;td&gt;10&lt;/td&gt;
  &lt;td&gt;15&lt;/td&gt;
  &lt;td&gt;2&lt;/td&gt;
  &lt;td&gt;20&lt;/td&gt;
  &lt;td&gt;0.5&lt;/td&gt;
  &lt;td&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;As ships travel to their destinations they will encounter enemy ships. The aggression factor will determine the probability of engaging enemy ships. 0% means that your ships will continue towards their destination planet, even under fire. 100% means that they will engage the enemy.&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/coscon2.png"&gt;/img/coscon2.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;If you send ships to their creation planet (by double clicking on a planet) they will sit in orbit waiting for enemy ships to arrive and will engage them to defend the planet.
Each player may have a maximum of 25 ships enroute at any time. (current number of ships are display under the credits on the bottom left)&lt;/p&gt;
&lt;h3&gt;Perks&lt;/h3&gt;
&lt;p&gt;Every second the players gain a credit point that they can spend on purchasing perks. Perks are valid for a period of time and then they are gone. You cannot purchase the same perk while it’s active. The players credits are displayed at the bottom left&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/coscon3.png"&gt;/img/coscon3.png&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;Warp Perk&lt;/h4&gt;
&lt;p&gt;This will increase the speed of all ships by 100% for 5 seconds and costs 25 credits.&lt;/p&gt;
&lt;h3&gt;Range Perk&lt;/h3&gt;
&lt;p&gt;This will increase the attack range of all ships by 5 for 3 seconds and costs 35 credits.&lt;/p&gt;
</content:encoded></item><item><title>TechScan DevLog 2018-12-03</title><description>Techscan project updates</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Mon, 03 Dec 2018 00:00:00 GMT</pubDate><guid isPermaLink="true">techscan_devlog_2018-12-03.html</guid><content:encoded>&lt;p&gt;A new month a new dev log for the stuff that’s been going on&lt;/p&gt;
&lt;p&gt;Huge change yet again for the engine which I will get into later. First order
of business is a summary of the new stuff:&lt;/p&gt;
&lt;h2&gt;Summary&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;get rid of all but USD pairings for cryptos&lt;/li&gt;
&lt;li&gt;reduce symbol listing response size from 1.2M to 0.8M&lt;/li&gt;
&lt;li&gt;new scanner: trend start&lt;/li&gt;
&lt;li&gt;S/R zones to charts&lt;/li&gt;
&lt;li&gt;using TaLib java API&lt;/li&gt;
&lt;li&gt;Candle stick patterns scanners&lt;/li&gt;
&lt;li&gt;port back over to java w/o spring + hibernate&lt;/li&gt;
&lt;li&gt;eclim, idea + X forward, Che adventures&lt;/li&gt;
&lt;li&gt;market overview calculations in SQL&lt;/li&gt;
&lt;li&gt;store technical calculations in KV store&lt;/li&gt;
&lt;li&gt;correlation calculations in technical calculations&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Good bye pairings&lt;/h2&gt;
&lt;p&gt;Some of the alt coins are worth so less that compared with BTC they end up
taking 8-9 decimal places. This is a disaster for the display and the layout of
the app in general. At first I had thought about displaying these types of
currency pairs as satoshis but that was met with high resistance from my
previous team members. The pair name is XXX/BTC so you cannot display it in
Satoshi’s was the justification. Fair enough I guess. Another fix for this
could be decreasing the font size if there are a lot of decimal places, but I
have tried this. It sounds like it should work in theory but I’d have to
experiment with it to be convinced that it does. So for the time being the
easiest solution is to drop pairings with BTC and keep only the pairs that are
traded against the USD. All of the big coins are included in this so no big
loss their.&lt;/p&gt;
&lt;h2&gt;Slim responses&lt;/h2&gt;
&lt;p&gt;The autocomplete component of Vuetify requires a list of the items to complete
(though I’m pretty sure their should be a version that can do partial searches
with AJAX) and that list in the previous version was huge around 1.2 megabytes.
The initial delay after the autocomplete trigger was around 2 seconds which
made it appear to be not responding. My primary solution to this was to trigger
a request to the symbol listing endpoint after the app loaded in the background
and since requests are cached the searches would not have that initial lag.
This worked out like I thought but the payload size is still more than I cared
for so I got rid of some of the fields in the response and change the structure
from a JSON object to an array dropping the keys and therefore reducing the
size even further.&lt;/p&gt;
&lt;h2&gt;More scanners&lt;/h2&gt;
&lt;p&gt;A saw a scanner on STB that I wanted to incorporate as I think it’s important:
The new trend started scanner. It fires when the ADX crosses the 25 line. Even
though ADX lags it’s still useful to know that a trend has begun.&lt;/p&gt;
&lt;h2&gt;More charts&lt;/h2&gt;
&lt;p&gt;Data visualizations are always cool, you can never get enough of them. This
motivated me to add a chart displaying the support and resistance zones
calculated using the clustering method I blogged about a couple of weeks back.&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/ts2.png"&gt;/img/ts2.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I plan on adding charts to each triggered scan with the relevant indicators
like MA’s for MA crossovers etc. But it’s a low priority task right now.&lt;/p&gt;
&lt;h2&gt;New technical analysis library&lt;/h2&gt;
&lt;p&gt;Ta-lib.org is a mature technical analysis library that supports way more
indicators that I built into talib4j. I was quite happy with the results I got
when&lt;/p&gt;
&lt;p&gt;using the python wrapper so it’s back in. I plan on doing a write up on the
performance vs talib4j as the code is probably transpiled from the C version
and impossible to read. The Java API is god awful because of this generated
code, which means the C API is just as disgusting. To limit the exposure to
this filth I wrapper the API with a custom class and I can just substitute that
for talib4j any time if I have all the indicators coded in.&lt;/p&gt;
&lt;h2&gt;Even more scanners&lt;/h2&gt;
&lt;p&gt;Using Talib also gives me access to candle pattern recognition. I didn’t want
to write a scanner for each of the patterns so I had to resort to using the
java reflection API to figure out the correct method to call from the scan
definition file. So the definition file is something like this:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;{ “id”: “…” “name”: “some scanner”: “module”: “CDL2CROWS” }&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;I had all the definitions generated from the documentation on the talib site
with a small python script (around 60 different scans) and look up the method
from the module attribute of the definition. With the addition of all the
candle patterns each run consists now of around 16K scans!&lt;/p&gt;
&lt;h2&gt;Back to the drawing board&lt;/h2&gt;
&lt;p&gt;Now that I am running 16K scans the python code took 48 hours to complete a
days worth of scans. This of course is unacceptable as the scans need to be
done quickly. It’s no use to display scans 2 days after the market closes. I
poked around with multi threading in the python code but to no avail as there
is this thing called the “Global Interpreter Lock” which limits you to the
total performance of a single core. Also using multi threaded code consume too
much memory – something which I will not have that much of in production. So
back to a faster language: Java. But this time I didn’t want all the bloat that
comes with spring + hibernate. They consume way too much memory that was one of
the reasons for going with python. So this time around it’s a plain old Java
application with small utility libraries for database operations. Now 16K scans
take 1 hour to complete without multi threaded code. I was initially thinking
of keeping the python engine for other stuff like synchronization, and
technical calculations etc. but ended up porting all the engine code back to
Java.&lt;/p&gt;
&lt;h2&gt;Have Chromebook will code&lt;/h2&gt;
&lt;p&gt;I got a new toy from the Black Friday sales events so naturally I want to use
it all the time. But it’s not buffed in terms of hardware so I needed to find a
way of coding Java without running a full blown IDE on my Chromebook. It would
probably run the IDE OK but the engine + database would put to much strain and
it would start to crawl. So I started coding in Emacs. Plain old Emacs with no
packages. It sounds crazy and it actually is quite crazy. It was nice just
suspending the machine and reattaching the session to continue where I left
off, but no syntax checking, not auto imports makes it a hassle. Not being able
to see the parameters of a method call was the worst. So I checked out what
packages people were using for coding on Emacs. The most effective one seemed
to be Eclim. I had used Eclim before with vim (which is the original purpose of
Eclim: Eclipse + vim) but somebody had wrote a wrapper around the binary for
Emacs. I tried to get it running on my Debian development server but I could
not get it to work. It would just not connect. So I gave up on Eclim and
checked out another package called Megahanada. Found that one too complicated
and didn’t really find the functions it provided useful. Then I tried X
forwarding with Intellij Idea. This felt like home a familiarity that was much
appreciated. This lasted for a week or 2 until the inefficient X protocol drove
me nuts with the stupid lagging of the UI. I looked around for some
alternatives and came across xpra which was supposed to be faster but really
wasn’t. And the fonts and graphics were blurry with Xpra so it went out the
window. I thought that maybe it was Swing that wasn’t playing nicely so I tried
X forwarding with VS Code. Same problems. But on a side note I really liked the
Java plugin for VS Code – it’s lightweight and provides all the great
functionality that I was searching for. Anyways then I remembered Eclipse Che –
A web based IDE. I had tried Che before in it’s early stages and wasn’t really
impressed with it’s current state. But know they’ve created a Docker image
which is super easy to install and get running and they’ve also added Git
support so worst I could use Che to write the code push and compile/test on my
development server. But Che workspaces already come with Java + Maven so I
could basically do everything I wanted in the Che environment. Another bad
thing with X Forwarding was that once the laptop suspended the SSH connection
was lost and the applications died on me. Since I have leave the computer to do
other stuff (like burping, diaper changes, etc) this was bugging me quite a
bit. Now in Che the tab remains open and I can continue where I left off
without a problem.&lt;/p&gt;
&lt;h2&gt;Bugs bugs bugs&lt;/h2&gt;
&lt;p&gt;Porting over code is also a great chance to check what I’ve actually written. I
figured out major bugs in the technical calculations code which I fixed. I was
doing all of these calculations in application code, which is probably slower
than doing them on the DB side so I moved the things I could calculate on the
DB over there.&lt;/p&gt;
&lt;h2&gt;few architectural changes&lt;/h2&gt;
&lt;p&gt;I was letting the API calculate some of the data on the symbol detail view on
the fly, but now I decided to have these pre-calculated for the last trade date
and store them in the key/value store. I really wan’t refrain from having the
API do calculations to consolidate all the logic on the engine code base. This
meant moving the technical and overview tab data to the key/value store. I also
wanted to merge these to requests as they did have a couple of overlapping
values. I also decided to store the correlation data in the key/value store as
it was taking up a lot of rows in the table. I was keeping a history of the
correlated items which is probably not necessary. While at it I also removed
the dedicated job for correlated calculations and merged it into the technical
calculations.&lt;/p&gt;
&lt;p&gt;Wow that was quite a long post – a lot has happened in the past week.&lt;/p&gt;
</content:encoded></item><item><title>HP X2 Chromebook review</title><description>My experience with a computer that's only meant to run web applications</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Thu, 22 Nov 2018 00:00:00 GMT</pubDate><guid isPermaLink="true">hp_x2_chromebook_review.html</guid><content:encoded>&lt;p&gt;2018-11-22&lt;/p&gt;
&lt;p&gt;I’ve been pondering about Chromebooks since their inception about 5 maybe 6 years ago. It just made sense to me at the time that a simple browser-as-an-OS device would enable me to do 90% of the things that I wanted. All the apps I use are web based – so that’s covered, but what about being productive? What about managing servers? The ChromeOS team had that covered too with their SSH extension. But I can easily run a browser on my computer, why would I pay to get another device that just runs a browser. That’s what had put me off of getting a Chromebook all this time, until a week ago when I finally gave in to the temptation after discovering the HP X2 on a review site. Buying the device is a story in its own. I started doing my research after I saw an add for the new Google slate. A tablet with a detachable keyboard was just the thing I needed when working on the couch. My 13“ Asus Zenbook is a bit too big when using on the couch although manageable but uncomfortable, so I was trying to get stuff done with an old iPad Air 2 fitted with a Zagg Rugged keyboard case. The keyboard on that is really small so extended typing/coding sessions would result in pains in my wrists. Not being able to remap the caps lock key to a control key made things worse, and the best SSH client Termius on iOS has the escape key on screen and not on the keyboard. Good-bye easy vim usage.&lt;/p&gt;
&lt;p&gt;So this all made me start a search for a smaller more portable device. I checked out quite a lot of reviews for different devices on Amazon and the web. I’m always skeptical towards the ‘review sites’ as I feel they can be bribed by companies for biased reviews so I always check out user experiences too. Almost all reviews on amazon for any Chromebook was fairly positive. So I had my mind set on a cheaper 12” device around 200-300. The hardware on all these low-end devices are about the same so I was looking for a small bezel and nice looks. I told my SO about my intentions to switch to a low end Chromebook and the reply I got was “You always end up regretting those cheap purchases. Go for something better” (my regrets so far: Asus EEE Pc, Gateway netbook, Amazon Fire tablet, Samsung Galaxy E tablet, …). This actually got me encouraged to go for something better. The best Chromebook you can buy today is the Pixel which is ridiculously priced at 999 for the base model and is not a tablet. It looks sleek, but out of my price range. Next up according to some site was the HP X2. I hadn’t actually checked this device out before so I started doing some research. No user reviews on amazon – bummer. BestBuy reviews were pretty good, site reviews were also pretty good. It’s a tablet so that ticks a checkbox on my list. It’s aspect ratio is 3:2 which is actually a great screen size for me. It supports android apps – this I though would be a must have if you are getting a new device.&lt;/p&gt;
&lt;p&gt;One thing that bothered my was the faux leather textured keyboard, which I though would “unnerdy” and more “businessy”. The CPU is an Intel M3 mobile optimized chip which I have no idea about. The RAM is 4GB’s and the storage is 32GB. Normally I would never get a device with 4GB of RAM but the beauty of the Chromebook is that it’s efficient and 4GB is enough – at least that’s what I had read in all the reviews. So I started hunting for a deal on this device.&lt;/p&gt;
&lt;p&gt;The first time I checked BestBuy the device was listed for 530. 60 off the full price. I was like ‘meh’ I’ll wait for Black Friday and see what happens. 2 days later it was full price again and this actually made me sad. That’s when I realized that I wanted this – and I wanted it bad. I checked HP’s official site and they still had a 50 promo going on until the 14th of November. In the hopes that Best Buy would price match I went to their Bellevue store. I located the device on display and played around with it. I also played around with the various other cheaper devices they had and the X2 and Pixel really stood out from that lot.
The cheaper displays looked foggy compared to the HP and Pixel. Anyways I found a sales person and asked them about the device, specifically if they would price match HP. To my dismay the guy said “We can’t match the manufacturer only retailers”. I tried a bluff with “I’ll buy it online from HP then” and the guy said “Yeah makes sense”. I guess they aren’t flexible in that regard. So my head hanging low I walked out of the store empty handed back to my car. I sit in the car for 10 minutes and then think to my self: “I’ll pay the 50 premium for the luxury of an easy return if I don’t like to device”. This is both a “rationalization” (or an excuse) and partially true. I went back into the store and found a different sales person. No way I’ll swallow my pride and talk to the same guy after the bluff I pulled that backfired I just told the guy I wanted the x2 and he started searching for a box. He was looking at Samsung boxes checking their bar codes. I said “Why are you looking at Samsung boxes?” and the reply was “I want to make sure I get the code correct”. I try to refrain from pushing people that misunderstand what I said as I see they get irritated when I immediately reiterate, so I waited 2, 3 minutes as he continued searching and then I said: “Why would they put an HP device in a Samsung box?”. Then he understood what he was doing and apologized and started looking for other boxes. As his search continued without results I was starting to worry that they didn’t have it stock. Wouldn’t be the first time that it would happen to me, but luckily after a couple of more minutes of searching he found the correct item. A generic brown box with a HP logo on it. We went to the register and I paid the full price of 600$ + tax not being sure if it was money well spent.&lt;/p&gt;
&lt;h1&gt;Hardware&lt;/h1&gt;
&lt;p&gt;After I got home I could only unbox the device before I had to do a diaper change or a feeding – I don’t exactly remember.&lt;/p&gt;
&lt;p&gt;The box isn’t anything fancy like an Apple product but who cares? I’d rather not pay extra for something that I’ll end up throwing in the recycle anyways. After I put the family to sleep I got on my new toy and registered my google account and started playing around with it. The first thing that really impressed me was the screen. It’s on par with a retina MacBook. The colors are vivid the fonts are crisp and the UI elements look beautiful. I’ve used Windows and Linux machines with similar resolutions but no Windows machine could come close to a Mac before. But the X2 + ChromeOS are there – that’s for sure. The device is usable on my lap as it doesn’t need a kick-stand to stabilize the screen, but I does feel a bit unbalanced at times due to the screen being quite heavy as it has all the guts. The keyboard is not back-lit which I don’t really care about as I’m a touch typist and the keys are a joy to type on. I’m usually a mechanical keyboard user and don’t like mushy keyboards but this one is pleasant to use. The track pad is OK, it doesn’t feel like a premium track pad like the one on the MacBook. There are 2 USB-C ports that can be used for charging and a 3.5 mm headphone jack on the side. I streamed some music from Spotify to my AudioTechnica ATH-50x headphones and Apple earbuds and the quality was good.&lt;/p&gt;
&lt;h1&gt;Software&lt;/h1&gt;
&lt;p&gt;The next day I got a chance to play around more with my new computer. I wanted to get my daily setup going and see if this machine was a keeper. Chrome is already setup with all my bookmarks and extensions synced automatically so that’s done. I just needed a decent SSH client to connect to my development servers and start coding. I installed the Chrome SSH client extension first. This app is OK but it opens in a browser tab which is not the best for switching back and forth between web pages and the terminal. One thing that I couldn’t accept with this app was that C-Space selection didn’t work it Emacs. This would make my life significantly harder. So I tried ConnectBot and Termius from the app store. Both had weird rendering issues like the caret would be misaligned with the end of the text. This was not a show stopper but annoying. Next up was the Linux support through Crostini. The installs a VM / container and runs Linux apps. The only app I need was a terminal and it works great. The fonts are great, Emacs works as expected so I’m basically setup for my daily work on my current project. Setting up my Samsung m2020 printer with Google cloud print was a breeze too. Just register from the web interface of the printer and its shows up in the print dialog. That’s about it for the software I tested that doesn’t work in browser.&lt;/p&gt;
&lt;h1&gt;Verdict&lt;/h1&gt;
&lt;p&gt;Before I end this review, I also want to tell the rest of my story of my purchase. 2 days after I came home, during a late night feeding session I randomly checked the Best buy website and saw that they had a new promo going on: 100 off the full price! At first I felt so frustrated that I had missed this but then I remembered I could just return it and buy it again. I had already redeemed the 2 years 100 GB drive offer, I would probably lose that but I though I could give customer services a call and have them continue the drive offer. So I power washed the X2 put it back in it’s box and went to Best Buy the next day. The customer services guy said that they’ll price match themselves so I just got back my 100.&lt;/p&gt;
&lt;p&gt;A couple of things I still need to test are the active stylus and remote desktop connections via RDP/VNC. I’ll post a reply on this topic once I’ve done these. Today I managed to get X forwarding working running a X based emacs instance on my development server with the display forwarded to my X2. This is specific to this device but the ChromeOs in general. This opens the doors of the Linux applications to its fullest extent. I could even run heavy programs like IDEs on my server and use them without slowing down the X2. I’ve also managed to create a desktop application launcher for the remote application which means there is no rogue terminal windows cluttering my Alt+Tab space. Another thing I did today was install Keepass Android from the play store on this machine. It works flawlessly and that put my mind at ease as I was kind of worried about not having my password manager on this. I’m very satisfied and happy with this purchase for now. I still need to test it when I’m not on my local network as X forwarding might be laggy beyond use over WAN – but I’ll still have my good old terminal emacs locally.&lt;/p&gt;
</content:encoded></item><item><title>TechScan DevLog 2018-11-20</title><description>Techscan project updates</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Tue, 20 Nov 2018 00:00:00 GMT</pubDate><guid isPermaLink="true">techscan_devlog_2018-11-20.html</guid><content:encoded>&lt;p&gt;So I’ve been working on the engine in past 2 weeks every chance I get, which is
not a lot these days. I’ve also had to adapt the&lt;/p&gt;
&lt;p&gt;web client to some of the breaking API changes (mostly fields names, and simple
structure changes). With major changes in the database structure, some of the
old tables being merged into the key value table, the engine code is a bit
clearer now. MYSQL should be able to handle the queries to the KV table with
ease as it’s properly indexed and the record cardinality is much lower because
most of the data is stored in a JSON structure now. I implemented the top
activity module, correlation and the news sync module. The correlation finder
takes a long time as python is kind of slow when iterating over a lot of
records and each symbol has to be checked against all other symbols to find a
correlation. This made me want to switch to something faster but I resisted the
urge as the correlation finder can be run maybe every other week and it’s OK if
it takes 12 hours to run. I also got rid of the old API code that was hogging
memory thanks to spring + hibernate storing tons of classes and garbage in
memory. I went with flask which is a simple micro framework for creating API’s.
Currently I create a new connection for each request to the database and I need
to test if this will scale under the load. What I have read is that the old
“connections are expensive” is now a myth with newer databases, but still the
network overhead could prove this theory wrong. In the second half of this
month I adjusted the web client code to the new API responses and fixed
cosmetics here and there. I can probably say I ported all the old code to the
new API with maybe a couple of features missing that I will add in the
following days. A major change on the client was switching from the Google
Charts JS library to static images to display the candle sticks. My initial
thought was it would be good to offload the chart creation to the client to
lessen the load on the server, but it this turned out to have 2 disadvantages:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;slower mobile clients take forever to render the chart (my Samsung tablet).&lt;/li&gt;
&lt;li&gt;a ton of charting data is transferred to the client which slows the page&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;loading. So I struggled for a day with the excellent matplotlib for python to
get a nice candle chart with a volume overlay and I think it turned out quite
well.&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/ts3.png"&gt;/img/ts3.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Before this was completed I used a chart from Finviz as a placeholder and
inspiration. I also managed to squeeze in the android client build by using an
excellent plugin for Vue which was quite painless to setup. I side loaded the
app on my phone and tablet and they seem to work great. After loading the apps
I realized that some things like pull to refresh were missing. It’s essential
to convert to a mobile app and try it out to get a good feel for the user
experience, even though I’m actually developing the client in a browser. My
plan for the upcoming days are using the app to iron out some more user
experience quirks, then I need to get into StockTwits integration and start
with marketing stuff. The launch timing seems quite bad as the markets have
taken a turn for the worse – or maybe people will be searching for
opportunities in this turmoil and can use TechScan to seek out these
opportunities?&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/ts4.png"&gt;/img/ts4.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;:&lt;/p&gt;
</content:encoded></item><item><title>TechScan DevLog 2018-10-10</title><description>Techscan project updates</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Wed, 10 Oct 2018 00:00:00 GMT</pubDate><guid isPermaLink="true">techscan_devlog_2018-10-08.html</guid><content:encoded>&lt;p&gt;&lt;strong&gt;summary&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;stuff done in September 2018&lt;/li&gt;
&lt;li&gt;Jenkins automation&lt;/li&gt;
&lt;li&gt;persistence problems&lt;/li&gt;
&lt;li&gt;return to single thread mode&lt;/li&gt;
&lt;li&gt;scan refactoring and parameter change support&lt;/li&gt;
&lt;li&gt;scan performance improvements&lt;/li&gt;
&lt;li&gt;java 10 adventures&lt;/li&gt;
&lt;li&gt;parameter recommendation tests&lt;/li&gt;
&lt;li&gt;hybrid client developments&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Wow, September was a month that I would only describe as “I lost my humanity
and became a beast”. After checking the git commit logs I see 480 new commits,
touching 26410 lines for the API and Engine, which is quite a bit. There is
basically too much stuff that I have done to cover in detail so I’ll just have
to go over the most import changes for this month.&lt;/p&gt;
&lt;p&gt;First off I want to start with the automation tasks. I was running the BFX, IEX
sync tasks, scanner tasks via crontab on the test machine. This was OK for some
time, but it wasn’t getting notifications about failed jobs or any information
about the task duration. So I moved all these periodic engine tasks to Jenkins.
Another added bonus is it’s way easier to manage the task pipeline (which task
should run after which task, which can run in parallel) from Jenkins rather
than a bunch of ad-hoc shell scripts. I also changed the development cycle from
committing code to master to committing first into a development branch, and
then asking Jenkins via Hubbot through slack to test and merge and push the
changes. This keeps the master branch at a stable state all the time. G.
requested that any pushes to the master branch of the web client repository be
deployed immediately so I had to do some GitLab trickery to get that working,
as GitLab doesn’t allow that for unpaid accounts. But it can be done via web
hooks.&lt;/p&gt;
&lt;p&gt;The current flow of crons are looking like this&lt;/p&gt;
&lt;p&gt;&lt;em&gt;lost image&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Using spring boot is a MUST if you are developing with Java – the advantages it
provides are countless, but it does come with it’s own quirks. I had been
getting “transaction manage not found – cannot remove entity” errors on some of
the data sync services. The solutions on the internet were all about adding a
transactional annotation to the service method and people had accepted those
answers. But I guess something changed along the way in spring development as
they did not work for me. The solution is was to add the annotation to the
repository interface. Sometimes something so simple can eat up a lot of
precious development time, but it’s satisfying in the end when you solve it. As
I was fiddling around with this I also decided to save the response JSON from
the providers instead of parsing them into domain entities and saving those.
Now instead of having 1 M daily data points, I have 8 K key value items and I
process them in memory. I was caching the domain objects anyways so this spares
some extra load on the database.&lt;/p&gt;
&lt;p&gt;During development I wanted to get the engine results as fast as possible so I
was parallelizing all the operations in the engine. I noticed along the way
that “parallelStream” is not the answer to all of the question. I ran into
cases where parallelizing would really screw up the cache, and serial
processing with a good cache usage is way better (in terms of efficiency) than
just using all the cores. I can get more bang for a core than I could when the
processing was done in parallel. This decision was also in part due to the fact
that I want to run the engine on the same machine as the API (yes, I am
basically poor) and I can’t have the engine hogging all the CPU and exhausting
RAM. I can’t also have the entire data set in memory (or most of it) and this
tends to happen when threads are running at the same time. So with the serial
processing using the cache in an optimal way, the scanning process takes 2.5 K
seconds on a single core. Running in parallel took 600 seconds on 8 cores.&lt;/p&gt;
&lt;p&gt;A prerequisite to serialize the scanners was to improve their performance. I
installed the excellent YourKit profiler trail version (which by the way is
very expensive – otherwise I would buy it) and tracked down the bottle necks to
unnecessary object wrapping (using my own SuperList class with convenience
methods for accessing elements, like getLast(N), getTail(..), etc.) and the
parsing of string to dates and vice versa. After hunting these down and
refactoring the code to get rid of extra layers and work, there was a 3x
increase in speed which brings the processing time to acceptable limits.&lt;/p&gt;
&lt;p&gt;An integral part of the system is the performance evaluator for scans based on
past performance. I had coded this in a hurry and it was a bit disgusting, so I
refactored this into it’s own service. The functionality is the same but it’s
simplified and runs a bit faster.&lt;/p&gt;
&lt;p&gt;I hate the verbosity of Java so I thought I’d look into what was going on in
the Java world, which I hadn’t done since the release of Java 8 and the
streaming API. I found out that Java 10 was released March 2018 and finally had
support for the “var” keyword, which meant less verbosity in assignments. I
know it’s kind of trivial but I wanted to give it a go, since spring boot it
supposed to support Java 10. So I went ahead and updated the development and
test environments to Java 10 and compiled the code. A couple of warnings of
unsafe access in spring but otherwise everything seemed OK. That is until I
tried running the API. Then a lot of exceptions about Redis not being happy
with something (which I don’t remembers, and could not find an easy solution
for), so I reverted back to 8, which is way more stable. I have long lines of
code, but at least everything works correctly&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/1-m79Makp8mOHomhro.png"&gt;/img/1-m79Makp8mOHomhro.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;A great Idea that I had for the engine was parameter optimizations. RSI
oversold is 80, but why? why not 60?&lt;/p&gt;
&lt;p&gt;I guess the guy who invented it had success with 80 and kept it as a default
and now everybody uses that. But wouldn’t it be great if I could figure out the
optimal number by scanning the past RSI turning points? That’s what parameter
optimization/recommendation is about. There are a LOT of combinations to
calculate so this feature has to be selective on the symbols and the parameter
values that it tries. I still have to bake this idea, but I did put down a PoC
service that does this.&lt;/p&gt;
&lt;p&gt;I also started with the mobile client development using PhoneGap and Framework
7 with Vue.js. Vue.js is pretty amazing – at last someone has come up with a
good framework for JavaScript development. I used to be a Mithril person but
the lack of templating and using that m() function was a bit annoying. Also the
component system in Mithril is complicated and not easy as Vue.js. Framework7
looks OK’ish but there are some quirks with it too. I ran into a problem with
the router, that would break the back button randomly. It’s surprisingly
difficult to find answers to question – I guess they don’t have a large
community so I’ll probably drop F7 in favor Vuetify.&lt;/p&gt;
&lt;p&gt;That was a long post, but I guess this is how it’s gonna be if I do it monthly.
I still want to do a write up about the team dynamics, and the frustration that
I’m having with that.&lt;/p&gt;
</content:encoded></item><item><title>Hibernate batch statements</title><description>batching hibernate insert statements for performance gains</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Wed, 05 Sep 2018 00:00:00 GMT</pubDate><guid isPermaLink="true">hibernate-batch-statements.html</guid><content:encoded>&lt;p&gt;Here is a working way to do bulk inserts for hibernate:&lt;/p&gt;
&lt;p&gt;First make sure that your entity id generation is not AUTO. I use UUID/GUID generation&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    @Id
    @GeneratedValue(generator = &amp;quot;uuid&amp;quot;)
    @GenericGenerator(name = &amp;quot;uuid&amp;quot;, strategy = &amp;quot;uuid&amp;quot;)
    @Column(columnDefinition = &amp;quot;CHAR(32)&amp;quot;)
    private String id;

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;add the following to your configuration (this is for spring boot)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;spring.jpa.properties.hibernate.jdbc.batch_size=400
spring.jpa.properties.hibernate.order_inserts=true
spring.jpa.properties.hibernate.order_updates=true
spring.jpa.properties.hibernate.jdbc.batch_versioned_data=true
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;the following code will batch the statements for a great performance increase:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;        List&amp;lt;SurfaceTile&amp;gt; tiles = new ArrayList&amp;lt;&amp;gt;();
        for (Star star : stars) {
            for (Planet planet : star.getPlanets()) {
                tiles.addAll(planet.getTiles());
            }
        }
        tiles.removeAll(Collections.singleton(null));
        surfaceTileRepository.save(tiles);

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;you can check that it's being batched using the following spy driver:&lt;/p&gt;
&lt;p&gt;add &lt;code&gt;compile 'p6spy:p6spy:2.1.4'&lt;/code&gt; to your build file and set the following for your datasource url and driver&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#spring.datasource.url=jdbc:p6spy:mysql://host:3306/db?rewriteBatchedStatements=true
#spring.datasource.driverClassName=com.p6spy.engine.spy.P6SpyDriver
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;download the properties file in the attachment and put it in your resources directory and you will see the following in the logs&lt;/p&gt;
&lt;p&gt;&lt;a href="spy.properties.txt"&gt;spy.properties&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;p6spy  : 1450114684813|0|batch|connection 7|insert into ...
p6spy  : 1450114684814|1|statement|connection 7|insert into ...
p6spy  : 1450114684817|2|commit|connection 7||
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;the 3rd column (batch) means that the statements are getting batched and if the 3rd column reads 'statement' that means the query was sent to the server.&lt;/p&gt;
</content:encoded></item><item><title>TechScan DevLog 2018-09-05</title><description>Techscan project updates</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Wed, 05 Sep 2018 00:00:00 GMT</pubDate><guid isPermaLink="true">techscan_devlog_2018-09-05.html</guid><content:encoded>&lt;p&gt;It’s been quite a while since I wrote a devlog, and quite a lot has happened in
the project in between. I’ll try to merge the stuff from the commit logs and
stuff I posted on mastodon to give an overview. I’ve been coding the scanner
for most of the month. We consolidated the scanner into categories, with some
constraints on the combinator based on categories, so that you don’t have 2
scanners of the same category combined. Also you don’t want bullish/bearish
scanner combinations. There are 70 scanners and it’s hell to have to change
anything on the scanner interface. I’ve partially solved this problem by
extending the scanners from an abstract class, but for a feature called
parameter customization I still have to go over almost all scanners and add
their default parameters. I’ve also encountered a lot of performance issues
with scanner performance calculations. Doing the calculation based on last
years data took quite a while when I was using the scan results from the
database, so I decided to truncate the scan results kept in the database to a
months worth of data, and do all scanner runs on a years worth of data online
during the scanner performance calculations. Less DB round trips increased the
performance.  There was also an issue that ran into a sort of N select problem,
where the DB was queried in each iteration of the loop. I fixed this by using
an IN query to get all the stuff I needed before going into the loop.&lt;/p&gt;
&lt;p&gt;I had started using MongoDB for raw data such as OHLCV data and scanner
results, but I decided to get everything into MySQL as complex queries on
MongoDB are a pain. So I got rid of MongoDB for all modules in the project.  I
have a couple of ideas for parameter recommendations for indicators based on
the indicators values. I actually wanted to brute-force my way though some
parameter combos to find the best scoring combo for that symbol and indicator
but that leads to an unmanagable number of scans. Now I will try to recommend
RSI/Stoch overbought/oversold parameters based on the number that actually was
used as the turning point in the charts.&lt;/p&gt;
&lt;p&gt;There was progress on the web client as well. I setup a nice continuous
integration server that deploys all pushed commits and I also setup my router
with DynDNS and port forwarding so that the team can use the test environment.
I re-purposed my workstation as a Proxmox host (something I had already done
before) and I’m using my laptop as my workstation now. This kind of sucks
because it’s a weak weak machine. I don’t really want to spend money on a new
work station right now, as I have received my EAD and I’m planning to start
working somewhere after I get this project live. So back to the web client, we
have the main page almost setup, but since nobody in the team is a designer or
has any background related to design it doesn’t look professional to me. This
could be just a bias, I’m not sure. I put out the idea of paying someone to
design it, but it wasn’t received well – probably because we can’t visualize
what we want and cannot really tell the designer what he should do. The pricing
page, login and registration pages exists and are functional, but not really
tested. Testing and product management is a weak point in the team.&lt;/p&gt;
&lt;p&gt;So, product management for this project is actually quite simple: I expect wire
frames, use cases, and some testing from our PM.  He has no experience, but I
just can’t understand why somebody can’t simple research all this stuff and do
it. I have to step in at almost every step, and this is slowing us down and
demotivating me, as I don’t want to do this – that’s the point of having a
product manager.&lt;/p&gt;
&lt;p&gt;I’ve set a tight deadline to go live, per peter principle I want to keep
everybody on their toes, but my current status on this is yellow, that’s why
I’m also working on a B plan. The opportunity cost is just too high now that I
have the EAD.&lt;/p&gt;
</content:encoded></item><item><title>Efficient calculation of bollinger bands</title><description>a method to calculate the standard deviations for a period window over a list of numbers</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Tue, 21 Aug 2018 00:00:00 GMT</pubDate><guid isPermaLink="true">bollinger.html</guid><content:encoded>&lt;p&gt;The Bollinger bands used in technical analysis is the +/- 2 * standard deviation of the closing price plotted on the chart.
This prices are expected to fluctuate in this band 95% of the time. As with any sliding window calculation the easy way is
to calculate everything each time for each window. Which usually means quadratic algorithm. A better way exists to calculate
the values for standard deviations using some smart manipulations on the standard deviation formula. (to be more precise the
variance formula which is the square of the standard deviation.)&lt;/p&gt;
&lt;p&gt;To the variance formula is (k = )&lt;/p&gt;
&lt;p&gt;$$ \sum_{i=1}^{n} (price_i - mean)^2 $$&lt;/p&gt;
&lt;p&gt;expanding the quadratic term&lt;/p&gt;
&lt;p&gt;$$ \sum_{i=1}^{n} (price_i^2 - 2 \times price_i \times mean + mean^2) $$&lt;/p&gt;
&lt;p&gt;extracting the last constant term independent of i&lt;/p&gt;
&lt;p&gt;$$ \sum_{i=1}^{n} (price_i^2 - 2 \times price_i \times mean) + n \times mean^2 $$&lt;/p&gt;
&lt;p&gt;extract the term independent of i from the 2nd part&lt;/p&gt;
&lt;p&gt;$$ \sum_{i=1}^{n} (price_i^2) + \sum_{i=1}^{n}(-2 \times price_i) \times mean + n \times mean^2 $$&lt;/p&gt;
&lt;p&gt;first term and last term can be handled the way moving averages are handle. When the window slides right, add the new term
remove the old term on the left. This is efficient.&lt;/p&gt;
&lt;p&gt;$$ \sum_{i=1}^{n} price_i = total = mean \times n $$&lt;/p&gt;
&lt;p&gt;so the middle term becomes&lt;/p&gt;
&lt;p&gt;$$ -2 \times mean^2 \times n $$&lt;/p&gt;
&lt;p&gt;now the second term can also be calculated using the efficient method.&lt;/p&gt;
&lt;p&gt;Here is an implementation in code for bollinger bands&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-java"&gt;public SuperList&amp;lt;BollingerBand&amp;gt; calculate() {
    double totalAvg = 0d;
    double totalSq = 0d;
    int i = 0;
    SuperList&amp;lt;BollingerBand&amp;gt; result = new SuperList&amp;lt;&amp;gt;();
    for (Double value : values) {
        totalAvg += value;
        totalSq += value * value;
        if (i &amp;gt;= PERIOD - 1) {
            double avg = totalAvg / PERIOD;
            double stddev = Math.sqrt((totalSq - (totalAvg*totalAvg)/PERIOD)/ PERIOD);
            BollingerBand band = new BollingerBand(avg, avg + 2 * stddev, avg - 2 * stddev);
            result.add(band);
            totalAvg -= values.get(i - PERIOD + 1);
            totalSq -= values.get(i - PERIOD + 1) * values.get(i - PERIOD + 1);
        }
        i++;
    }
    return result;
}
&lt;/code&gt;&lt;/pre&gt;
</content:encoded></item><item><title>MySQL query log enable/disable</title><description>how to enable the mysql query log to see whats going on</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Wed, 15 Aug 2018 00:00:00 GMT</pubDate><guid isPermaLink="true">mysql-query-log.html</guid><content:encoded>&lt;p&gt;when programming with spring data jpa, it is sometimes usefull to see what querties MySQL is processing.
here is a way of doing that:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    mysql

    &amp;gt;set GLOBAL log_output = &amp;quot;FILE&amp;quot;;
    
    &amp;gt;set global general_log = &amp;quot;ON&amp;quot;;
    
    &amp;gt;set global general_log_file=&amp;quot;/tmp/mysql.log&amp;quot;;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;now just tail the mysql.log file to see the queries that are executed.&lt;/p&gt;
</content:encoded></item><item><title>TechScan DevLog 2018-08-10</title><description>Techscan August updates</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Fri, 10 Aug 2018 00:00:00 GMT</pubDate><guid isPermaLink="true">techscan_devlog_2018-08-10.html</guid><content:encoded>&lt;h2&gt;summary&lt;/h2&gt;
&lt;p&gt;• reboot the project • current status&lt;/p&gt;
&lt;h1&gt;Rebooting the project&lt;/h1&gt;
&lt;p&gt;A technical analyzer is one of those project I keep returning to. I had already
laid down a nice foundation with TaLib4J for the technical calculations so it’s
usually cleaning up the glue code that is changing with each new iteration.
This time around I’ve taken a new approach by building a team around the
project to drive me to turn it into a product. I’ve created a multi module
spring project with the following modules: API, Databus, Engine, corelib. The
API is the gateway for clients to access analysis data and takes care of user
management.  The databus module is an API for the api module to access the
data. The engine is a command line application that does the actual
calculations and the corelib is the module that contains common classes shared
by the modules. After initial testing it turned out that having the Databus as
a separate service comes with severe performance penalties due to JSON data
conversions etc, so I integrated the databus module into the corelib module.
You want to go service oriented until you realize that there are only 2 other
services that want to consume it and then you decide to integrate it back.
Keeping the engine separate made sense though as it runs as a batch processor.&lt;/p&gt;
&lt;h1&gt;Current status&lt;/h1&gt;
&lt;p&gt;As of today there are 33 unique scanners, and I also run the 2 element
combinations of these scanners for a total of 33c2 (528) scanners.  This
produces around 6 M scan results for a 20 month worth of stock EOD data. I want
to increase the combination count but I’m not sure if the server I have in mind
for production deployment can handle the amount. That’s on my try this list and
will report how it goes.  I have most of the basic user management features
completed in the API, except for the integrations to payment and transactional
emails.  I’m also adding performance evaluation for the scanners by means of
running a test from the date the signal was generated going forward and
checking the price went up/down X ATRs confirming the signal. This calculation
is affected by the amount of scan results so increasing the combination count
will have an impact on the performance calculation. I’ve asked a question on
the math StackExchange forum about calculating the conditional probability of 2
technical indicator but have yet to receive a satisfying answer. Being able to
calculate a reasonably (~%1 error maybe?) accurate approximation for this would
mean that I do not have the actually run all the combinations to get their
scores. I’m also using an error rate calculation based on Z-tables to give a
confidence interval on the scanner score.  A nice optimization I did was to
keep all the stock OHLCV data in cache and use a binary search to query data
between given dates instead of hitting the DB for each time. In the earlier
version I was actually keeping the raw OHLCV data in files but reading them
into cache takes longer than reading them from a DB plus using a DB also gives
opportunities for querying in different ways which I need in the future.&lt;/p&gt;
&lt;p&gt;Yesterday I noticed that one the scanners used 4 conditions to check for a
signal ma5 &amp;gt; ma26 , ma26 &amp;gt; ma50, ma50 &amp;gt; ma200, stoch &amp;lt; 20.  This led me to the
idea that I should actually make each of these conditions a scanner on it’s own
and brute force my way through all of the combinations to reach the ideal
scenario for each symbol by calculating the score. Maybe the best results for a
stock are when ma5 &amp;lt; ma26, ma26 &amp;gt; ma50, … because there was a short term fall
in the price for the stoch to reach a low etc.  I also implemented an
optimization for the score calculator yesterday. Pre-optimization I was looping
each symbol, fetching the scan results for each symbol and calculating the
score for the scanners from those results. This was doing too much DB round
trips. I changed it to looping through each scanner combination and storing the
results of the scans in a map keyed by it’s symbol. This is 1 less loop and
less DB requests.&lt;/p&gt;
</content:encoded></item><item><title>Yazilimin birimi</title><description>🇹🇷90larda Netas'in yazilim fiyatlamasi icin devletin anlayacagi bir model gelistirmesinin hikayesi</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Tue, 19 Jun 2018 00:00:00 GMT</pubDate><guid isPermaLink="true">netas.html</guid><content:encoded>&lt;p&gt;1990larda turkiye'de yazilim hakkinda Ali Akurgal'in (Netas ARGE muduru) bir anisi. Baslamadan &amp;quot;hayali ihracat&amp;quot; diye bir konsept turemisti 90larda. Devletin ihracati arttirmak icin sundugu tesvikleri somurmek uzerine kurulmus bir cesit hile hurda.&lt;/p&gt;
&lt;p&gt;Siz, yazilimin birimi nedir bilir misiniz?&lt;/p&gt;
&lt;p&gt;Metre.
Evet metre.
Neden metredir bilir misiniz?&lt;/p&gt;
&lt;p&gt;Anlatayim:
1992 yilinda, yâni topu topu 20 yil önce, Netasta ilk yazilim ihracatini gerçeklestirdik. Hazirlanan bir yazilim paketini; tusa bastik, o zaman internet falan yok, çatidaki çanak marifeti ile, vallahi de billahi de müthis bir hiz olan 128kb/s ile, Ingiltereye uydu üzerinden yolladik. Faturayi da pullu posta ile yolladik. 2M$ bankaya geldi, kasaya koyduk.&lt;/p&gt;
&lt;p&gt;Aradan 3-4 ay geçti, vergi memurlari geldiler. Dediler ki, siz bir fatura yollamissiniz, 2M$. Evet dedik. Bu para ödenmis dediler. Evet dedik. Ama mal çikisi yok, bu hayali ihracat dediler!&lt;/p&gt;
&lt;p&gt;Bunun üzerine vergi memurlarini ArGeye aldik, bir bilgisayarin basina oturttuk. Su enter tusuna basar misiniz dedik. Biri basti. Sonra ne oldu diye sordu. 300k$lik ihracat yaptiniz, bunun da faturasini yollayacagiz, o da ödenecek dedik. Adam suça ortak olmus oldugu için çok kötü oldu. Sonra yazilim nasil yazilir, uydu baglantisi nedir, bu ne kadar para eder bunlari gezdirip gösterip anlattik. Adamlar çok iyi anladik ama mal çikisi olmasi lâzim, mevzuat böyle dediler.&lt;/p&gt;
&lt;p&gt;Bunun üzerine dedik ki: biz bu yazilimi banda kaydedelim ( o zaman CD yok, hattâ kaset bile yok, ½ makarali bant kullaniliyor) onu yollayalim. Adamlar bir çözüm bulmus olmanin sevinci ile tamam dediler, kaydedin yollayin. Ihraç ettigimiz yazilimin kaydi iki makara etti. Bunlar paketlendi ve gümrük komisyoncusuna verildi. Komisyoncu, bunlari gümrüge götürdü ve ihracat islemine basladi. Gümrük memuru, islemi yapmis yapmis ve bir noktada sormus: TIRlar nerede?. Komisyoncu da TIR MIR yok hepsi bu iki zarf demis, masanin üzerindeki teyp bantlarini göstermis. Gümrük memuru bu iki zarf 2M$ edemez, ben bu islemi yapamam demis, birakmis.&lt;/p&gt;
&lt;p&gt;Mahkemeye gidildi, bilirkisi heyeti kuruldu, bizim o iki makaradaki yazilimin 2M$ edip etmeyecegini (nasil baktilarsa?) inceledi. Neyse ki, 2M$ eder dediler de hayali ihracattan kurtulduk. Bu sefer, ayni komisyoncu, ayni gümrük memuruna ayni iki makarayi 2M$ eder mahkeme karari ile götürüp islemi yeniden baslatti. Ancak, gene islem sirasinda, ihraç malinin birim fiyati, miktari ve toplam fiyatinin girilmesi gerekiyor. Mevzuat öyle. Ne yapsinlar, is daha uzamasin diye bakmislar zarfta teyp bandi var, bir makarada kaç metre bant vardir diye kestirmisler, makarasi 1.000 metreden 2.000 metre yazilim ihraç etmis olmusuz.&lt;/p&gt;
&lt;p&gt;Yaaa, yazilimin birimi metre. Iste böyle.&lt;/p&gt;
</content:encoded></item><item><title>TechScan DevLog 2018-06-01</title><description>Techscan June updates</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Fri, 01 Jun 2018 00:00:00 GMT</pubDate><guid isPermaLink="true">techscan_devlog_2018-06-01.html</guid><content:encoded>&lt;p&gt;A new month is here and time goes by fast. There is a theory about the
perception that the older you get to faster time seems to go by is due
to the fact that the percentage of time relative to your age gets smaller.
E.g a year when you are 5 years old is 20% of your age and is a long duration.
But when you are 40 it’s only 2.5% of your age and it goes by faster.&lt;/p&gt;
&lt;p&gt;So what’s new? I’ve concentrated on the stock viewing page today. Every
parameter that I had hard coded during the design phase is now the
actual value it’s supposed to be. So the main part of the stock view
page is complete. The Thymeleaf style does take a bit getting used to
but I have figured out everything I needed to do.&lt;/p&gt;
&lt;p&gt;A nasty bug I came across was the dates of the technical and scans
was the date the user wanted to scan. Randomly I tried a date when testing
and I saw in the database that this was a weekend. So I fixed that by using
the last date in the data returned from the API.&lt;/p&gt;
&lt;p&gt;Another related issue was that dates from the API were showing up as weekends.
This is due to the fact that the IEX API returns a string for the date
field and the JSON parser just uses the current timezone and this ends
up being a date before the date in the string. Easy fix, just set
the timezone to EST where the stock exchanges are.&lt;/p&gt;
</content:encoded></item><item><title>TechScan DevLog 2018-05-30</title><description>Techscan updates</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Wed, 30 May 2018 00:00:00 GMT</pubDate><guid isPermaLink="true">techscan_devlog_2018-05-30.html</guid><content:encoded>&lt;h2&gt;summary&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;UI design&lt;/li&gt;
&lt;li&gt;technicals&lt;/li&gt;
&lt;li&gt;performance&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;now that the foundation for getting the data and caching properly was complete
and I had a couple of scanners going I started on the technical indicator
calculations. The first batch contains&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;price&lt;/li&gt;
&lt;li&gt;price change percentage&lt;/li&gt;
&lt;li&gt;ATR&lt;/li&gt;
&lt;li&gt;ADX&lt;/li&gt;
&lt;li&gt;DI +/-&lt;/li&gt;
&lt;li&gt;Long, medium and short term trends based on moving averages&lt;/li&gt;
&lt;li&gt;52 week high and low&lt;/li&gt;
&lt;li&gt;average volume&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;At first I thought I’d only store 1 record per symbol containing the most
up-to-date data on the instrument, but then I opted for storing the history of
the technical data as well. I could be useful to browse them later.&lt;/p&gt;
&lt;p&gt;When running the technical calculations I noticed that the Redis cache
retrieval code was still not fast enough. I also tweaked that code. Instead of
making N parallel requests to Redis per stock symbol and parsing and storing
them in the local cache, I do a single multi get to Redis, then parse the JSON
data in parallel and store them into the cache. This is way faster (I didn’t
measure the exact amount). Even after this optimization it was still not fast
enough. I can’t wait more than 10 seconds for the cache warm-up. So I checked
the next offender which is the JSON parsing. People on the net did benchmarks
on the GSON library performance and it looked like it was one of the slowest
libraries around. I thought that maybe using org.json could be better without
using any reflection but that is the only library out there that’s slower than
GSON. Luckily the library that comes with spring (Jackson) is one of the
fastest so I switched to using that and the results were amazing.&lt;/p&gt;
&lt;p&gt;GSON parser took 133 seconds to parse ~6.000 items, while Jackson took 1.7s to
parse the same items. After this improvement I could run the technical data
without wasting time on the application startup.&lt;/p&gt;
&lt;p&gt;Another matter that was annoying was the NaN values that TaLib4J returns. I
didn’t really expect to see a NaN value but some of the data from IEX for some
stocks contains no opening/closing prices or the stock didn’t trade at all some
days so the prices are all the same. This led to NaN values in the library. I
sorted these out.&lt;/p&gt;
&lt;p&gt;I also started on the stock data display page GUI design. Foundation CSS
provides a nice framework for the layout etc so I’m not using bootstrap.&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/stocktoot2-1.png"&gt;/img/stocktoot2-1.png&lt;/a&gt;&lt;/p&gt;
</content:encoded></item><item><title>Using Kruskal's MST algorithm for warp lane generation</title><description>making sure all stars in a galaxy are connected</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Wed, 09 May 2018 00:00:00 GMT</pubDate><guid isPermaLink="true">kruskal-galaxy-mst.html</guid><content:encoded>&lt;p&gt;Almost every sci-fi / space themed game has warp lanes connecting the star systems in the game. I've come across this quite often so here is a small piece of code that implements a Minimum spanning tree between the stars to guarantee all of them are reachable.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public class WarpLaneBuilder
    {
        List&amp;lt;HashSet&amp;lt;StarSystem&amp;gt;&amp;gt; sets = new List&amp;lt;HashSet&amp;lt;StarSystem&amp;gt;&amp;gt;();
        public void GenerateWarpLanes(List&amp;lt;StarSystem&amp;gt; stars)
        {
            foreach (var star in stars)
            {
                var set = new HashSet&amp;lt;StarSystem&amp;gt;();
                set.Add(star);
                sets.Add(set);
            }

            var edges = BuildEdges(stars);
            var results = new HashSet&amp;lt;Edge&amp;gt;();
            foreach (var edge in edges)
            {
                var set1 = Find(edge.Source);
                var set2 = Find(edge.Target);
                if (!set1.Equals(set2))
                {
                    results.Add(edge);
                    Union(set1, set2);
                }
            }

            foreach (var result in results)
            {
                result.Source.WarpLanes.Add(result.Target);
                result.Target.WarpLanes.Add(result.Source);
            }

        }

        private List&amp;lt;Edge&amp;gt; BuildEdges(List&amp;lt;StarSystem&amp;gt; stars)
        {
            List&amp;lt;Edge&amp;gt; edges = new List&amp;lt;Edge&amp;gt;();
            for (int i = 0; i &amp;lt; stars.Count - 1; i++)
            {
                for (int j = i + 1; j &amp;lt; stars.Count; j++)
                {
                    edges.Add(new Edge(stars[i], stars[j], stars[i].DistanceTo(stars[j])));
                }
            }
            edges.Sort((x,y) =&amp;gt; x.Weight.CompareTo(y.Weight));
            return edges;
        }

        private HashSet&amp;lt;StarSystem&amp;gt; Find(StarSystem star)
        {
            return sets.First(x =&amp;gt; x.Contains(star));
        }

        private void Union(HashSet&amp;lt;StarSystem&amp;gt; set1, HashSet&amp;lt;StarSystem&amp;gt; set2 )
        {
            sets.Remove(set1);
            sets.Remove(set2);
            set1.UnionWith(set2);
            sets.Add(set1);
        }

        private class Edge
        {
            public StarSystem Source;
            public StarSystem Target;
            public double Weight;

            public Edge(StarSystem source, StarSystem target, double weight)
            {
                Source = source;
                Target = target;
                Weight = weight;
            }
        }
    }
&lt;/code&gt;&lt;/pre&gt;
</content:encoded></item><item><title>Galaxy generation algorithm</title><description>a method for generating a galaxy for a space game</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Wed, 09 May 2018 00:00:00 GMT</pubDate><guid isPermaLink="true">procedural-galaxy-generation.html</guid><content:encoded>&lt;p&gt;an integral part of a 4x space game is the galaxy generation. Galaxy generation means speading out the stars in your galaxy in a way that looks good,
should resemeble reality and must satisfy some constraints. If you take a look at the maps fom old 4x games you will see that the stars are laid out in a very 
linear fashion. The method used here is splitting the coordinate plane into sectors of a defined height/width and then randomly placing stars in side this 
satisfying a density constraint. You also have to check the neighboring sectors for stars that are near the border otherwise you might end up with star 
that are very close to each other. This is a tedious way of going about things and the end result isn’t that satisfactory.&lt;/p&gt;
&lt;p&gt;Here is an example of the sector method&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/57c7fdc9d8a3b.png"&gt;/img/57c7fdc9d8a3b.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;A better method is generating a spiral galaxy. I’ve being doing some research on the subject and there are various methods even some involving actual 
astro-physical calculations (simplified) but these are still to complicated and a better approximated result can be obtained will less hassle. 
Here is the version that I found which works quite well&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/57c7fdedc12aa-2.png"&gt;/img/57c7fdedc12aa-2.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Each black dot represents a star in the system. I think it looks nice and quasi realistic. The code to accomplish this layout is&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; public Galaxy generate(Galaxy galaxy) {

        int NUMHUB = 20;
        int NUMDISK = 5000;
        double DISKRAD = 400;
        double HUBRAD = 50;
        int NUMARMS = 3;
        double ARMROTS = 0.5;
        double ARMWIDTH = 65.0;
        double FUZZ = 25.0;

        double omega = 360 / NUMARMS;
        int i = 0;
        while (i &amp;lt; NUMDISK) {
            i++;

            double dist = HUBRAD + RandomUtils.nextFloat(0, 1) * DISKRAD;
            double theta = ((360.0 * ARMROTS * (dist / DISKRAD))) + RandomUtils.nextFloat(0, 1) * ARMWIDTH
                    + omega * RandomUtils.nextInt(0, NUMARMS) + RandomUtils.nextFloat(0, 1) * FUZZ * 2.0 - FUZZ;

            double x = Math.cos(theta * Math.PI / 180) * dist;
            double y = Math.sin(theta * Math.PI / 180) * dist;

            Star star = starService.create(x + galaxy.getSize().getWidth() /2 , y + galaxy.getSize().getHeight() / 2);
            if (!isDensitySatisfied(galaxy, star)) { //make sure that the stars are not too close to eachother
                LOGGER.info(&amp;quot;density condition failed.&amp;quot;);
                continue;
            }
            galaxy.getStars().add(star);
        }

        i = 0;
        while (i &amp;lt; NUMHUB) {
            i++;

            double dist = RandomUtils.nextFloat(0, 1) * HUBRAD;
            double theta = RandomUtils.nextFloat(0, 1) * 360;
            double x = Math.cos(theta * Math.PI / 180) * dist;
            double y = Math.sin(theta * Math.PI / 180) * dist;
            Star star = starService.create(x + 500, y + 500);
            if (!isDensitySatisfied(galaxy, star)) {
                LOGGER.info(&amp;quot;density condition failed.&amp;quot;);
                continue;
            }

            galaxy.getStars().add(star);
        }

        return galaxy;

    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here is a legend of what the knobs in the code actually tweak&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/57c7fe1749fc3-2.png"&gt;/img/57c7fe1749fc3-2.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The only gotcha here is that you may not get the number of stars that you requested if the density checking function returns false for some stars. 
But thats no big problem as you are requesting a constraint be satisfied.
The algorithm used is by Ben Motz &amp;lt;motzb-at-hotmail.com&amp;gt; The original C source code for DOS (including a 3D viewer).&lt;/p&gt;
</content:encoded></item><item><title>ChessPresso extract FEN</title><description>using the chesspresso library</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Wed, 09 May 2018 00:00:00 GMT</pubDate><guid isPermaLink="true">chesspresso-fen-extract.html</guid><content:encoded>&lt;p&gt;Chesspresso is a great library for processing chess games stored in PGN format. One of the greatest uses I have found for chesspresso is using it to extract FENs of the current position on the board. I’ve used this for example to create a candidate move selector in a chess database application. 
Here is a an example usage to extract the FENs from a game PGN given as a String:&lt;/p&gt;
&lt;pre&gt;
ByteArrayInputStream bis = new ByteArrayInputStream(singleGame.getBytes());
PGNReader pgnReader = new PGNReader(bis, "");
Game game;
game = pgnReader.parseGame();
if (game == null) return null;
game.gotoStart();
Move[] mainLine = game.getMainLine();
for (int i = 0; i &lt; mainLine.length; i++) {
    Move move = mainLine[i];
    String fen = game.getPosition().getFEN();
    System.out.println(fen);
    game.getPosition().doMove(move);
}
&lt;/pre&gt;
</content:encoded></item><item><title>CORS with spring boot</title><description>setting up a CORS filter in spring boot</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Wed, 09 May 2018 00:00:00 GMT</pubDate><guid isPermaLink="true">cors-with-spring-boot.html</guid><content:encoded>&lt;p&gt;CORS (Cross Origin Resource Sharing) allows to make cross domain ajax requests for allowed domain. To setup CORS in spring add the following filter&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@Component
public class CORSFilter implements Filter {
    @Override
    public void init(FilterConfig filterConfig) throws ServletException {

    }

    @Override
    public void doFilter(ServletRequest req, ServletResponse res, FilterChain chain) throws IOException, ServletException {
        HttpServletResponse response = (HttpServletResponse) res;
        response.setHeader(&amp;quot;Access-Control-Allow-Origin&amp;quot;, &amp;quot;*&amp;quot;);
        response.setHeader(&amp;quot;Access-Control-Allow-Methods&amp;quot;, &amp;quot;POST, GET, PUT, OPTIONS, DELETE&amp;quot;);
        response.setHeader(&amp;quot;Access-Control-Max-Age&amp;quot;, &amp;quot;3600&amp;quot;);
        response.setHeader(&amp;quot;Access-Control-Allow-Headers&amp;quot;, &amp;quot;Origin, X-Requested-With, Content-Type, Accept&amp;quot;);
        chain.doFilter(req, res);
    }

    @Override
    public void destroy() {

    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The ‘Access-Control-Allow-Origin’ parameter controls which domains will be allowed to make cross domain requests and ‘Access-Control-Allow-Methods’ defines the methods that will be allowed&lt;/p&gt;
</content:encoded></item><item><title>ITTB devlog 2018-05-09</title><description>AI, movement, animations updates</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Wed, 09 May 2018 00:00:00 GMT</pubDate><guid isPermaLink="true">ittb_devlog-2018-05-09.html</guid><content:encoded>&lt;h2&gt;Summary&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;AI, movement&lt;/li&gt;
&lt;li&gt;movement animations&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;over the last 2 days the AI got a lot of attention. Moving to random tiles with in the range
was annoying anyway so I implemented a target selection algorithm. The basics are the same 
for the algorithm I had used in the prototype. Pick the closest building based on euclidean
distance and go towards that. This type of target selection may sometimes lead to what would
seem as non optimal. Such as the case&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;. . . . .
1 x . @ .
. x . . .
. x . . .
. x . . .
. . . . .
. . . 2 .
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;@ = player&lt;/p&gt;
&lt;p&gt;1 = target&lt;/p&gt;
&lt;p&gt;2 = target&lt;/p&gt;
&lt;p&gt;x = blocker&lt;/p&gt;
&lt;p&gt;Here the closest target is 1 based on euclidean distance, when in fact the path to that target
is way longer than the path to target 2.&lt;/p&gt;
&lt;p&gt;But “optimal” is not what I’m searching for. It’s OK to make the game unpredictable at times,
so it doesn’t get boring. After the target selection, I added the ability to show a target indication
for enemies. This is actually a ‘threat’ indication as the attack will happen next turn. The enemies
stay committed to the direction they are attacking if they lock on to a target and will attack
in that direction if they are pushed/pulled or dislodged some other way. I also added the force move
and it’s damage effects on the units. I realized that if a weapon can do more than 1 tile force move
the code has to be in the movement class, as the damage effects need to be applied after the animation
to that tile is complete. This lead to the need for separating the movement animation code from the 
movement class into a separate component. I also needed to add a “Fly” method that doesn’t check if
the path to a target node contains blockers, as I want the unit to crash into the blockers. While at
it I also changed the way the movement animations were done. Previously I was LERP’ing the movement 
between the tiles, which lead to a movement that gradually sped up when it was getting near to it’s 
target. Now I just use a simple method to calculate the amount to move and animate the movement in a
linear fashion, which made the animations look better. The idea is quite simple, I don’t know why I
didn’t do it in the first place:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;distance = Speed * Time.deltaTime //distance to travel this frame
dir = target.position - my.position
if (dir.magnitude &amp;gt; distance) {
  translate(dir.normalized * distance)
} else {
  my.position = target.position
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I also added an in game console, which I use for messages as the unity Debug.Log sucks.&lt;/p&gt;
</content:encoded></item><item><title>Galaxy hyper lane generation</title><description>a few different methods for generating travel lanes between stars</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Wed, 09 May 2018 00:00:00 GMT</pubDate><guid isPermaLink="true">galaxy-hyper-lane-generation.html</guid><content:encoded>&lt;p&gt;Hyper lanes a.k.a Warp Lanes? What are those? They are a simple element of most space RTS/TBS games. They the lines that connect the stars. They are the highway lanes of spacetime, they enable spaceships to travel through them and guide the spaceships to their destination. They are a cheap alternative to wormhole generators which bend spacetime to connect stars. Here are what they look like from a popular game&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/58a34c67daa29.png"&gt;/img/58a34c67daa29.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Technically speaking they are edges (the lines) between vertices (stars). What we need to do is generate these edges given a set of vertices and there a couple of methods for doing this. The first one that pops up is to generate a minimum spanning tree. But a minimum spanning tree would look this&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/58a34d26a9467.png"&gt;/img/58a34d26a9467.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;and this doesn't exactly look like a nice interstellar highway as we would like to be able to travel to a couple of nearby stars from our origin star. This way when we are trying to reach a distant star we have multiple options of getting to that star. Image that you did your warp lanes using an MST and you want to get from star A to star D and the only path is A -&amp;gt; B -&amp;gt; C -&amp;gt; D. What do you do if there is an enemy fleet in the star C system and you don't want to engage that fleet with your science ship? Observe that the MST has only 1 connection between 2 neighboring stars so there is no way for you to do that.&lt;/p&gt;
&lt;p&gt;So here is a naive algorithm I came up with&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;let S be a list star with random coordinates in a 1000x1000 plane&lt;/li&gt;
&lt;li&gt;for each star in S&lt;ol&gt;
&lt;li&gt;if star was visited before, skip it&lt;/li&gt;
&lt;li&gt;get the N closest stars to this star&lt;/li&gt;
&lt;li&gt;add a connection from this star to its neighbors&lt;/li&gt;
&lt;li&gt;add a connection from each neighbor to this star&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;the get closest star also needs some attention as we don't want to return a close neighbor if it already has a connection to the current star.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;filter out all other stars except our current star&lt;/li&gt;
&lt;li&gt;filter out all stars that already have a connection with the current star&lt;/li&gt;
&lt;li&gt;map the remaining stars as a tuple of ( distance to source, this star)&lt;/li&gt;
&lt;li&gt;sort by the distance&lt;/li&gt;
&lt;li&gt;take N closest and return the stars from the tuple&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The N parameter determines the number of max connections going out from a star.
Here is an image of this algorithm with N=5&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/58a34f85a5be6.png"&gt;/img/58a34f85a5be6.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This does look a bit better but there are too many cramped points where it's hard to tell what's going on. The stars are too close to each other so we need some kind of regulation when generating the random points for the stars. One way of doing this is checking the &amp;quot;star density&amp;quot; when generating the star and only placing the star if it's acceptable. This basically means not placing a star to close another and we can do this by checking if the generated star falls within a range of existing stars. That would be done by checking if it lies in a circle of radius R with the star at its origin.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;let S be a list of stars initially empty&lt;/li&gt;
&lt;li&gt;while S size &amp;lt; number of stars to generate&lt;/li&gt;
&lt;li&gt;generate a random point in the plane&lt;/li&gt;
&lt;li&gt;if this point satisfies the density condition add the star to S&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;One point to note about this algorithm is that it has the possibility of never terminating if the density conditions are too strict and it cannot find a good place for the next star. So it's a good idea to add a loop counter check that will terminate with an exception after a number of tries and tell the user to relax the number of stars and the radius R. The acceptable density function can be done as follows&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;let R be the minimum distance that two stars should be apart (which is the radius R)&lt;/li&gt;
&lt;li&gt;for each star already generated check if (src.x - star.x)^2 - (src.y - star.y)^2 &amp;lt; R^2&lt;/li&gt;
&lt;li&gt;if there are stars that satisfy this equation then the density condition is not satisfied.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;After adding the density check and reducing N to 3 the lines look a bit clearer.&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/58a352d019823.png"&gt;/img/58a352d019823.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;There is a fundamental error in this approach. If you select a low N (connectivity value) then you sometimes will get disconnected stars like this&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/58a36eaca414e.png"&gt;/img/58a36eaca414e.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;To address this issue a combination of an MST and the naive approach could work.&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/58a36f7ad5694.png"&gt;/img/58a36f7ad5694.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Now that the MST guarantees that all the graph will be connected we have addressed the issue but still, the layout doesn't look good for efficient traveling. We still could use more triangulation that is more lanes connecting nearby stars. Using the closest N method led to a cluttered layout. The cause of this clutter is that if 2 stars are almost in a straight line and are the 2 closest stars, there will 2 connections to these stars that overlap.&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/58a37252c62a7.png"&gt;/img/58a37252c62a7.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Yet another way of connecting the stars would be to use Delaunay Triangulation. This also produces a very nice warp lane structure but still, has the cluttering problem due to the star layout.&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/58a37861e14cc.png"&gt;/img/58a37861e14cc.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Now let's address the clutter problem. It seem that the warp lanes look cluttered if there are neighboring stars too close to an existing warp lane.&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/58a385c4c845c.png"&gt;/img/58a385c4c845c.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;the green arrow shows a lane we could do better without. How can we detect these lanes? Just from the definition of the problem. If a neighbor star is too close to a lane, drop the existing lane so the closer lane to the a star will remain. Here is a simple outline for the algorithm that requires a bit of linear algebra:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Sort all the neighbors for each star is descending order according to their distance from the origin star.&lt;/li&gt;
&lt;li&gt;for each neighbor i to all neighbors - 1&lt;ol&gt;
&lt;li&gt;for each neighbor j from i + 1 to all neighbors&lt;/li&gt;
&lt;li&gt;if the distance of neighbor i from the lane between origin star and neighbor j &amp;lt; some threshold T discard the lane&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;calculating the distance of a point P0 to a line given by P1 and P2 is&lt;/p&gt;
&lt;p&gt;$$ \bigl|\frac{(y_2 - y_1) \times x_0 - (x_2 - x_1) \times y_0 + x_2 \times y_1 - y_2 \times x_1}{\sqrt{(y_2-y_1)^2 + (x_2-x_1)^2}}\bigr| $$&lt;/p&gt;
&lt;p&gt;Here is the result of a relaxed threshold that will draw a lot of lanes&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/58a3871f9072d.png"&gt;/img/58a3871f9072d.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;here are the same results with a stricter threshold that has discarded the middle lane&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/58a387534357e.png"&gt;/img/58a387534357e.png&lt;/a&gt;&lt;/p&gt;
</content:encoded></item><item><title>LetterPress helper</title><description>a simple script to generate the maximum scoring words in LetterPress</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Wed, 09 May 2018 00:00:00 GMT</pubDate><guid isPermaLink="true">letterpress-helper.html</guid><content:encoded>&lt;p&gt;LetterPress is a nice combination of Go and scrabble. Here are a few lines of scala code that will give a decisive advantage&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import scala.io.Source
def freq(w:String) : Map[Char,Int] = {
 w.map(x=&amp;gt;(x,1)).groupBy(_._1).map { 
  case (key,values) =&amp;gt; (key, values.map(_._2).sum)
  }
}

val src = freq(&amp;quot;rfcdpnrxqgeruenaolhntutim&amp;quot;)
//val src = freq(&amp;quot;wasttaxnmerhenriehxldtihr&amp;quot;)

val words = Source.fromFile(&amp;quot;corncob_lowercase.txt&amp;quot;).getLines.toList.map(_.trim)
val f = words.map(x=&amp;gt;(x, freq(x)))
f.filter(x=&amp;gt; x._2.map({ case (k,v) =&amp;gt; src.contains(k) &amp;amp;&amp;amp; src(k) &amp;gt;= v}).forall(x=&amp;gt;x == true) )
 .sortWith(_._1.size &amp;gt; _._1.size)
 .take(10)
 .foreach(println)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Explanation&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The logic behind it is very simple:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;count the frequencies of the letters on the board (the src var has this)&lt;/li&gt;
&lt;li&gt;count the frequencies of all the letters per word in the dictionary &lt;code&gt;( (word, Map(w-&amp;gt;1,o-&amp;gt;1,r-&amp;gt;1,d-&amp;gt;) )&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;filter out all the words that have letter frequencies less than or equal to the letters on the board&lt;/li&gt;
&lt;li&gt;sort these by word length&lt;/li&gt;
&lt;/ul&gt;
</content:encoded></item><item><title>Scrabble Island detection</title><description>java code to detect an invalid board for scrabble</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Wed, 09 May 2018 00:00:00 GMT</pubDate><guid isPermaLink="true">scrabble-island-detection.html</guid><content:encoded>&lt;p&gt;there is a game app called “kelimelik” which is a Turkish version of scrabble that I’ve been playing for a while now which is quite fun. So I thought it might be a nice way to waste a couple of hours trying to write a program that would give the highest scoring word given a board state. Most of the program is quite trivial in that it just has to generate permutations of the given letters and place them in all possible combinations on the board and then check if the board is valid. E.g that all the words on the board are in a dictionary and all the tiles are connected. The second part of the validity check is interesting. The first thing that popped to my mind was using a flood-fill algorithm starting from the tile nearest to the top-left corner. After the fill if there are any tiles on the board that are unmarked then there is more than 1 island on the board and the board is invalid. So how does a flood-fill algorithm work? Quite simple actually. You mark the current tile you are on at (x,y) and recurse to the neighbors if they are not empty, or have not been marked. Here is a simple bit code that does this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;private boolean connectedCheck(int i, int j, String[][] board) {
    board[i][j] = &amp;quot;!&amp;quot;;
    boolean resh = true;
    boolean resv = true;
    boolean resh2 = true;
    boolean resv2 = true;
    if (i &amp;lt; 14 &amp;amp;&amp;amp; !board[i + 1][j].equals(&amp;quot;*&amp;quot;) &amp;amp;&amp;amp; !board[i + 1][j].equals(&amp;quot;!&amp;quot;)) {
        connectedCheck(i + 1, j, board);
    }
    if (i &amp;gt; 0 &amp;amp;&amp;amp; !board[i - 1][j].equals(&amp;quot;*&amp;quot;) &amp;amp;&amp;amp; !board[i - 1][j].equals(&amp;quot;!&amp;quot;)) {
        connectedCheck(i - 1, j, board);
    }
    if (j &amp;lt; 14 &amp;amp;&amp;amp; !board[i][j + 1].equals(&amp;quot;*&amp;quot;) &amp;amp;&amp;amp; !board[i][j + 1].equals(&amp;quot;!&amp;quot;)) {
        connectedCheck(i, j + 1, board);
    }
    if (j &amp;gt; 0 &amp;amp;&amp;amp; !board[i][j - 1].equals(&amp;quot;*&amp;quot;) &amp;amp;&amp;amp; !board[i][j - 1].equals(&amp;quot;!&amp;quot;)) {
        connectedCheck(i, j - 1, board);
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;empty squares are noted as “*”, tiles with the letter and marked tiles with “!”. Here is a 3×3 board array for reference:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;|   |   |   |
|---|---|---|
|*  | * | * |
|A  | * | * |
|B  | C | * |

&lt;/code&gt;&lt;/pre&gt;
</content:encoded></item><item><title>3 different approaches to the same problem</title><description>finding the first unique character in a string</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Wed, 09 May 2018 00:00:00 GMT</pubDate><guid isPermaLink="true">3-different-approaches.html</guid><content:encoded>&lt;p&gt;I came a across a seemingly simple problem today that turned out to have multiple solutions with varying efficiency. These type of problems are very well suited for step by step iterative solutions where each step you improve upon the existing solution. 
The problem is the simple matter of find the first unique character in a string. 
I'm skipping the obvious solution of starting at the beginning of the string and scanning through the string comparing the current charater with every other. This type of solution will lead to an N^2 solution which is usually unacceptable. Think that you are searching a DNA sequence of 10 million nucleotides. No way exponential solutions are going to work. 
So the first solution is this:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;scan the list from left, and keep track of the characters and the number of times we have seen a character.&lt;/li&gt;
&lt;li&gt;scan the list from left and lookup the number of times the current character was seen. If it's 1 then we've found the first non-repeating character.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;Character findFirstUniqWorst(String s) {
        HashMap&amp;lt;Character, Integer&amp;gt; map = new HashMap&amp;lt;&amp;gt;();
        for (char c : s.toCharArray()) {
            if (!map.containsKey(c)) {
                map.put(c, 0);
            }
            int e = map.get(c);
            map.put(c, e + 1);
        }

        for (char c: s.toCharArray()) {
            if (map.get(c) == 1) {

                return c;
            }
        }

        throw new RuntimeException();
    }

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;an improvement on this would be to eliminate the 2nd scan. If we stored the position of the 1st occurance of a character with the count we could return that. Something like:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;scan the list from the left and build the count map. Store the position of the first occurance too like 'a'-&amp;gt;(count, position)&lt;/li&gt;
&lt;li&gt;scan the map and return the result with count equal to 1 having to lowest position.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;static class Pair {
        public int count;
        public int position;

        public Pair(int count, int position) {
            this.count = count;
            this.position = position;
        }
    }
    Character findFirstUniqMed(String s) {
        HashMap&amp;lt;Character, Pair&amp;gt; map = new HashMap&amp;lt;&amp;gt;();
        char[] chars = s.toCharArray();
        for (int i=0;i&amp;lt;chars.length;i++) {
            char c = chars[i];
            if (!map.containsKey(c)) {
                map.put(c, new Pair(1, i));
            } else {
                Pair e = map.get(c);
                e.count += 1;
                map.put(c, e);
            }
        }
        int index = Integer.MAX_VALUE;
        Character returnChar = null;
        for (Character c : map.keySet()) {
            if (map.get(c).count == 1) {
                if (map.get(c).position &amp;lt; index) {
                    returnChar = c;
                }
            }
        }
        return returnChar;
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;this is a good option if the alphabet is small like in the DNA example. But if the alphabet is large, we still would do a large scan. So enter the third option: 
instead of keeping the position of the character, keep a pointer to a linked list node. This linkedlist will hold the the unique characters we've seen so far and the head of the link list will be the first.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;scan the list from the left.&lt;ol&gt;
&lt;li&gt;if the character is not in the map, insert a node to the tail of the list and add the (char-&amp;gt;node) mapping&lt;/li&gt;
&lt;li&gt;if the characater is in the map, and pointer to a node exists remove the node from the link delete, set (char-&amp;gt;null) as the mapping&lt;/li&gt;
&lt;li&gt;if the character is in the map and the pointer doesn't exists do nothing and continue with the next.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;this method will scan the input string once but return the first found character o(1).&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;static class DoubleLinkedList {
        public Character value;
        public DoubleLinkedList prev;
        public DoubleLinkedList next;
    }
    Character findFirstUniqBest(String s) {
        char[] chars = s.toCharArray();
        DoubleLinkedList list = new DoubleLinkedList();
        HashMap&amp;lt;Character, DoubleLinkedList&amp;gt; map = new HashMap&amp;lt;&amp;gt;();
        DoubleLinkedList head, tail;
        head = list;
        tail = list;
        for (int i = 0; i &amp;lt; chars.length; i++) {
            char cur = chars[i];
            if (!map.containsKey(cur)) {
                DoubleLinkedList node = new DoubleLinkedList();
                node.value = cur;
                node.prev = tail;
                node.next = null;
                tail.next = node;
                map.put(cur, node);
                tail = node;
            } else {
                if (map.get(cur) != null) {
                    if (map.get(cur).prev == null) {
                        head = map.get(cur).next;
                    } else {
                        map.get(cur).prev.next = map.get(cur).next;
                    }
                    if (map.get(cur).next == null) {
                        map.get(cur).prev.next=null;
                        tail = map.get(cur).prev;
                    } else {
                        map.get(cur).next.prev = map.get(cur).prev;
                    }
                    map.put(cur, null);
                }
            }
        }
        if (head == null) throw new RuntimeException();
        return head.value == null ? head.next.value : head.value;
    }
&lt;/code&gt;&lt;/pre&gt;
</content:encoded></item><item><title>Hex grid cells in range</title><description>calculating the hex cells that are N units away from the source</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Wed, 09 May 2018 00:00:00 GMT</pubDate><guid isPermaLink="true">hex-grid-cells-in-range.html</guid><content:encoded>&lt;p&gt;Getting the cells in a range of N is also an important aspect that worth talking about. There are 2 current uses for this feature in Hexarategy:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;get the cells that a weapon of range N can target&lt;/li&gt;
&lt;li&gt;get the cells the ship can navigate to&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The algorithm implementations will depend on the underlying data structure you choose to represent you grid. In this post I will go over algorithms that can be 
used when using a graph to represent the grid. Let’s start with the weapon range, as the movement range is a bit more complicated since it has some 
different constrains.&lt;/p&gt;
&lt;p&gt;The range of a weapon is defined as all the cells in all directions from the home cell that are &amp;lt; N units away. Think like the inside area of a circle.&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/57de523c6fd8e.jpg"&gt;/img/57de523c6fd8e.jpg&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;If the yellow cell is the home cell, then the purple cells are all the cells that are 1 units away, and the orange cells + purple cells are all the cells 
that are 2 units away.  So given the yellow colored home cell, how can we get the cells that are N units away?&lt;/p&gt;
&lt;p&gt;This is a classical graph walk with a range constraint. Instead of visiting all nodes, or quitting when a node is found, we need to quit when we exhaust our range. 
So we need to keep track of the range, that’s for sure. We also need to consider when we decrease this range, because for all purple cells the range from the 
home cell is 1, and we cannot decrease the range each time we visit a purple cell. What we need is to keep track of how many purple cells there are and decrease 
the range after we have consumed them all. We will need track of this by using 2 extra counters: nodesInNext and nodesInCurrent . nodesInNext  will hold the count 
of the neighbors in the next level and the current will hold how much of the current level we have consumed. There are recursive graph traversing algorithms 
and there are ones using stacks and queues. We’ll opt for a non-recursive algorithm here&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;... get the home cell and add it to the queue
goneRange = N //how far is our range?
nodesInCurrent = 1 /*home cell*/, nodesInNext = 0;
while(queue.Count &amp;gt; 0 &amp;amp;&amp;amp; goneRange &amp;gt; 0)
{
    nodesInCurrent--;
    currentCell = queue.Dequeue();
    List&amp;lt;Cell&amp;gt; neighborList = new List&amp;lt;Cell&amp;gt;();
    foreach (Cell item in currentCell.neighbors)
    {
        if (item != null) neighborList.Add(item);
    }
    neighborList.Remove(homeCell);
    IEnumerable&amp;lt;HexCell&amp;gt; nlist =  neighborList.Except(result);
    nodesInNext += nlist.Count();
    foreach (Cell neighbor in nlist)
    {
        queue.Enqueue(neighbor);
        result.Add(neighbor);
    }

    if (nodesInCurrent == 0)
    {
        goneRange--;
        nodesInCurrent = nodesInNext;
        nodesInNext = 0;
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;the result list will contain all the cells that are in range and we can use that. Note that this doesn’t check for friendly fire.&lt;/p&gt;
&lt;p&gt;The movement range calculations are bit more interesting as there is the condition that a rotation move also costs 1 range. Take a look at this diagram&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/57de52979442d.jpg"&gt;/img/57de52979442d.jpg&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Starting at the orange cell facing NE the yellow cell is in range 1. The cell NE of the yellow cell is in range 2 as it is in the same direction. 
The cells to the NW and E of the orange cell are in range 2 because 1 range point would be used to rotate the ship from NE to NW and NE to E. 
Let’s solve this algorithm with a recursive approach. Here is the outline of what we will try to implement&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;if no more range points left, return&lt;/li&gt;
&lt;li&gt;if the result set doesn’t contain the current cell, add it&lt;/li&gt;
&lt;li&gt;for the next 3 directions, if there is a neighbor cell in that direction recurse with range – 1 in that direction otherwise decrease range points.&lt;/li&gt;
&lt;li&gt;for the previous 2 directions, if there is a neighbor cell in that direction recurse with range – 1 in that direction otherwise decrease range points.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So if we are facing NE like the diagram, and we have 2 range points, we will go to the yellow neighbor. We still have have range point so we’ll go NE. 
Now we don’t have any range points so add this cell to the results. Backtrack to the yellow cell and decrease the range points. 
The next direction is E, but we don’t have any range points. This will hold for all the remaining directions on the this cell,
so we backtrack to the orange cell. The next direction is E, and we consumed a range point by turning in this direction so we have 1 point left. 
There is a cell to the E so go to that cell and add it to the list… you get the idea.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public void CellRangeMovement(Cell currentCell, int rangeLeft, List&amp;lt;Cell&amp;gt; result, Direction direction)
{

    if (rangeLeft &amp;lt; 0) return;
    if (!result.Contains(currentCell))
    {
        result.Add(currentCell);
    }

    Direction nextDirection = direction;
    int rangeReg = rangeLeft;
    for (int i = 0; i &amp;lt; 3; i++)
    {
        Cell currentNeighbor = currentCell.neighbors[nextDirection];
        if (currentNeighbor != null)
        {
            CellRangeMovement(currentNeighbor, rangeReg-1, result, nextDirection);
        }
        nextDirection = nextDirection.Next();
        rangeReg--;
    }

    rangeReg = rangeLeft;
    nextDirection = direction;
    for (int i = 1; i &amp;lt; 3; i++)
    {
        Cell currentNeighbor = currentCell.neighbors[nextDirection];
        if (currentNeighbor != null)
        {
            CellRangeMovement(currentNeighbor, rangeReg - 1, result, nextDirection);
        }
        nextDirection = nextDirection.Prev();
        rangeReg--;
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;One interesting point here is that, you cannot rotate 6 six times clockwise to get all the directions, as that would mean consuming extra ranges, 
e.g if you are facing NE and want to face NW you would not go E,SE,SW,W,NW. You would just go NE, NW. That’s why you have to check the directions 
in 2 separate for loops.&lt;/p&gt;
</content:encoded></item><item><title>Island detection / Flood fill with clojure</title><description>using clojure to detect an invalid board state for a game of scrabble</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Wed, 09 May 2018 00:00:00 GMT</pubDate><guid isPermaLink="true">scrabble-island-detection-clojure.html</guid><content:encoded>&lt;p&gt;I had already talked about a mutable version of this algorithm for flood filling island detection &lt;a href="/code/scrabble-island-detection.html"&gt;here&lt;/a&gt;. This time I went immutable with clojure
The algorithm is a bit different, this we will not have a variable in the outer scope but pass a new instance of a board (which is efficiently managed by clojure) to the function for
each iteration/recursion.&lt;/p&gt;
&lt;p&gt;The full source is at &lt;a href="https://gitlab.com/dendiz/kelimelik-clj/tree/master"&gt;https://gitlab.com/dendiz/kelimelik-clj/tree/master&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;there a few helper functions&lt;/p&gt;
&lt;p&gt;&lt;code&gt;first-char-on-board&lt;/code&gt; scans the board to find the first tile that is not empty
&lt;code&gt;split&lt;/code&gt; this will split a string such as &amp;quot;abc&amp;quot; into a vector as &lt;code&gt;[&amp;quot;a&amp;quot; &amp;quot;b&amp;quot; &amp;quot;c&amp;quot;]&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;the basic idea is to keep a list of next slots to visit on the board as we visit slots. 
the &lt;code&gt;next-frontier&lt;/code&gt; function will return a list of next slots. This is basically BFS search
on a graph.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;(defn flood-fill
  &amp;quot;flood fill the board starting from the first non empty slot.
   the flooded slots will contain '!' empty slots '.'. If there
   are islands they will contain letters.
  &amp;quot;
  [board]
  (let [[y x] (first-char-on-board board)
        board (mapv split board)
        ]
    (loop [board board
           frontier [[x y]]]
      (if (-&amp;gt; frontier count zero?)
        board
        (let [front (first frontier)
              x (first front)
              y (second front)]
          (recur
           (assoc-in board [y x] &amp;quot;!&amp;quot;)
           (concat (next frontier) (next-frontier board [x y]))))))))
    	   		   
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;the &lt;code&gt;next-frontier&lt;/code&gt; code is also worth mentioning&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;(defn next-frontier
  &amp;quot;return the coordinates of candidate neighbors for flood filling&amp;quot;
  [board [x y]]
  (for [i [(dec y) y (inc y)]
        j [(dec x) x (inc x)]
        :when (and (&amp;gt;= i 0)
                   (&amp;gt;= j 0)
                   (&amp;lt; i 15)
                   (&amp;lt; j 15)
                   (or (= x j) (= y i))
                   (not (and (= x j) (= y i)))
                   (not= &amp;quot;!&amp;quot; (get-in board [i j]))
                   (not= &amp;quot;.&amp;quot; (get-in board [i j])))]
    [j i]))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;flood-fill&lt;/code&gt; will mark visited slots with &lt;code&gt;!&lt;/code&gt; and &lt;code&gt;next-frontier&lt;/code&gt; will return a list of the candidate slot from the 8 neighbors of the current slot.
if the neighbor is visited or empty it's not included in the list.&lt;/p&gt;
&lt;p&gt;if the starting board was like this&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;...a...
...bc..
..de...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;the flood would start with &lt;code&gt;a&lt;/code&gt; and the &lt;code&gt;next-frontier&lt;/code&gt; would return only &lt;code&gt;b&lt;/code&gt; from the neighbors and mark &lt;code&gt;a&lt;/code&gt; as &lt;code&gt;!&lt;/code&gt;.
&lt;code&gt;b&lt;/code&gt; would return &lt;code&gt;c&lt;/code&gt; and &lt;code&gt;e&lt;/code&gt; and &lt;code&gt;d&lt;/code&gt;. &lt;code&gt;a&lt;/code&gt; would be marked as &lt;code&gt;!&lt;/code&gt; so it would not be included. After the fill the board would be like&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;...!...
...!!..
..!!...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;this algorithm is useful when detecting if the scrabble board is connected.&lt;/p&gt;
</content:encoded></item><item><title>Chained ajax calls</title><description>a method of making async calls in sequence</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Wed, 09 May 2018 00:00:00 GMT</pubDate><guid isPermaLink="true">chained-ajax-calls.html</guid><content:encoded>&lt;p&gt;Sometimes you want to make successive calls to multiple urls one after another - not in parallel. With the programming model for javascript using callbacks this can be a bit confusing to implement properly. Here is a neat trick to do it.
say you have a list of urls [url1, url2, url3] if you could transform this list to&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[
  function() {
    XHR.send();
    XHR.onload = next_fn_in_list
  },
  function() {
    XHR.send();
    XHR.onload = next_fn_in_list
  }, ...
]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;you actually dont even need this be a list, because the onload will reference the next function to call. This is exactly what reduce does for arrays.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;var chainedAjaxCalls = myList.reduceRight(function(previousValue, currentValue) {
        return function() {
            var xhr = new XMLHttpRequest();
            xhr.onload = previousValue;
            xhr.open(&amp;quot;GET&amp;quot;, 'http://url?param=' + currentValue);
            xhr.send()
        }
    }, function() {});
    chainedAjaxCalls();

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;we iterate over the array with the initial NOP function, and return a function that sets the onload to the previous function. We start from the right so the last requests onload is the nop. then n-1 functions onload is n, etc. 
this will create a chain of ajax calls for the url list.
very nice.&lt;/p&gt;
</content:encoded></item><item><title>Sbt publishing to repository</title><description>using sbt to push an artifact to a repository</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Wed, 09 May 2018 00:00:00 GMT</pubDate><guid isPermaLink="true">sbt-publishing.html</guid><content:encoded>&lt;p&gt;If you run a maven repository for your own company/projects here is how you can publish your artifacts using SBT. 
The repository manager I use is archiva but it should be similar for nexus etc too.&lt;/p&gt;
&lt;p&gt;in your build.sbt file&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;credentials += Credentials(&amp;quot;Repository Archiva Managed internal Repository&amp;quot;,&amp;quot;10.0.1.23&amp;quot;, &amp;quot;admin&amp;quot;, &amp;quot;somepass&amp;quot;)
//or use a file
//credentials += Credentials(Path.userHome / &amp;quot;.ivy2&amp;quot; / &amp;quot;.archiva-cred&amp;quot;)

publishMavenStyle := true

publishArtifact in Test := false

publishTo := {
  val archiva = &amp;quot;http://10.0.1.23:9001/repository/&amp;quot;
    Some(&amp;quot;internal&amp;quot;  at archiva + &amp;quot;internal&amp;quot;)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;important points:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the hostname in the credentials part should not contain the port&lt;/li&gt;
&lt;li&gt;the realm is important, it should be like it's shown here (substitute 'internal' for your repo name if it's different)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you are using a file to store your credentials (which is the better way) here is the file format&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;realm=Repository Archiva Managed internal Repository
host=10.0.1.23
user=admin
password=somepassword
&lt;/code&gt;&lt;/pre&gt;
</content:encoded></item><item><title>Mirroring a website with wget</title><description>wget parameters to mirror a web site for offline usage</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Wed, 09 May 2018 00:00:00 GMT</pubDate><guid isPermaLink="true">mirror-website.html</guid><content:encoded>&lt;p&gt;Mirroring a website? Why would you do that in the first place? Well I used it to mirror documentation/API reference for offline usage, like on long flights. Here is a fast way of doing this with wget:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;wget -r -np -N [url] &amp;amp;
wget -r -np -N [url] &amp;amp;
wget -r -np -N [url] &amp;amp;
wget -r -np -N [url] &amp;amp;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The trick is the -N switch, which downloads the file if its newer than the one on disk.&lt;/p&gt;
</content:encoded></item><item><title>Scrabble Solver Script</title><description>groovy script to find the max scoring word for scrabble</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Wed, 09 May 2018 00:00:00 GMT</pubDate><guid isPermaLink="true">scrabble-solver.html</guid><content:encoded>&lt;p&gt;I've been challenged by burcin at a game of scrabble - the Turkish version. She is quite crafty with words and can easily beat me and all of her friends. 
But I'm crafty with computers so I wrote a nice groovy script to play for me. I'm quite ok with making the strategical decisions, so the script just 
finds the best possible word for a given state. To make it play a good game of scrabble would involve far more than that. Here are some interesting 
parts of the script&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  def permutations(letters) {
    def powerset = powerset(letters)
    def res = []
    powerset.each {
      def list = it.split(&amp;quot;&amp;quot;) - &amp;quot;&amp;quot; as List
      res &amp;lt;&amp;lt; list.permutations().collect { it.join(&amp;quot;&amp;quot;) }
    }
    return res.flatten()
  }

  def powerset(letters) {
    def size = 2 ** letters.size()
    def res = []
    for (int i=0;i&amp;lt;size;i++) {
      def tmp = &amp;quot;&amp;quot;
      for (int j=0;j&amp;lt;letters.size();j++) {
        if ( (i &amp;amp; (1&amp;lt;&amp;lt;j)) &amp;gt; 0) {
          tmp += letters[j]
        }
      }
      res &amp;lt;&amp;lt; tmp
    }
    return res - &amp;quot;&amp;quot;
  }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;this piece of code generates all the possible permutations from your letters. First you need to generate the power set of the letters so if you have the 
letters [a,b,c] you will need [a,b,c,ab,ac,bc,abc]. The power set also includes the empty set which is pointless here. A nice way of generating the
power set is used here. You know that there are 2^n elements in the power set, so you start from 0 and go up to 2 ** n and for each number in the 
range the bits of the number will represent which elements to take from the letters. So say you are 4 in the range, which is 010 in base 2. 
This means that the 4th element in the power set is the 2 element from your letters. 5 is 011 which means the 5th element in the set is the 
first and second letters concatenated. Pretty cool way of doing it. Next we need all the permutations of all the elements in the power set. 
You want to check for the words&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;a, b, c&lt;/li&gt;
&lt;li&gt;ab, ba&lt;/li&gt;
&lt;li&gt;ac ,ca&lt;/li&gt;
&lt;li&gt;bc, cb&lt;/li&gt;
&lt;li&gt;abc,acb,bca, etc..&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;across the board.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;def putWord(word, board, x, y) {
    if (board[y][x] != ASTERISK) return null
    //println &amp;quot;tryword: $word x/y $x $y&amp;quot;
    def clone = clone(board)
    def putat = x
    for(int i=0;i&amp;lt;word.size();i++) {
      while(putat &amp;lt; 14 &amp;amp;&amp;amp; clone[y][putat] != &amp;quot;*&amp;quot;) {
        putat++
      }
      if (putat &amp;gt; 14) {
        //putting the whole word would exceed board bounds
        return clone
      }
      clone[y][putat] = word[i]
      putat++
    }

    return clone

  }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;this piece of code will put the given word on the board. The thing you need to careful about is that you may need to skip over exiting letters from words.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
|   |   |   |   |   |   |
|---|---|---|---|---|---|
|*  |a  |*  |*  |*  |*  | 
|*  |b  |*  |*  |*  |*  | 
|*  |c  |*  |*  |*  |*  | 

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;if you want to put the word &amp;quot;xyz&amp;quot; at position 0,0 you need to skip over the letter a and then continue putting the word  so it looks like&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;| | | | | | |
|-|-|-|-|-|-|
|x|a|y|z|*|*| 
|*|b|*|*|*|*| 
|*|c|*|*|*|*| 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;if the starting location doesn't contain the * character you just just return as a word can't start there.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
def isValidWords(board, dict) {
    def words = []
      for (def line : board) {
    	def wl = line.join(&amp;quot;&amp;quot;)
    	def st = new StringTokenizer(wl, &amp;quot;*&amp;quot;)
    	while(st.hasMoreElements()) {
    		def nt = st.nextToken()
    		if (nt.size() &amp;gt; 1) words &amp;lt;&amp;lt; nt
    	}
     }



    for (String w : words) {
    	if (!dict.containsKey(w)) return false
    }
    return true
  }

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;to check if the board is valid after you put a word you need to check that all the words on the board are in your dictionary, and that there are no 
extra islands on the board. The board is a 2D array like this&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[
 [* * * * *],
 [* * * * *]
...
]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;if you join each row of the board into a string and then tokenize on &amp;quot;*&amp;quot; you will get all the words in that row. Look them up in your dictionary and 
return false if a single words doesn't exists in the dictionary. What about vertical words? Just transpose the board (t_board[i][j] = board[j][i]) 
and run the same check.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;def connected(board) {
    //dumpboard(board)
    def startx, starty
    outer:
    for(int i=0;i&amp;lt;15;i++) {
      for(int j=0;j&amp;lt;15;j++) {
                  if (board[i][j] != ASTERISK) {
                          startx = j
                          starty = i
                          break outer
                  }
      }
    }
    def clone = clone(board)
    floodfill(clone, startx, starty)
        for(int i=0;i&amp;lt;15;i++) for(int j=0;j&amp;lt;15;j++) if (clone[i][j] != ASTERISK &amp;amp;&amp;amp; clone[i][j] != BANG) return false
        return true
    //return clone.flatten().findAll { it != ASTERISK &amp;amp;&amp;amp; it != BANG }.size() == 0
  }

  def floodfill(board, x, y) {
    board[y][x] = BANG
    if (y &amp;lt; 14 &amp;amp;&amp;amp; board[y+1][x] != ASTERISK &amp;amp;&amp;amp; board[y+1][x] != BANG) {
      floodfill(board, x, y+1)
    }
    if (y &amp;gt; 0 &amp;amp;&amp;amp; board[y-1][x] != ASTERISK &amp;amp;&amp;amp; board[y-1][x] != BANG) {
      floodfill(board, x, y-1)
    }
    if (x &amp;lt; 14 &amp;amp;&amp;amp; board[y][x+1] != ASTERISK &amp;amp;&amp;amp; board[y][x+1] != BANG) {
      floodfill(board, x+1, y)
    }
    if (x&amp;gt;0 &amp;amp;&amp;amp; board[y][x-1] != ASTERISK &amp;amp;&amp;amp; board[y][x-1] != BANG) {
      floodfill(board, x-1, y)
    }
    //dumpboard(board)
  }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;to check for islands just find the indices of the first letter on the board, and do a flood fill, replacing the letters with the bang character. 
Next check all locations for a character other than &amp;quot;!&amp;quot; or &amp;quot;*&amp;quot;. If there are any it means there is an island and the board isn't valid. 
I have a more detailed write up on this method &lt;a href="/code/scrabble-island-detection/"&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The first iteration of the script ran on a single thread and would take about 6 to 7 minutes to calculate 13699 words. But it's a great 
candidate for parallelization which is very simple with groovy. With 6 threads it completes in about 2 minutes which is quite acceptable.&lt;/p&gt;
</content:encoded></item><item><title>Hex grid backing arrays</title><description>how to represent a backing array for a hex grid</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Wed, 09 May 2018 00:00:00 GMT</pubDate><guid isPermaLink="true">hex-grid-backing-arrays.html</guid><content:encoded>&lt;p&gt;Programming game worlds with square grids is pretty straight forward. You just use a 2D array, and calculations are quite easy. 
To go up you subtract from the Y coordinate, to go left you add 1 to the X coordinate. But when you are dealing with hex grids 
life gets a bit more complicated. Representing a backing array for a hex grid can be done in the following way&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[
  [null,null,null,{},{},{},{}],
  [null,null,{},{},{},{},{}],
  [null,{},{},{},{},{},{}],
  [{},{},{},{},{},{},{}],
  [{},{},{},{},{},{},null],
  [{},{},{},{},{},null,null],
  [{},{},{},{},null,null,null]]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;this would be the representation array for the following grid&lt;/p&gt;
&lt;p&gt;the row 3 in the array is the row in the center of the grid. If you go up one row the row becomes an element shorter (represented by a null element). 
You could also skip adding the null element and use different length elements for each row, but that brings it own advantages and disadvantages. 
The radius of the grid is defined as the length on the longest row for the hex shaped grid. Now for a given radius of N how could we generate 
the backing array for that grid?&lt;/p&gt;
&lt;p&gt;The property to notice here is that the number of nulls increases from the middle out by one. So you would have abs(i - mid) number of null 
elements for a given row i where mid is floor(radius) /2. You would place these null elements in the beginning of the array if i &amp;lt; mid 
and at the end of the array if i &amp;gt; mid.
Here is some coffeescript code that does this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;createMatrix: (radius) -&amp;gt;
        mid = Math.floor(radius/2)
        matrix = [1..radius].map (it, i) -&amp;gt;;
            count = Math.abs(i - mid)
            head = [0 ... count].map -&amp;gt; null
            tail = [count + 1 .. radius].map (it) -&amp;gt; {}
            if  i &amp;gt; 3 then head.concat tail else tail.concat head
        matrix

&lt;/code&gt;&lt;/pre&gt;
</content:encoded></item><item><title>K Closest star selection</title><description>An efficient way of calculating the first N items of unsorted array</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Wed, 09 May 2018 00:00:00 GMT</pubDate><guid isPermaLink="true">closest-star-selection.html</guid><content:encoded>&lt;p&gt;In my post about generation galaxy warp lanes &lt;a href="/code/galaxy-hyper-lane-generation/"&gt;GalaxyWarpLaneGeneration&lt;/a&gt; I talked about the a naive method that would select the N closest stars to a given star. 
Even though the name states the method as naive it isn't such a naive tasks when you consider large amounts of stars. For a game the number of stars could be in the 
hundreds or maybe thousand, but what if for a minute we actually consider the real world? How could you select N closest start from 10M star? or 100M maybe even a 1B?&lt;/p&gt;
&lt;p&gt;My initial though was the simple approach: calculate the distance between the source and each of the other stars, and sort the other star list on this distance. 
This results in an O(nlogn) algorithm which is the best a sort on this type of randomized data. But there is a better way: The key is we don't need to 
sort all the list, we are just looking to get the closest N elements. The algorithm is as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;create a MAX heap of size N&lt;/li&gt;
&lt;li&gt;add the first N stars from the list to the heap, based on a distance comparator from the source star.&lt;/li&gt;
&lt;li&gt;for the remaining stars in the list:&lt;ol&gt;
&lt;li&gt;if the distance to that star is less than the top of the heap, remove the top and add this star.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;get all the element in the heap for the result.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;public List&amp;lt;Star&amp;gt; closest(List&amp;lt;Star&amp;gt; stars, int n) {
    PriorityQueue&amp;lt;Pair&amp;lt;Star,Double&amp;gt;&amp;gt; heap = new PriorityQueue&amp;lt;&amp;gt;(n, 
       (x1, x2) -&amp;gt; x2.getSecond().compareTo(x1.getSecond()));

    for (int i =0;i&amp;lt;n;i++) {
        heap.add(new Pair&amp;lt;&amp;gt;(stars.get(i), distance(stars.get(i))));
    }
    for(int i=n;i&amp;lt;stars.size();i++) {
        if(stars.get(i) == this) continue;;
        double distance = distance(stars.get(i));
        if (distance &amp;lt; heap.peek().getSecond()) {
            heap.poll();
            heap.add(new Pair&amp;lt;&amp;gt;(stars.get(i), distance));
        }
    }
    return heap.stream().map(Pair::getFirst).collect(toList());
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;we are adding (N-k) element to a heap of k element. Each insertion will cost log(k). So the total will be o(N * logK)
I am usually connecting 2 or 3 stars which result in 1000 * log2 which is around 300 operations vs. 1000 * log(1000) which is also 300 operations.
It doesn't make a difference for the basic case. But if I had 10M start then 10M * log2 = 3M vs 10M * log10M = 70M
it does make a difference.&lt;/p&gt;
</content:encoded></item><item><title>hex grid border highlighting</title><description>highlighting the borders of a hex on a grid in unity 3d</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Wed, 09 May 2018 00:00:00 GMT</pubDate><guid isPermaLink="true">hex-grid-border-highlighting.html</guid><content:encoded>&lt;p&gt;Previously I've been doing this by actually highlighting all the possible cells, but it's looks a lot better if you just highlight the borders. Here's the results I've got after this implementation&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/57de50c77de2a.png"&gt;/img/57de50c77de2a.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Calculating the border cells is a different task which I've explained over &lt;a href="/code/hex-grid-cells-in-range/"&gt;here&lt;/a&gt;. After we have the cells that we can navigate to we need to filter out the border cells. If you look carefully the edges that need highlighting from all the cells in range are the ones that do not have a navigable neighbor. In the image the cell (4,-6,2) and (5,-6,1) are both in range, but they share a border with a navigable cell, so that edge should not be highlighted. The algorithm should be like this:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Get all the cells in range and the starting cell, and add the starting cell to the cells in range.&lt;/li&gt;
&lt;li&gt;for all the cells loop&lt;ul&gt;
&lt;li&gt;for all the neighboring cells of the current cell loop&lt;ul&gt;
&lt;li&gt;if the cells current neighbor = null or cells in range doesn't have the neighbor highlight that edge&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The actual highlighting is done by placing a quad with a bar texture with the correct rotation and coordinates easily calculated from the current cell we are processing.&lt;/p&gt;
&lt;p&gt;Here is a video of the highlighting:&lt;/p&gt;
&lt;p&gt;{{&amp;lt; youtube UkWKeim-n_Y &amp;gt;}}&lt;/p&gt;
</content:encoded></item><item><title>ITTB DevLog 2018-05-07</title><description>map generation, path finding, weapons and loots updates</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Mon, 07 May 2018 00:00:00 GMT</pubDate><guid isPermaLink="true">ittb_devlog-2018-05-07.html</guid><content:encoded>&lt;h2&gt;Summary&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;map generation&lt;/li&gt;
&lt;li&gt;movement, path finding&lt;/li&gt;
&lt;li&gt;loot generation, weapons&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ported over the path finding code and map validation. I ran into a stupid typo
bug that was screwing up the lee path expansion matrix code, which took me 2
hours to debug and fix. And it turned out to be one of those 1 character typos
(wrote a y instead of x). This stuff can be so frustrating sometimes! I also
started genericising the names for the in-game components as the theme is not
decided completely yet. So instead of calling a tile “water” I just call it a
“killer” tile as it could be water or it could be fire. I also did JetBrains
Rider a favor and cleared 99% of the warnings and applied it’s suggestions.
It’s annoying to have code fragments underlined and highlighted. In the
prototype move of the behavior and data and logic code were in the same file,
but with unity using the component system it’s easy to separate these so the
unit selection and unit movement code went into their own components. It’s
quite nice to have a unit class that’s pretty short and these types attributes
and behaviors in different components. I have seen a player class in one of the
open source rogue-likes that around 5 K lines of code. I could never wrap my
head around it or even manage that much code in a single file.  I also
implemented the movement arcs, and the unit selection indication. I refactored
some methods to return game objects (tile processing code) which I later
reverted back the base component class to take better advantage of static
typing. It’s easy to access the game object on the component to get another one
anyways, so it makes more sense to return the base component.&lt;/p&gt;
&lt;p&gt;In the prototype the units were kind of teleport-ed to a location when clicked
on them, with a line showing path it came from. Now I have the units animate
tile by tile to their destination. This is a nice way to reduce the clutter on
the map and make the game look more professional. But now I had to come up with
a way to disable the next turn button when a unit is moving. Otherwise if the
player would press the button the enemies would start moving and the game would
stop being turn based but be more real time, and I’m sure it would cause a lot
more bugs and complications. The animation of the units works by calculating
the path it will take and queuing these tiles up in the movement behavior. If
the queue is full, it means the unit is moving and the button should be
disabled. So I added a co-routine in the button behavior that checks this for
all ally units and adjusts the button state accordingly. The queue is processed
in the Update loop for each unit, so the checks have to be done in a separate
thread. I also added some enemy units, and after the players turn the enemy
units make their move. In the prototype the enemy units were teleporting too,
so I could just process their calculations sequentially and be done with it.
Now I have to do the same checks I did for the “next turn” button for the
enemies so that they play one after the other.&lt;/p&gt;
&lt;p&gt;I also ported a part of the loot generator for weapons. This part was bugging
me in the prototype as the implementation done by GO was based on a data
centered approach you would use in a functional language and not really OOP.
What I have so far is a function that returns a random prefab from the
available weapons, and the code that spawns the player randomizes the weapon
parameters and adds the weapon instance as a child node to the player. I need
to get the parameter randomization code into the loot generator, and add the
items to a player inventory. In the unit lab the player will assign a weapon
from the inventory to the player, and the player with spawn with that.&lt;/p&gt;
</content:encoded></item><item><title>ITTB DevLog 2018-05-04</title><description>Porting the prototype over to Unity Engine</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Fri, 04 May 2018 00:00:00 GMT</pubDate><guid isPermaLink="true">ittb_devlog-2018-05-04.html</guid><content:encoded>&lt;h2&gt;Summary&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;unity port&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So far I am content with the Game mechanics I’ve come up with and the
prototyping phase is thus over. One thing I can say about Godot is that the
editor sucks, so I had to revert to using vim + CLI. Another thing is that
GDScript is a nice prototyping script but I can’t see myself using it for a
complicated project. Mainly due to the missing data structures, lack of
libraries, it’s simplistic nature and my personal preference for statically
typed languages.&lt;/p&gt;
&lt;p&gt;So the real product development I’ve decided to go with my old friend Unity.
I’m now in the process of porting and cleaning the code in GDScript. I’ve
managed to get the Player units, unit selection, path finding, map generation,
obstacle generation working in a day. The architecture is &lt;em&gt;way&lt;/em&gt; cleaner and
being able to use JetBrains Rider is a great speed up. Here is a screen shot of
the current state&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/ittb1.png"&gt;/img/ittb1.png&lt;/a&gt;&lt;/p&gt;
</content:encoded></item><item><title>ITTB DevLog 2018-05-01</title><description>playing around with some game mechanics</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Tue, 01 May 2018 00:00:00 GMT</pubDate><guid isPermaLink="true">ittb_devlog_2018-05-01.html</guid><content:encoded>&lt;h2&gt;Summary&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;difficulty mechanics&lt;/li&gt;
&lt;li&gt;attack mechanics&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The difficulty of the level was being determined by the number of enemies, but
the enemy stats were being generated randomly. This meant that some games level
2 could be much more harder than other games. To balance this I came up with a
budgeting system. Each level has a budget that is a function of the level
number. The more advanced the level, the higher the budget. At the start of
each level, this budget is consumed according to the stats of the randomly
generated enemy. So if say the level 2 budget is 10, you could have 3 monsters
with 3 stats, or 2 with 5 each. This keeps the game dynamic while keeping the
levels balanced. For the in-level enemy spawns, the budget is increased each
turn according to the current level. Further on the game the in-level budget
increase is much high therefore more/stronger enemies spawn.&lt;/p&gt;
&lt;p&gt;I also changed the end of level loots to a random number between one and two.
Sometimes you’ll be lucky and get two, but this should not affect the game
progression that much.&lt;/p&gt;
&lt;p&gt;I also increased enemy melee damage with level and building armor too. This
provides a way to decide on which buildings to protect from which enemy. Also
it’s now a good idea to check an enemies damage before deciding to go in for a
melee or ranged attack.&lt;/p&gt;
&lt;p&gt;I tried playing around with the committed attack directions. This means that
once the enemy is committed to an attack, they will keep the relative direction
of the attack, and do the attack on that square even if it means damaging a
friendly. I though this would lead to more tactical game play, by pushing
enemies into tiles that will be attacked for sure the next turn, but that
doesn’t happen as much I as thought it would, so I reverted the code.&lt;/p&gt;
&lt;p&gt;A peculiar thing with Godot is that freed objects are not set to null. This
lead to a subtle bug: If the player dies, and you click on an enemy to see some
info about the guy that killed you the game would crash. This was happening
because the player object had been freed and there was a reference in the info
label to the player object. There was a null check if place, but that didn’t
cover it. The current solution is the wrap that object with a weak reference,
but that means changing every access of the target variable with a weak
reference. Meh. What I came up with is checking the the target object is in the
scene tree during the label update.  The label update is done every frame, so
this is potentially a performance bottleneck, but since it is only run when the
enemy is selected it is an acceptable trade-off for a clean approach.&lt;/p&gt;
</content:encoded></item><item><title>ITTB DevLog 2018-04-27</title><description>Enter the mech lab</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Fri, 27 Apr 2018 00:00:00 GMT</pubDate><guid isPermaLink="true">ittb_devlog_2018-04-27.html</guid><content:encoded>&lt;h1&gt;Summary&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;how to use the mech lab&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We now have the unit lab fully functional. Actually we already had it for a couple of days but it’s
only now that I had a chance to write about it. The unit lab is the place where you can add/remove
items and weapons from your units. You can modify and deploy up to 4 units into battle. Going over
a screen shot will make it easier to under stand what’s going on:&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/mechlab1.png"&gt;/img/mechlab1.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This is the main screen. The unit as listed on the left with their equipment. The middle section
contains the inventory and the right section contains the stats of the selected item.&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/mechlab2.png"&gt;/img/mechlab2.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;this little tool here allows to to select which unit you want to change.&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/mechlab3.png"&gt;/img/mechlab3.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;the “+” button allows you to equip that weapon to the currently selected unit. The “D” button
drops the item from your inventory. Currently there is no limit to the items you can have in your
inventory but that may change. It’s only purpose is to empty the trash items if it gets to crowded.&lt;/p&gt;
&lt;p&gt;Each unit can only carry a single ranged weapon/melee weapon/item, so when you add an item it will
get swapped with the existing item.&lt;/p&gt;
&lt;p&gt;When a unit has a chassis, melee weapon and a melee weapon it will be deployed automatically. Currently
we are debating the issue of an option to not deploy a mech that is fully equipped but there are no
strong cases where a player would not want a mech on the battlefield.&lt;/p&gt;
</content:encoded></item><item><title>ITTB DevLog 2018-04-26</title><description>Bugfixes are inevitable. Loot generation is underway</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Thu, 26 Apr 2018 00:00:00 GMT</pubDate><guid isPermaLink="true">ittb_devlog-2018-04-26.html</guid><content:encoded>&lt;h2&gt;summary&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;bug fixes&lt;/li&gt;
&lt;li&gt;loot generation&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I had implemented the duplicates check for the spawn queue in a inefficient
way, so I corrected that. No need to scan the queue every time, just keep track
of the element in the queue in a set. I also realized during test playing that
newly spawned water tiles could lead to islands in the map. So a check for
connectivity was needed before adding that new water tile to the queue. This
lead me to fix a performance issue in the connectivity checking code. A split
the tile-tile checking code from the slower building – tile checking code. I’m
still not sure if I should let water tiles spawn on building tiles. This is
frustrating for the player because most of the time there is nothing you can do
to stop it. It’s simply not possible to kill the remaining enemies in the
number of turn given to save the building and this does reduce the global
building preservation count. On the other hand it does make the game a bit more
difficult and exciting.&lt;/p&gt;
&lt;p&gt;A couple of days ago I had noticed that some enemies froze occasionally.
Investigation into this led me to discover that it was possible for the enemies
to select a building/mountain tile as the location for an attack on the player
in some configurations. I implemented a fix for this and also implemented a fix
for selecting unreachable tiles. I’m wondering if I should just let the enemies
do a random walk if they don’t get a movement tile or just let them sit frozen
for a couple of turns?&lt;/p&gt;
&lt;p&gt;During one test game I was blessed (!) with a mech that had 5 speed. This made
it super easy to go around killing all the enemies very fast before a wave came
in to their rescue. After progressing about 5 levels the game crashed with a
NPE because the level generator could not place the number of required units on
the deployment zone for the enemies. There just wasn’t enough free tiles!. What
this means is this&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The weapon/item generation system is flawed. Why would I get a +5 speed mech
in the first level?&lt;/li&gt;
&lt;li&gt;Not just more enemies each level, we also need stronger enemies.&lt;/li&gt;
&lt;li&gt;There has to be a trade-off between speed, weapon strength, range.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These were issues I was previously aware of, and had in my to do list. The
solution is a points system which measures the strength of the units and
adjusts the level difficulty based on this.&lt;/p&gt;
&lt;p&gt;Also I’m thinking of introducing a weight and maybe a heat system to implement
the trade off between items. To install an AC with +2 damage means your speed
is reduced by 1. So if you have a mech that’s only speed 1 you can’t install
that weapon. With the current setup of only 1 item per mech this also means
that if can’t have armor + speed. So if your mechs initial speed is 1 you
cannot have AC2 + armor which may have a negative effect on game play.&lt;/p&gt;
&lt;p&gt;I also saw an issue where the supports unit would surround a normal enemy unit
and would not budge effectively freezing that unit in place. I set an upper
limit of 1 for support units on the map.  Now that the unit lab development is
complete and we can equip the units with items and weapons things are looking a
lot better. We also implemented a budgeting system for generating the weapon
stats based on level. Each level you get a budget of say 5 units and this
budget is distributed randomly to the stats of the loot being generated. This
type of generation also brought a balance to the game. No more Bruce Lee’ing
around the map killing everybody.&lt;/p&gt;
</content:encoded></item><item><title>ITTB DevLog 2018-04-25</title><description>Performance improvements, jumping mechanics and some game mechanics</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Wed, 25 Apr 2018 00:00:00 GMT</pubDate><guid isPermaLink="true">ittb_devlog-2018-04-25.html</guid><content:encoded>&lt;h2&gt;summary&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;performance/code improvements&lt;/li&gt;
&lt;li&gt;jump jet mechanics, game mechanics&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I have been skimming through the code so far, which is around 2K lines right
now, and I have noticed some inefficiencies and some simplification that could
be made. GD Script doesn’t really provide an extensive language so a lot of
things have to be done the old fashioned way. I guess their motto is, C doesn’t
have those fancy constructs and they’re doing fine, why shouldn’t we? So I did
a couple of one-liner fixes and some code reduction here and there, nothing too
big. A couple of bug crawled into the code making it possible for the player to
gain super Mech attack powers, like attacking even after the attack action had
been consumed.&lt;/p&gt;
&lt;p&gt;Like that wasn’t enough the ranged weapons could fire beyond their ammo limit.
I fixed that too, so no more Bruce Lee mechs, kicks every bodies ass.&lt;/p&gt;
&lt;p&gt;One of the items that I want to add is a jump jet, that will get the player
beyond blocked tiles. This will give the ability to jump over the enemy to
their behind and attack them. And also get out of hairy situations like this&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/ittb2.png"&gt;/img/ittb2.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The item isn’t pick-able yet, but the movement mechanics are there. So the item
should be ready within the coming days.&lt;/p&gt;
&lt;p&gt;I also wanted the player to prioritize building protection as this is supposed
to be a tower defense game.  Now if you lose more than X building across all
levels, the game is over.&lt;/p&gt;
&lt;p&gt;I’m thinking of a turn counter so that you may just have to protects the
buildings for X turns, but this also brings the mechanic of running away from
the monsters if you have high speed or a jump jet. This is kind of refuted by
the newly spawning enemies. But I also wanted to try out the mechanic of water
flooding, killing buildings, enemies, mountains or anything else in it’s path
eventually cover the whole map.&lt;/p&gt;
</content:encoded></item><item><title>ITTB DevLog 2018-04-24</title><description>Firing arcs, support units and water flooding</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Tue, 24 Apr 2018 00:00:00 GMT</pubDate><guid isPermaLink="true">ittb_devlog-2018-04-24.html</guid><content:encoded>&lt;h2&gt;summary&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;firing arcs&lt;/li&gt;
&lt;li&gt;support units&lt;/li&gt;
&lt;li&gt;water expansion&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;When displaying enemy firing arcs I didn’t want any water tiles to be
considered in range, as it made it look like water tiles were traversable,
which is false. So I just declared them as obstacles and excluded from the arc.
This lead to an undesired side effect of players not being able to shoot
enemies on the other side of the river. So I had to remedy the situation by
just not displaying the arc if the tile is a water tile.&lt;/p&gt;
&lt;p&gt;Another thing that was bugging me was that the armor support units boost was
effecting the enemy units only after the first enemy moves were made. I changed
this by giving the boost in the &lt;code&gt;_ready&lt;/code&gt; function call with gets called every
frame. I like to refrain from using this function as it consumes a lot of CPU
cycles. Another option would be to implement some kind of post enemy creation
hook that runs after all enemies are spawned and then distribute the boosts. I
would have to run this code again after each in-level spawn has happened which
I thought would be unnecessary complication in the code. One optimization I did
was instead of executing the call every frame I added a check to execute it one
every 0.5 seconds which is good enough for my purposes.&lt;/p&gt;
&lt;p&gt;I was thinking about a type of enemy unit that would manipulate the terrain,
e.g expand the water tiles or make the volcano’s erupt and make lava flow
around the map having the same effect as water. When I set out to implement
this I realized that the backing array that I used when creating the map
initially was kind of limiting. If I wanted to add a new lava tile, I would
have to come up with a constant that represented that tile, and then add manage
path finding code, etc to account for this new tile type. Besides this I was
maintaining 2 data structures: the scene tree and matrix containing redundant
data. Since I can’t dump the scene tree, I had to dump the matrix. The first
iteration constructs a new matrix when needed from the scene tree on the fly,
the use of a 2D matrix makes path finding code a lot more simple. For the
second iteration of refactoring I’m thinking about getting rid of the constant
that I had been using to compare tile types, but I’m not sure this can be done.
I was thinking about comparing class types to get to tile types, but some tiles
share a class type, and GD script class type comparison isn’t that good. For
instance I could not find a way to compare a class to it self. Say I have a
function that returns all the enemy units on the map and in the support unit I
want to skip over the enemy types “support unit”. You can load the support unit
within itself, so you are kind of stuck with the constant comparisons.&lt;/p&gt;
</content:encoded></item><item><title>Music discoveries</title><description>A list of songs I've discovered</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Mon, 23 Apr 2018 00:00:00 GMT</pubDate><guid isPermaLink="true">music.html</guid><content:encoded>&lt;p&gt;I'm a spotify subscriber and I like to use the radio and the discovery feature of spotify quite a bit. 
I guess one advantage of these types of services is their ability to aggregate data and give you a 
recommendation.&lt;/p&gt;
&lt;p&gt;Here I list my latest discoveries in the realms of neo-classical / symphonic metal and some classical music.&lt;/p&gt;
&lt;h2&gt;2018&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Falconer - Heresy in disguise&lt;/li&gt;
&lt;li&gt;Sabaton - The last battle&lt;/li&gt;
&lt;li&gt;Brothers of metal - Yggdrasil&lt;/li&gt;
&lt;li&gt;Sabaton - The final solution&lt;/li&gt;
&lt;li&gt;Excalion - Losing time&lt;/li&gt;
&lt;li&gt;Raubtier - Lat napalmen regna&lt;/li&gt;
&lt;li&gt;Lyriel - Leverage&lt;/li&gt;
&lt;li&gt;Sirenia - Sirens of the seven seas&lt;/li&gt;
&lt;li&gt;Sabaton - Twilight of the thundergod&lt;/li&gt;
&lt;li&gt;Sabaton - Winged husars&lt;/li&gt;
&lt;li&gt;Lyriel - Dust to dust&lt;/li&gt;
&lt;li&gt;Dark sarah - Dance with the dragon&lt;/li&gt;
&lt;li&gt;Human fortress - defenders of the crown&lt;/li&gt;
&lt;li&gt;Dragony - Lords of the hunt&lt;/li&gt;
&lt;li&gt;CPE Bach - Solfeggio in C Minor&lt;/li&gt;
&lt;li&gt;Bloodbound - Nightmares from the grave&lt;/li&gt;
&lt;li&gt;Epica - Beyond the matrix&lt;/li&gt;
&lt;li&gt;Keldian - The last frontier&lt;/li&gt;
&lt;li&gt;Timeless miracle - The Devil&lt;/li&gt;
&lt;li&gt;Keldian - Never existed&lt;/li&gt;
&lt;li&gt;Excalion - Wingman&lt;/li&gt;
&lt;li&gt;Avantasia - Death is just a feeling&lt;/li&gt;
&lt;li&gt;Dragonland - The black mare&lt;/li&gt;
&lt;li&gt;Orden Ogan - To the end&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;2017&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Deftones - Root&lt;/li&gt;
&lt;li&gt;Bloodbound - We raise the dead&lt;/li&gt;
&lt;li&gt;Seventh wonder - A day away&lt;/li&gt;
&lt;li&gt;Dream theater - I walk beside you&lt;/li&gt;
&lt;li&gt;Dream theater - Under a glass moon&lt;/li&gt;
&lt;li&gt;Orphaned land - All is one&lt;/li&gt;
&lt;li&gt;Elvenking - Swallow tail&lt;/li&gt;
&lt;li&gt;Asrai - All seems so hallow&lt;/li&gt;
&lt;li&gt;Sabaton - En livsted i krieg&lt;/li&gt;
&lt;li&gt;Sabaton - Carolus Rex&lt;/li&gt;
&lt;li&gt;Sirenia - Dim days of dolor&lt;/li&gt;
&lt;li&gt;Epica - The cosmic algorithm&lt;/li&gt;
&lt;li&gt;Krypteria - Liberatio&lt;/li&gt;
&lt;li&gt;Freedom call - Land of the light&lt;/li&gt;
&lt;li&gt;Master plan - Lonely winds of war&lt;/li&gt;
&lt;li&gt;Visions of atlantis - silence&lt;/li&gt;
&lt;li&gt;Sirenia - Path to decay&lt;/li&gt;
&lt;li&gt;Nightwish - Feel for you&lt;/li&gt;
&lt;li&gt;Nightwish - Passion and the opera&lt;/li&gt;
&lt;li&gt;Axxis - Doom of destiny&lt;/li&gt;
&lt;li&gt;Cain's offering - I will build you a rome&lt;/li&gt;
&lt;li&gt;Nocturnal Rites - Fools never die&lt;/li&gt;
&lt;li&gt;Sirenia - My mind's eye&lt;/li&gt;
&lt;li&gt;Lunatica - A song for you&lt;/li&gt;
&lt;li&gt;Elis - Der letzte tag&lt;/li&gt;
&lt;li&gt;Xandria - Forevermore&lt;/li&gt;
&lt;li&gt;Elis - Anger&lt;/li&gt;
&lt;li&gt;Xandria - Dreamkeeper&lt;/li&gt;
&lt;li&gt;Amberian Dawn - River of Tuoni&lt;/li&gt;
&lt;li&gt;Delian - The Gathering&lt;/li&gt;
&lt;li&gt;Savage Circus - Ballad of susan&lt;/li&gt;
&lt;li&gt;Sabaton - To hell and back&lt;/li&gt;
&lt;li&gt;Sabaton - Hearts of iron&lt;/li&gt;
&lt;li&gt;Iced earth - Raven wing&lt;/li&gt;
&lt;li&gt;Sabaton - Primo victoria&lt;/li&gt;
&lt;li&gt;Tarja - Innocence&lt;/li&gt;
&lt;li&gt;Bloodbound - Drop the bomb&lt;/li&gt;
&lt;li&gt;Dreamtale - Island of my heart&lt;/li&gt;
&lt;li&gt;Sabaton - The last stand&lt;/li&gt;
&lt;li&gt;Zonata - Gate of fear&lt;/li&gt;
&lt;li&gt;Twilight force - Rise of a hero&lt;/li&gt;
&lt;li&gt;Dream theater - A rite of passage&lt;/li&gt;
&lt;li&gt;Iced earth - Anthem&lt;/li&gt;
&lt;li&gt;Avantasia - Sign of the cross&lt;/li&gt;
&lt;li&gt;Falconer - The clarion call&lt;/li&gt;
&lt;li&gt;Avantasia - Draconian love&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;before 2017&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Dark Moor - This is my way&lt;/li&gt;
&lt;li&gt;Heavenly - Ode to Joy&lt;/li&gt;
&lt;li&gt;Xandria - Sisters of the light&lt;/li&gt;
&lt;li&gt;Edenbridge - Flame of passion&lt;/li&gt;
&lt;li&gt;Iron Mask - Holy war&lt;/li&gt;
&lt;li&gt;Fredic Chopin - 12 Etudes, Op.25, no 12 in C Minor&lt;/li&gt;
&lt;li&gt;Dream theater - One last time&lt;/li&gt;
&lt;li&gt;Dream theater - the spirit carries on&lt;/li&gt;
&lt;li&gt;Ayreon - The eyes of time&lt;/li&gt;
&lt;li&gt;Sonata Arctica - The truth is out there&lt;/li&gt;
&lt;li&gt;Kamelot - Center of the universe&lt;/li&gt;
&lt;li&gt;Kamelot - The great pandemonium&lt;/li&gt;
&lt;li&gt;Kamelot - The haunting&lt;/li&gt;
&lt;li&gt;Kamelot - Abandoned&lt;/li&gt;
&lt;li&gt;Alteria - History of times to come&lt;/li&gt;
&lt;li&gt;Alteria - Fire and ice&lt;/li&gt;
&lt;li&gt;Alteria - House of my soul&lt;/li&gt;
&lt;/ul&gt;
</content:encoded></item><item><title>ITTB DevLog 2018-04-23</title><description>Firing arcs, support units and water flooding</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Mon, 23 Apr 2018 00:00:00 GMT</pubDate><guid isPermaLink="true">ittb_devlog-2018-04-23.html</guid><content:encoded>&lt;h2&gt;summary&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;firing arcs&lt;/li&gt;
&lt;li&gt;AI target selection&lt;/li&gt;
&lt;li&gt;support units&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I put off working on indirect/direct firing weapons for a couple of days to get
the basics of targeting and arc display going, but now that I have that down, I
added types of different range selection. Indirect firing weapons don’t require
a direct line of sight, these will be weapons like rockets, or attack drones.
Direct fire weapons are your classical AC and laser type weapons. L.O.S is
normally a tricky thing to implement when you are doing it for an arc F.O.V but
the weapons in this game are simple, and only have effect on files and ranks.
So no diagonals means easier L.O.S sigh implementation. Just keep looking at
the next tile in the direction you are scanning in and if you hit a target or
blocker stop progressing in that direction.&lt;/p&gt;
&lt;p&gt;Targeting got some love today as well. I had already implemented ranged weapons
for enemies and their targeting arc was visible on the map when the player was
moving, but the units did not engage the target even it if came into range. I
changed that today. If an enemy detects a player unit in firing range it will
drop it’s current target and go after the player unit. If it was committed to
an attack when the player unit jumped into range, it will still carry out the
committed attack then pursue the player unit. The adds a bit of variety to the
AI units. It is still relatively easy to tip-toe around the firing arc of the
enemies but may a smarter AI that guards choke points on the map (like a
mountain passage with a single tile width way to access an area of the map)
would make for some interesting tactics and game play.&lt;/p&gt;
&lt;p&gt;Not all units in an army are there to engage and attack. Well at least not
until it’s a last resort so I added a support unit that will increase the armor
of the enemy units as long as it is alive. It will try to center itself
relative to it’s team mates, but I may change this movement heuristic to a more
evasion biased heuristic, like run away from the player.  I’m kind of worried
if this will actually lead to all the support units grouping in one corner of
the map while trying to stay away from the player. The logic behind trying to
center them was to simulate an area of effect range for the armor boost.&lt;/p&gt;
&lt;p&gt;The number of unit types are increasing so here is a a little info on the types
so far with some of their stats:&lt;/p&gt;
&lt;h2&gt;Basic enemy&lt;/h2&gt;
&lt;p&gt;&lt;a href="/img/ittb-e1.png"&gt;/img/ittb-e1.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This guy only has melee attack with damage 1-3, armor 2 + X (based on level), speed 1 – 4&lt;/p&gt;
&lt;h2&gt;Advanced enemy&lt;/h2&gt;
&lt;p&gt;&lt;a href="/img/ittb-e2.png"&gt;/img/ittb-e2.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This guy has a melee weapon and a ranged weapon. These can get pretty dangerous as they can
switch targets and start going after the player units if they can lock onto the player.&lt;/p&gt;
&lt;h2&gt;Armor support enemy&lt;/h2&gt;
&lt;p&gt;&lt;a href="/img/ittb-e3.png"&gt;/img/ittb-e3.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;These guys don’t attack the player, but provide an armor boost +1 to all enemy unit while
they are alive.&lt;/p&gt;
</content:encoded></item><item><title>ITTB DevLog 2018-04-22</title><description>AI, support units, targeting and weapons stuff</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Sun, 22 Apr 2018 00:00:00 GMT</pubDate><guid isPermaLink="true">ittb_devlog_2018-04-22.html</guid><content:encoded>&lt;h2&gt;summary&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;AI,&lt;/li&gt;
&lt;li&gt;support units&lt;/li&gt;
&lt;li&gt;weapons&lt;/li&gt;
&lt;li&gt;targeting arcs&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I thought about different AI enemy types today. Currently the damage, and the
health/armor for the AI was being set within an interval appropriate with the
current level, but this doesn’t really give the sense that you are fighting
against different enemies. The AI also tries to compensate for the static
nature by introducing some non-determinism into target selection but still not
enough. What I need is to have different types of units. E.g a unit that stuns
the enemy, like the half snake monsters from XCOM2. Or support units that boost
the health of the all the enemies in the level unless it’s destroyed. These
types of units will need their own AI implementations. E.g a support unit won’t
go around chasing enemies, it will try to stay as far away from the player as
it can and evade the player. So to facilitate this, I moved the AI into the
enemy base class and a portion of it (target selection/movement) to the current
type of enemy. (called type A, because I haven’t yet thought about names or a
story line etc.). This turned to be a bit tedious with subtle variable
shadowing bugs creeping in an took a good portion of my day.&lt;/p&gt;
&lt;p&gt;This also lead the way for letting the enemies use the same types of weapons
the player was using, for the time being which means that the enemies will soon
get ranged weapons. This actually has an implication on the user interface, the
player should be able to see which enemy has a ranged weapon and the area that
it covers. Maybe if this were a PC game a mouse-over the enemy would reveal
it’s range and coverage but this doesn’t work when you are targeting handheld
devices.  I also don’t want to complicate the selection states further by
revealing this information when a player is not selected and an enemy is
selected etc. So the idea I came up with is to display the ranged attack arc of
the enemy when the player selects his own unit and that unit can actually move,
as it only matters when moving. This refactoring lead me to the decision to
also move the targeting code from the player and enemy classes into the weapon
classes themselves, using the wielder information for target selection (you
don’t want to shoot at friendlies). Coming from a server-side programming
background I am used to using lists, arrays etc to use composition in objects,
but with the scene tree there, it actually makes more sense to use a node in
the scene tree to hold stuff like weapons, as you get the holder of that item
from the scene tree way more easier.  Otherwise you have to pass around the
reference of the parent etc. This model of programming should also find it’s
way into other domains. You should be able to freely traverse the object graph.&lt;/p&gt;
&lt;p&gt;I was also thinking that all player units would carry a ranged weapon but this
doesn’t seem optimal to me now. Some units should only have a melee attack, and
loot a ranged weapon after progressing in the game? One thing is for sure
though you can’t have 2 ranged weapons, as that would require the player to
select which one to fire. I want to take a convention over configuration type
of approach for a mobile game. The convention here being that if you are in
melee range you can only do a melee attack. This is also kind of more
realistic. If you were in a close brawl with someone would you leave that and
try to shoot at something far away?&lt;/p&gt;
&lt;p&gt;I was able to squeeze a couple of hours more out of the day (mostly because my
SO is away on an MBA class reunion in Nashville) to implement the range arc
display for enemies that are equipped with a ranged weapon. I also changed the
sprite they use for a visual distinction between the current 2 types of
enemies.&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/ittb3.png"&gt;/img/ittb3.png&lt;/a&gt;&lt;/p&gt;
</content:encoded></item><item><title>ITTB DevLog 2018-04-21</title><description>Enemy spawns, mechanics, turns, targeting, game difficulty</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Sat, 21 Apr 2018 00:00:00 GMT</pubDate><guid isPermaLink="true">ittb_devlog_2018-04-21.html</guid><content:encoded>&lt;h2&gt;summary&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;enemy spawns&lt;/li&gt;
&lt;li&gt;game mechanics&lt;/li&gt;
&lt;li&gt;turns&lt;/li&gt;
&lt;li&gt;targeting&lt;/li&gt;
&lt;li&gt;game difficulty&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A tactical feature that was missing after the enemy spawns was an indication of
the tile of the spawn and the time.  Enemies suddenly appearing on the map and
random places doesn’t benefit the strategical and tactical aspect of the game
as the player has no chance to plan and prepare for the new wave of enemies.&lt;/p&gt;
&lt;p&gt;I implemented this ETA and location indication on the map. If the player can
get a unit on the tile for the new spawn, it will void.  This is a nice way for
the player to prevent new enemies and gives to opportunity for a trade-off.
Should I defend a building or prevent a new spawn?&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/ittb4.png"&gt;/img/ittb4.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The turn mechanics for enemies started out as alternating between movement and
attack. This made the game a bit static, but it was the basis for the push
strategy to save buildings. If an enemy was next to a target at the end of the
movement phase, the next turn would mean a damage to a building, so it was wise
to push the enemy away from the building.&lt;/p&gt;
&lt;p&gt;But during the movement turns towards the targets, the attack phase made the
game progression slow. Turns were wasted doing nothing as there wasn’t anything
to attack. I changed this around to the following structure: A turn for an
enemy is either attack or move. If the enemy reaches it’s target after a
movement turn, then it is committed to attacking that target even it’s pushed
away and will not move for that turn. Currently this means doing nothing as the
target is not in range, but I have a 2 ideas on how to stop this attack turn
being wasted. Either store the direction the attack would have been and do an
attack in that direction. If there is anything (un)lucky enough to be on that
tile, it will receive the damage (maybe including friendlies?) Or select a
target in range and just attack that target. I will have to discuss these
options and get some feedback on them.&lt;/p&gt;
&lt;p&gt;The game is suffering from being to easy. Go up to the enemies and hit them on
the head. Or even don’t go up to them and attack them from range.  Well
attacking from a distance is nice and realistic but infinite ammo for range
attacks is not. That’s why I implemented a feature to limit the number of
ranged attacks per unit per level. This makes the level progressively harder as
you have to start walking around to hit the enemies after a while.&lt;/p&gt;
&lt;p&gt;Also the chunk level generator wasn’t paying attention to the number of
buildings placed on the level. Having 9 buildings on a level makes it easier to
survive (think of buildings as player units). I added a pretty simple function
that tries to adjust the number of buildings on the level based on the current
level the player is at.&lt;/p&gt;
</content:encoded></item><item><title>Fooling the whatpulse.org client</title><description>a simple way of gaining ranking points for whatpulse.org</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Sat, 21 Apr 2018 00:00:00 GMT</pubDate><guid isPermaLink="true">whatpulse-fooler.html</guid><content:encoded>&lt;p&gt;Whatpulse is a stats service that counts how many keys you have pressed, and how many times you have clicked your mouse etc.
It is a pretty cool service, and I believe that they do not log the actual keys you press but just the numbers. I want to believe at least. They also have a ranking system with the leaders above 160M keys pressed. I'm not sure these are totally legit, as I do remember reading stuff about people replaying network packet they captured after a pulse to record fake stats. Anyways I always like cat/mouse challange so here is what I came up with to fool the client into thinking something was typed:&lt;/p&gt;
&lt;pre&gt;
activate application "MacVim"

set letters to {"q", "w", "e", "r", "t", "y", "u", "i", "o", "p", "a", "s", "d", "f", "g", "h", "j", "k", "l", "z", "x", "c", "v", "b", "n", "m"}
set listSize to count of letters
repeat 100 times
    set randomNumber to (random number from 1 to listSize)
    set letter to item randomNumber of letters
    tell application "System Events" to keystroke letter
    delay 0.05
end repeat
&lt;/pre&gt;
&lt;p&gt;This just selects random keys to send to a vim buffer. I might consider sending some fake keystokes to make up for the gap between the years that I did not use the client.&lt;/p&gt;
</content:encoded></item><item><title>ITTB DevLog 2018-04-20</title><description>Map generation</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Fri, 20 Apr 2018 00:00:00 GMT</pubDate><guid isPermaLink="true">ittb_devlog-2018-04-20.html</guid><content:encoded>&lt;h2&gt;summary&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;map generation&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Generating chunks was a good idea but not all chunks are perfect. There are
cases that some chunks may leave isolated tiles and/or buildings after the
generation. E.g&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; 0 0 0 0
 0 0 0 0
 1 1 0 0
 0 1 1 0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;this chunk is totally OK as long as it’s not placed at the bottom left
quadrant. If it is the bottom left tile is an island and pointless. Since we
are playing on an limit 8 x 8 board, we can’t have useless islands taking up
precious space. So to battle this I set out the write a connectivity check from
tile to tile and tile to building (all building need to be reachable as well).&lt;/p&gt;
&lt;p&gt;Tile to tile checking is easy with a DFS and check if every tile node is
visited. Build to tile check required a pairwise reach-ability check.  It takes
about 1 ~ 2 seconds to generate a valid map, which is acceptable. Next up the
movement of pieces and enemies where happening with place swaps, so it was
impossible to tell who went where and what happened. I decided to draw a route
line that indicated what happened to understand the movement of pieces better.
This lead to me realizing a bug in the path finding code and I changed that
completely.&lt;/p&gt;
&lt;p&gt;Previously I was using a BFS with a parent/child relationship map and back
tracking the nodes to build the path. I switched over to Lee’s algorithm which
is similar in concept but simpler. There is a more detailed approach on this
algorithm somewhere on the blog (try searching for graph path finding).&lt;/p&gt;
&lt;p&gt;With the path finder working again I completed the line drawing showing the
route the pieces had taken and also prevented pieces from jump over other
pieces blocking their way. This made the game a bit harder and more
restricting,&lt;/p&gt;
&lt;p&gt;I don’t know how it will impact the feedback during test plays.&lt;/p&gt;
</content:encoded></item><item><title>ITTB DevLog 2018-04-19</title><description>Game mechanics, enemy spawns, map generation</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Thu, 19 Apr 2018 00:00:00 GMT</pubDate><guid isPermaLink="true">ittb_devlog-2018-04-19.html</guid><content:encoded>&lt;p&gt;test playing the new turn based tower defense game which I have not yet dubbed
and shall refer to as TBTD for short I came to the conclusion that levels were
too easy. Adding more enemies is the first thing that popped into my mind but
that doesn’t make the game interesting, it only makes it tedious. In the first
round of the prototype I had the targeting set to all neighbor tile at a
distance of 1 tile.&lt;/p&gt;
&lt;p&gt;So diagonal attacks were possible. Changing this rule to only cardinal
directions increased the difficulty quite a bit. Also I came up with the
following mechanic: The player has 2 types of attacks. Ranged and melee. If you
are standing next to an enemy you default to a melee attack.&lt;/p&gt;
&lt;p&gt;You cannot use a ranged attack. If you are not next to the enemy it’s a ranged
weapon attack (if you have one). Since ranged attack will not displace the
enemy it becomes a tactical decision to use a ranged attack and keep you Mech
safe or go up to the enemy to displace it. This did add a variety to the
tactical decision needed. GO refactored the attack code into a weapons class,
so we have the foundation to add different types of weapons into the game.&lt;/p&gt;
&lt;p&gt;The pilot weapons are the Punch and Auto-cannon with different damages /
ranges.&lt;/p&gt;
&lt;p&gt;As the turns progress new enemies spawn. The current method for doing this is a
probabilistic method and the chances to spawn an enemy increase with each turn
that an enemy is not spawn. If an enemy does spawn, the chance reduces. So if
the game drags on your chances of clearing the level decrease quite a bit which
forces the player to act quickly. I’m also thinking of adding a turn counter to
make some levels survival mode levels.&lt;/p&gt;
&lt;p&gt;One feedback I got was that the levels become repetitive after a certain while,
especially if there is going to be the concept of permanent death, which I
actually find appealing. Random level generation is out of the question as
random is random, and not nice to play. So going through some procedural level
content designs, I came up with the idea of constructing the levels in chunks.
Each level consists of a combination of 4 chunks to choose from N.&lt;/p&gt;
&lt;p&gt;This can yield different level topology and game play. We’ll need to test this
to see how it goes.&lt;/p&gt;
&lt;p&gt;We discussed the concept of salvaging enemies at the end of each level
(looting) for better weapons and upgrades. This also looks like a promising
mechanic.&lt;/p&gt;
&lt;p&gt;For this to be meaningful, I will also need to implement some kind of
procedural weapon generator which I need look into.&lt;/p&gt;
</content:encoded></item><item><title>TechScan DevLog 2018-04-05</title><description>Project cycles and a new techscan cycle</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Thu, 05 Apr 2018 00:00:00 GMT</pubDate><guid isPermaLink="true">techscan_devlog_2018-04-05.html</guid><content:encoded>&lt;p&gt;I mentioned on my micro blog that I have a tendency to work on projects in
cycles. These cycles are work on games/work on financial projects. I have
noticed this in the past 2 years. I started working on chess related projects,
then the sudden crypto trading boom happened, and I started playing with
trading projects. Then the crypto market crashed and I became less interested
in the markets and started working on another TBS game. Now the Turkish Lira is
crashing and I’m once again interested in the markets. So this time I want to
make a project that analyzes US stocks and runs scanners on the price data to
generate signals. I want the system to be like twitter where you follow
companies and the signals appear in the companies timeline.&lt;/p&gt;
&lt;p&gt;The architecture so far is pretty simple&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/stocktoot-1.png"&gt;/img/stocktoot-1.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I get the stock data from IEX and cache it in Redis. N signal scanners will run
on this data to generate signals and the signal results are stored in MySQL.
There is a signal point system that is arbitrary at the moment. I assign a
multiplier and a adder value to each signal that I will use later to generate
the points. If the instruments generates signal points above a certain value it
will emit a signal.&lt;/p&gt;
</content:encoded></item><item><title>Join5</title><description>A match-N style game</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Wed, 21 Mar 2018 00:00:00 GMT</pubDate><guid isPermaLink="true">join5.html</guid><content:encoded>&lt;p&gt;Join5 is my first game with the godot engine. I did the logic programming (path finding, undo, joker supported ball destroys, etc) and a friend of mine did the graphics and GUI related programming. The game is a match-N type of game similar but a bit different than the old game I used to play on Gnome called &amp;quot;the same game&amp;quot;.&lt;/p&gt;
&lt;p&gt;The development including the GFX and SFX took about a month to complete working on average 3hrs/day on this. It did look like a superficial and simple game to implement but interesting cases did appear after we decided to add a joker colored ball.&lt;/p&gt;
&lt;p&gt;You can download it &lt;a href="https://play.google.com/store/apps/details?id=org.godotengine.join5"&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/conn5.png"&gt;image join 5&lt;/a&gt;&lt;/p&gt;
</content:encoded></item><item><title>Epic4x DevLog</title><description>Planets and populations</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Sun, 18 Mar 2018 00:00:00 GMT</pubDate><guid isPermaLink="true">epic4x_devlog-2018-03-18.html</guid><content:encoded>&lt;p&gt;If you don’t take good care of your populations on your planets, e.g starve them by not building farms or harvesting crops you will condemn them to die. But they won’t die immediately but instead after there has been starvation on the planet for long enough their chances of dying will increase with each turn. If you stop the starvation their chances of perishing will start to decrement once again.&lt;/p&gt;
&lt;p&gt;The ships have crews and now need a life support component. It’s options to install one but if you don’t the ship’s crew will start losing health points and eventually die. Life support replenishes the health of every crew member.&lt;/p&gt;
&lt;p&gt;ships are almost ready to travel between star systems. They now have FTL engines. FTL engines require a certain period to spin up and cool down before and after travel. Travel between stars can only be done through the warp lanes that connect the systems. The move command with ships equipped with an FTL drive will display the total time it takes to get to other systems.&lt;/p&gt;
&lt;p&gt;The calculator system that processes galaxy events and calculates pretty much everything each turn now operates based on a dependency mechanism. Previously it was operating based on a priority system where higher priority tasks were being executed first. But this is not scalable as I don’t want to manually keep track of which task should execute before which task, so having each calculator declare its dependencies makes much more sense. This was also a fun exercise in implementing topological sorting (first time I’ve done this).&lt;/p&gt;
&lt;p&gt;Planets have received a new property: Radius. It determines how long the planet survey takes for science ships. I also implemented various checks for planet information revealed to players. The most important one is that a player has to survey a planet before they can see any resource information.&lt;/p&gt;
&lt;p&gt;The client also got some love and now is displaying the resources in colors, check the attached images. I’ve also added notices for unemployed populations and idle buildings.&lt;/p&gt;
&lt;p&gt;We now have a new initial ship: The construction MkI. This ship can go to planets and build mining stations after the science MkI has surveyed them to exploit their orbital resources. Also, the concept of a mining station is something that is new. They are used to mine resources from planets without having to colonize them. Of course, only the orbital resources are gathered this way which is way less than the resources on the surface.&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/e4x-1.png"&gt;/img/e4x-1.png&lt;/a&gt;
&lt;a href="/img/e4x-2.png"&gt;/img/e4x-2.png&lt;/a&gt;&lt;/p&gt;
</content:encoded></item><item><title>Proxmox Home Lab adventures</title><description>notes on installing proxmox</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Sun, 11 Feb 2018 00:00:00 GMT</pubDate><guid isPermaLink="true">proxmox.html</guid><content:encoded>&lt;p&gt;Every once in a while, I somehow convince myself that I can make do without my 32gb Monster Notebook, and
repurpose it as a server (which I have always regretted and reverted back). Here is one of those adventures
using it as a virtualization server for proxmox.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;clone from the prodsys image.&lt;/li&gt;
&lt;li&gt;adjust RAM and CPU cores.&lt;/li&gt;
&lt;li&gt;Hard disk can be left at 150GB&lt;/li&gt;
&lt;li&gt;install vim&lt;/li&gt;
&lt;li&gt;change hostname in /etc/hostname and /etc/hosts&lt;/li&gt;
&lt;li&gt;reboot&lt;/li&gt;
&lt;li&gt;allow root login in /etc/ssh/sshd_config.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;PermitRootLogin yes
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;update /etc/network/interface with a static ip&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;
source /etc/network/interfaces.d/*

auto lo
iface lo inet loopback

allow-hotplug ens18
iface ens18 inet static
 address 10.0.1.40
 netmask 255.255.255.0
 network 10.0.0.0
 gateway 10.0.1.1
 broadcast 10.0.1.255

&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;reboot&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;optional&lt;/em&gt; Mount airport extreme disk.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;
mkdir /mnt/airport
mount -t cifs //10.0.1.1/MB3 /mnt/airport/ -o username=dendiz,sec=ntlm,uid=root,password=&lt;passwd&gt;
echo '//10.0.1.1/MB3 /mnt/airport  cifs  username=dendiz,sec=ntlm,uid=root,iocharset=utf8,password=&lt;password&gt; 0 0' &gt;&gt; /etc/fstab
&lt;/pre&gt;
&lt;p&gt;&lt;a href="/img/1-8KYB9bfcBk643S00.png"&gt;image&lt;/a&gt;&lt;/p&gt;
</content:encoded></item><item><title>Markov name generation</title><description>using markov chaings to generate star names</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Mon, 01 Jan 2018 00:00:00 GMT</pubDate><guid isPermaLink="true">markov.html</guid><content:encoded>&lt;p&gt;Generation of random planet names was a task I tackled recently, and these type of 'random name' generations are great candidates for Markov Chains. 
Markov chains are probabilistic structures where the next element in the chain depends on the previous elements. By training the model on a set on 
input data the process creates a chain with each link containing a set of the next probable elements. By starting at a random link in the chain 
and following until you reach an ending node it's possible to get similar names to the original set.&lt;/p&gt;
&lt;p&gt;Here is an example of how this works:
Say you have the training input&lt;/p&gt;
&lt;p&gt;&lt;code&gt;[sally sells seashells]&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;we will partition the input into 2 letter groups (the order of the chain is 2) and record the next letters that follow each partition. $ means end of word.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;(sa) -&amp;gt; l
(al) -&amp;gt; l
(ly) -&amp;gt; $

(se) -&amp;gt; l
(el) -&amp;gt; l
(ll) -&amp;gt; s
(ls) -&amp;gt; $

(se) -&amp;gt; a
(ea) -&amp;gt; s
(as) -&amp;gt; h
(sh) -&amp;gt; e
(he) -&amp;gt; l
(el) -&amp;gt; l
(ll) -&amp;gt; s
(ls) -&amp;gt; $
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;now we combine the same keys&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;(sa) -&amp;gt; (l)
(al) -&amp;gt; (l)
(ll) -&amp;gt; (y)
(ly) -&amp;gt; ($)
(se) -&amp;gt; (l,a)
(el) -&amp;gt; (l,l)
(ll) -&amp;gt; (s,s)
(ls) -&amp;gt; ($,$)
(ea) -&amp;gt; (s)
(as) -&amp;gt; (h)
(sh) -&amp;gt; (e)
(he) -&amp;gt; l
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;we have built our chain. To generate a new name we pick a random starting point and follow the chain by appending one of the characters in the 
values until we reach an end or have a long enough string. Let's say we picked ea to start. Here is a sample string that we could end up with&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;(ea) + s -&amp;gt; eas
e(as) + h -&amp;gt; eash
ea(sh) + e -&amp;gt; eashe
eas(he) + l -&amp;gt; eashel
...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;we would end up with &lt;code&gt;eashells&lt;/code&gt;. If we had encountered &lt;code&gt;(se)&lt;/code&gt; we would randomly choose between &lt;code&gt;l&lt;/code&gt; and &lt;code&gt;a&lt;/code&gt;. This small example does not product very 
original results but that's because our training data was limited. Given a large amount of data and a higher order we would end up with better results. 
Here is some clojure code to create a markov chain and generate names.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;;;the list is truncated for readability
(def words [&amp;quot;Acamar&amp;quot;,&amp;quot;Achernar&amp;quot;,&amp;quot;Achird&amp;quot;,&amp;quot;Acrab&amp;quot;,&amp;quot;Akrab&amp;quot;,&amp;quot;Elakrab&amp;quot;,&amp;quot;Graffias&amp;quot;,
            &amp;quot;Acrux&amp;quot;,&amp;quot;Acubens&amp;quot;,&amp;quot;Adhafera&amp;quot;,&amp;quot;Adhara&amp;quot;,&amp;quot;Ain&amp;quot;,&amp;quot;Aladfar&amp;quot;,&amp;quot;Alamak&amp;quot;,&amp;quot;Alathfar&amp;quot;,&amp;quot;Alaraph&amp;quot;,&amp;quot;Albaldah&amp;quot;,&amp;quot;Albali&amp;quot; ...])
    		
;;append ? to the end of each word so we have an easy way of knowing that a word has ended			
(def samples (map  #(str % &amp;quot;?&amp;quot;) words))


;;partition the words. we will use the first 2 characters as the key and the last as the value.
;;((\s \a \l) (\a \l \l) (\l \l \y) (\s \e \l) (\e \l \l) (\l \l \s) (\s \e \a) (\e \a \s) (\a \s \h) (\s \h \e) (\h \e \l) (\e \l \l))
(def orders (mapcat #(partition 3 1 %) samples))

;;convert into a list of maps with the keys and values set
;;({&amp;quot;sa&amp;quot; \l} {&amp;quot;al&amp;quot; \l} {&amp;quot;ll&amp;quot; \y} {&amp;quot;se&amp;quot; \l} {&amp;quot;el&amp;quot; \l} {&amp;quot;ll&amp;quot; \s} {&amp;quot;se&amp;quot; \a} {&amp;quot;ea&amp;quot; \s} {&amp;quot;as&amp;quot; \h} {&amp;quot;sh&amp;quot; \e} {&amp;quot;he&amp;quot; \l} {&amp;quot;el&amp;quot; \l})
(def gr (map (fn [[f s t :as o]] {(str f s) t}) orders))

;;convert maps to 2-vectors so we can group them
;;([&amp;quot;sa&amp;quot; \l] [&amp;quot;al&amp;quot; \l] [&amp;quot;ll&amp;quot; \y] [&amp;quot;se&amp;quot; \l] [&amp;quot;el&amp;quot; \l] [&amp;quot;ll&amp;quot; \s] [&amp;quot;se&amp;quot; \a] [&amp;quot;ea&amp;quot; \s] [&amp;quot;as&amp;quot; \h] [&amp;quot;sh&amp;quot; \e] [&amp;quot;he&amp;quot; \l] [&amp;quot;el&amp;quot; \l])
(def mp (map first gr))

;;group by the keys so that we have a list of possible characters for each key
;;{&amp;quot;al&amp;quot; [[&amp;quot;al&amp;quot; \l]], &amp;quot;ll&amp;quot; [[&amp;quot;ll&amp;quot; \y] [&amp;quot;ll&amp;quot; \s]], &amp;quot;el&amp;quot; [[&amp;quot;el&amp;quot; \l] [&amp;quot;el&amp;quot; \l]], &amp;quot;ea&amp;quot; [[&amp;quot;ea&amp;quot; \s]], &amp;quot;sa&amp;quot; [[&amp;quot;sa&amp;quot; \l]], &amp;quot;se&amp;quot; [[&amp;quot;se&amp;quot; \l] [&amp;quot;se&amp;quot; \a]],
;; &amp;quot;sh&amp;quot; [[&amp;quot;sh&amp;quot; \e]], &amp;quot;as&amp;quot; [[&amp;quot;as&amp;quot; \h]], &amp;quot;he&amp;quot; [[&amp;quot;he&amp;quot; \l]]}
(def gb (group-by first mp))

;;clean up the group-by so that only the following characters remain
;;{&amp;quot;ls&amp;quot; (\? \?), &amp;quot;al&amp;quot; (\l), &amp;quot;ll&amp;quot; (\y \s \s), &amp;quot;el&amp;quot; (\l \l), &amp;quot;ly&amp;quot; (\?), &amp;quot;ea&amp;quot; (\s), &amp;quot;sa&amp;quot; (\l), &amp;quot;se&amp;quot; (\l \a), &amp;quot;sh&amp;quot; (\e), &amp;quot;as&amp;quot; (\h), &amp;quot;he&amp;quot; (\l)}
(def markov-map (reduce-kv #(assoc %1 %2 (map second %3)) {} gb))

(defn generate-name
  &amp;quot;create a new name from the markov chain&amp;quot;
  []
  (loop [word &amp;quot;&amp;quot;
    part (subs (rand-nth words) 0 2)]
    (if (= part \?)
      word
      (let [new-word (str word part)
            new-part (rand-nth (markov-map (apply str (take-last 2 new-word))))]
           (recur new-word new-part)))))
    	   
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;the generation function works like this&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;our word is empty and the next part is the first 2 letters from a random word in our training data&lt;/li&gt;
&lt;li&gt;if our part is the end of a word stop and return the word so far&lt;/li&gt;
&lt;li&gt;other wise append the part to the word, select the a random value from the markov map with the key as the last 2 letters of our word&lt;/li&gt;
&lt;li&gt;recurse with the new word and new part&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Here are some of the names that the generator came up with&lt;/p&gt;
&lt;p&gt;&lt;code&gt;(take 25 (repeatedly generate-name))&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;(&amp;quot;Sape&amp;quot; &amp;quot;Kal&amp;quot; &amp;quot;Torus&amp;quot; &amp;quot;Mei&amp;quot; &amp;quot;Taulurushaukbu&amp;quot; &amp;quot;DuQue&amp;quot; &amp;quot;Cangforishynoriah&amp;quot; &amp;quot;Pavlius&amp;quot; &amp;quot;Gachine&amp;quot; &amp;quot;Arra&amp;quot; &amp;quot;Midea&amp;quot; &amp;quot;Avent&amp;quot; &amp;quot;Alcyoni&amp;quot; &amp;quot;Hava'eloremaias&amp;quot; &amp;quot;Rembus&amp;quot; &amp;quot;Scelsiascidia&amp;quot; &amp;quot;Fimsor&amp;quot; &amp;quot;Drenglossichiropus&amp;quot; &amp;quot;Ohnis&amp;quot; &amp;quot;Nex&amp;quot; &amp;quot;Bram&amp;quot; &amp;quot;Minn&amp;quot; &amp;quot;Altaramelbalia&amp;quot; &amp;quot;Gia&amp;quot; &amp;quot;Propintlah&amp;quot;)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="/code/markov-seed.txt"&gt;Here&lt;/a&gt; is a link to the full seed list.
    		
Playing with the order affects the quality of the results. For this example and order 3 was overfitting the data - producing mostly names 
identical to the ones in the training data. Order 2 seems like the best fit.&lt;/p&gt;
</content:encoded></item><item><title>Shield visual effects</title><description>A nice sphere around the ship</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Mon, 25 Dec 2017 00:00:00 GMT</pubDate><guid isPermaLink="true">shield_visual_effects.html</guid><content:encoded>&lt;p&gt;Even though I had put up some text to indicate the shield status of a ship, it doesn’t go without some visual effect to indicate a shield presence. This is mainly because I’m too lazy to read that info text every time I want to give some command to the ship. A more catchy indication is required.&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/sve1.png"&gt;/img/sve1.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Also during the economical phase you can’t move ship or adjust power diversion. I found myself clicking on ships multiple times during the economy phase without realizing that it was that phase only to thing “why aren’t my clicks registering?” followed by a “duh!” second. So I used a similar effect to indicate that you can’t select ships at the moment.&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/sve2.png"&gt;/img/sve2.png&lt;/a&gt;&lt;/p&gt;
</content:encoded></item><item><title>Turn processing and economy</title><description>What happens at each turn</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Sun, 24 Dec 2017 00:00:00 GMT</pubDate><guid isPermaLink="true">turn_processing_and_economy.html</guid><content:encoded>&lt;p&gt;2 easy parts don’t require much on the 3D side, but are a pain on the GUI part. The unity GUI is quite inferior compared to the browser that I can say. As far as I can guess it was even worse in 4.x and this is the revamped GUI system in unity 5 which still not that good. So the turn system. Turns are conducted in phases.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Movement/exploration/combat turn&lt;/li&gt;
&lt;li&gt;Economical phase&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Every 4 turns there is an economy return the others are for moving around, colonizing etc. During the movement phase the player still collects income from the colonies and pays ship maintenance costs but cannot buy ships or do research. In the economy phase the player cannot do the things done in the movement phase, but does the things not allowed in the movement phase. Every turn the ships also generate power and burn fuel.&lt;/p&gt;
&lt;p&gt;At the beginning of the economy turn the player collects the income and pays the maintenance costs and whatever is left over he can use to purchase ships or technology. There is a nice report that displays what happened economy wise at the beginning of the turn like this&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/tpae1.png"&gt;/img/tpae1.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;One thing to mention is that if there is an enemy ship in the neighbor cells of a colony then it will not produce any income. All the colonist are fearing for their lives and will not work.&lt;/p&gt;
&lt;p&gt;I’ve also added a nice bar at the top that displays the current star date and the credit points the player has and a button to confirm that the turn has ended.&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/tpae2.png"&gt;/img/tpae2.png&lt;/a&gt;&lt;/p&gt;
</content:encoded></item><item><title>Discovering enemy units and planets</title><description>What lies in the vast darkness of space?</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Sun, 24 Dec 2017 00:00:00 GMT</pubDate><guid isPermaLink="true">discovering_enemy_units_and_planets.html</guid><content:encoded>&lt;p&gt;At first I though that the game could be a game of perfect information where you know where all the planets are and where your enemies are based. But then first I made the planets invisible so you have to explore around to find planets to colonize. Then I though well I’ll also make the enemies invisible until you scan them. The procedure is quite simple: Every ship and planet has a set property called exploredBy. When creating the units you add yourself to the set. Then during the Update() call of every ship in transit you scan the neighboring cells with a radius of N and if there is anything on that cell you add yourself to their explored list and make them visible. Setting a sight line of 1 is okay for planets but could be dangerous for enemy ships as you would end up right in the middle if you go the max distance. So setting this to 2 or 3 is going to better I guess. But this is also a tactical choice: Do you spend all your power on the engines and have nothing attack/defense when you end up in the attacking range of an enemy ship, or do you travel less but have your guard up?&lt;/p&gt;
&lt;p&gt;Here is the new stuff in action on a very small map for testing purposes&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/h9.gif"&gt;/img/h9.gif&lt;/a&gt;&lt;/p&gt;
</content:encoded></item><item><title>Planet colonization</title><description>How to create a colony on a planet</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Sat, 23 Dec 2017 00:00:00 GMT</pubDate><guid isPermaLink="true">planet_colonization.html</guid><content:encoded>&lt;p&gt;This one wasn’t tricky as I expected it to be. To colonize a planet all you have to do is send a colony ship to that planet. No resistance – no ground battle the colony is yours. The colony ship disappears from the grid as it is turned into a colony base on the surface and a colonization message is displayed. Now you can get all that extra production, yeah.&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/h8.gif"&gt;/img/h8.gif&lt;/a&gt;&lt;/p&gt;
</content:encoded></item><item><title>Planets and some info panels</title><description>Some GUI additions and planets</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Thu, 21 Dec 2017 00:00:00 GMT</pubDate><guid isPermaLink="true">planets_and_some_info_panels.html</guid><content:encoded>&lt;p&gt;over the weekend I’ve added some planets to the grid. That was straight forward, find some nice planet surface textures and apply them on to a sphere. The info panels for the planets were GUI text at first with a canvas etc. But if you rotate these along the X-axis so that they lay flat on the grid the font rendering gets screwed up big time so I changed that to 3D text mesh. The results are pleasing.&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/pasip1.png"&gt;/img/pasip1.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;he planet names are 3 arrays of 5 meaningless names and a unique selection is made at random from these arrays.&lt;/p&gt;
&lt;p&gt;While at the subject of panes I also changed the ship info pane to a text mesh. The previous videos had examples of UI text and how ugly it looks when rotated as the ship info text. Now it’s much smoother:&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/pasip2.png"&gt;/img/pasip2.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;One of the tricky things here was to keep the text facing towards the user as the ship rotates. The text is a child component of the ship, and is positioned 0,0,-10 relative to the ship. When the ship rotates so does the axis for the text and it would end up in different positions for each rotation of the ship. To keep it below the ship for all rotation the positioning has to be with respect to the world axis. To accomplish this I had to get the TransformPoint for the ship location with respect to the ships origin and add the difference vector. Now when you set the position of the text you get this effect. Something along the lines of&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Vector3 p = ship.asset.transform.TransformPoint (Vector3.zero);
text.transform.position = p + new Vector3 (0, 0, -10f);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here is some video action&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/h7.gif"&gt;/img/h7.gif&lt;/a&gt;&lt;/p&gt;
</content:encoded></item><item><title>Ship mechanics</title><description>How do ships work in Hexarategy</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Wed, 20 Dec 2017 00:00:00 GMT</pubDate><guid isPermaLink="true">ship_mechanics.html</guid><content:encoded>&lt;p&gt;over the last week I’ve been thinking about how the ship mechanics should function. I wanted to come up with something that doesn’t require micro-managing a fleet of ships but is yet flexible enough for a nice tactical combat. The method I’m going to try out has the following properties&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ships have a limited amount of fuel. If that fuel runs out the ship is useless. It cannot move, attack or defend itself.&lt;/li&gt;
&lt;li&gt;Each turn N amount of fuel is converted into N*10 amounts of power.&lt;/li&gt;
&lt;li&gt;Power can be used for shields, lasers or movement.&lt;/li&gt;
&lt;li&gt;The player can decide how much of this power is used by which system, no power is wasted because after setting the shield and laser amounts the rest is used for the engines.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This looks to a like sweet spot is managing the ships vs stream lining battles but I can’t be sure until I have actually played some battles.&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/h5.gif"&gt;/img/h5.gif&lt;/a&gt;&lt;/p&gt;
</content:encoded></item><item><title>Avoiding obstacles in path</title><description>Path finding in a hex grid around obstacles</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Tue, 19 Dec 2017 00:00:00 GMT</pubDate><guid isPermaLink="true">avoiding_obstacales_in_path.html</guid><content:encoded>&lt;p&gt;Up until now there were any obstacles (excluding ship) so I really didn’t care for a proper path finding algorithm to select the cells that the ship would follow to reach it’s target. A simple rasterization of the cells were the way to calculate the path, but since I’ve added some asteroids it I also thought I’d spice up the path finding too.&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/aoip.jpg"&gt;/img/aoip.jpg&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In this picture the rasterization algorithm would pick the yellow line and the cells with the red dots on them, which are actually obscured by asteroids. The correct path is the path with the purple arrows. How to you choose these? Well luckily there are a couple of ways. The brute force version would be to do a breadth first search to find the target cell which would lead to wasted movements for sure. The next best approach is the select the next cell in the BFS not at random or in order but based on a heuristic, a good guess to which cell would lead quicker to the target cell. The easiest heuristic that comes to mind is the hex distance calculated as Math.max( x2-x1, y2-y1, z2-z1). You also add the total cost of movement to this cell, something that you know for sure. Why do we add the cost of movement? Because we may need a rotation to get to that neighbor cell, which is also a movement cost. So from the starting cell, you look at all the neighbors and calculate the distance to the target cell + the cost of movement to that cell and choose the closest one. You add the current cell to the visited list. Why? because in the next step the current cell will show up as a neighbor, and we don’t want to check that cell again. Then you advanced to that cell and do the same until you have reached your target. Is it possible that the target cell is never found or a ship will be there to block us? No because the target cell validity check is done before hand (the green cells). This is a simplified version of the A-start algorithm. Here it is in action&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/h4.gif"&gt;/img/h4.gif&lt;/a&gt;&lt;/p&gt;
</content:encoded></item><item><title>Navigation order processing</title><description>Implementing a command processing queue</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Sun, 17 Dec 2017 00:00:00 GMT</pubDate><guid isPermaLink="true">navigation_order_processing.html</guid><content:encoded>&lt;p&gt;Having ships is useless if you can’t boss them around the grid. So how would you do that, be also allowing multiple ships to move at any given time without running into each other? The first iteration of the path finder was the rasterized path finder I explained here. This method will provide a list of cells that the ship must travel through (I since have added a new algorithm that takes into account any obstacles in the way. It just returns a different list of cells which isn’t of any significance for the navigation command system). When the user clicks on a ship, we need to store that clicked cell and it’s ship into a temporary variable. The first click will also highlight the possible cells the ship can navigate to. The post about cells in range explains how there are calculated. The second time the user clicks on a cells, it can mean 3 things&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;the user wants to navigate to a cell&lt;/li&gt;
&lt;li&gt;the user wants to cancel the selection&lt;/li&gt;
&lt;li&gt;the user wants to select another ship from his fleet&lt;/li&gt;
&lt;li&gt;the user wants to attack an enemy ship&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We will address the first 3 items. Items 2 and 3 are simple so let’s get them out of the way first. If the user wants to cancel the selection, he just clicks on a cell not highlighted by the cells in range call. We just need to check if the clicked cell is in the list returned from this call. If not reset the variable that holds the clicked ship to return to the initial state. If the user wants to select another ship to move, if has clicked on a cell with one of his ships. Since he can’t attack that ship, just check if the clicked cell has a ship on it and if that ship belongs to the player. If true, set the selected cell to that one.&lt;/p&gt;
&lt;p&gt;Here is an image of a state machine that shows to transitions and states&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/nop.jpg"&gt;/img/nop.jpg&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The red transition is cancelling the selection, and the green transition is selecting another ship to navigate.&lt;/p&gt;
&lt;p&gt;Now let’s explore the case where the user wants to navigate to a cell. We need 
to support multiple ships wandering around at the same time, so the user doesn’t
have to wait for the first ship to arrive before issuing a second order.
This means we need a queue of navigation orders that will be processed at each
update. We create an object that will store the source cell, target cell, the
path the ship will take and the ship model and the ship object that carries meta
data associated with the ship. At each update call we will process each item in 
the command queue and make the required movement to the next cell in the path. 
After each item in the queue is processed it gets queued again. This way all the 
ships movements will be updated once for every update call. If there is another 
ship in the next cell for the ship we are processing just skip that command item 
for this frame. This will make the current ship wait if there is another ship 
blocking the path, until the ship moves away from that cell. There is an edge 
case that needs to handled here, which is that if the blocking ships final cell
is that cell, then the current ship will wait forever. To mitigate this case 
checking if any ships will end up at a cell blocking the way needs to be 
considered when creating the command. Processing the cells in the path of the 
command object is quite similar. Each update call, dequeue the next path from 
the paths and move towards that cell. If the ship has reached the cell, transfer
the ship to that cell and discard that cell from the path. If the path queue is 
empty, it means we have reached our destination. So here is the algorithm outlined 
in a list&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;copy the command item queue to a new queue, call it nextQueue&lt;/li&gt;
&lt;li&gt;while there are items in the queue, loop&lt;ol&gt;
&lt;li&gt;get the current command&lt;/li&gt;
&lt;li&gt;currentCell = the cell this ship is on now&lt;/li&gt;
&lt;li&gt;next cell = peek at the head of the path for the current command&lt;/li&gt;
&lt;li&gt;if there is a ship on the next cell, enqueue that command in nextQueue and continue the loop&lt;/li&gt;
&lt;li&gt;check if the ship needs a rotation to get the current cell, and process the rotation if required&lt;/li&gt;
&lt;li&gt;move the ship towards the next cell&lt;/li&gt;
&lt;li&gt;if the ship is in the next cell, transfer the ship to that cell.&lt;/li&gt;
&lt;li&gt;if there are more paths to process, requeue the current command in nextQueue&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;copy nextQueue back to command item queue&lt;/li&gt;
&lt;/ol&gt;
</content:encoded></item><item><title>Ship collision prevention</title><description>Stop ships from colliding when moving simulataneously</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Sat, 16 Dec 2017 00:00:00 GMT</pubDate><guid isPermaLink="true">ship_movement_collision.html</guid><content:encoded>&lt;p&gt;So, in the last movement video there were ship passing through each other like they were ghost ships of some sort. I could have just added a mesh collider and blew up the ship when they touched each other but that wouldn’t really make sense for ship of the same player. No same captain wouldn’t deviate from a collision course with a friendly ship (unless they’re unconscious or something). So the simplest way was to let one of the ship wait until the other one passes, and then carry on with the navigation.&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/h3.gif"&gt;/img/h3.gif&lt;/a&gt;&lt;/p&gt;
</content:encoded></item><item><title>Movement improvements</title><description>Better movements</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Fri, 15 Dec 2017 00:00:00 GMT</pubDate><guid isPermaLink="true">movement_improvements.html</guid><content:encoded>&lt;p&gt;on the last movement post I mentioned some of the improvements that I would be 
making to the ship movements. Here is the demo video of some of these improvements.
There are still some rough edges as can be seen (like ships passing through 
each other) which I will fix later. There are a few options about fixing 
colliding ships, I’m thinking of elevating the ship in the +Z axis so it will 
fly over the other ship. Another option would be to select a different route. 
Current the way of selecting the hex cells to reach the target is done like this:&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/mi.jpg"&gt;/img/mi.jpg&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;the yellow line is a direct line between the source and target cells. In the 
previous movement videos ship were taking this direct route. To rasterize the 
this route, I select N+1 equally distanced points on the line. N is the hex 
distance between the two points calculated as &lt;code&gt;Math.max( x1-x2,y1-y2,z1-z2)&lt;/code&gt;. 
These points are the green dots on the yellow line. Each of these points will 
fall into a cell on the grid and these are the cells that the ship will follow 
to reach the target, as I highlight them in white. So here is the video of the 
ship moving along the grid:&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/h2.gif"&gt;/img/h2.gif&lt;/a&gt;&lt;/p&gt;
</content:encoded></item><item><title>Hex grid neighbors</title><description>Method to get the neighboring cells in a hex grid</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Thu, 14 Dec 2017 00:00:00 GMT</pubDate><guid isPermaLink="true">hex_grid_neighbors.html</guid><content:encoded>&lt;p&gt;In the graph based storage of hex grids an important function for the cells is for them to keep track of their neighbor cells.&lt;/p&gt;
&lt;p&gt;One way you can build the neighbors list is as you are constructing the grid itself. This can be done on a direction basis. Each cell has the following the directions:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;NW (northwest)&lt;/li&gt;
&lt;li&gt;NE (northeast)&lt;/li&gt;
&lt;li&gt;E (east)&lt;/li&gt;
&lt;li&gt;SE (southeast)&lt;/li&gt;
&lt;li&gt;SW (southwest)&lt;/li&gt;
&lt;li&gt;W (west)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We will use an array of size 6 in each cell to store the neighbors. Each position in the array will correspond to a direction. It doesn’t really matter which index is which position as long as your are consistent about it. If you use an enumeration structure you will automatically assign integers for each direction, which you can then use as the indices for the neighbors array. Keep in mid that not every cell has exactly 6 surrounding cells. Depending on the position on the board some cells may have 3 or 5 but never more than 6. Here is an example to clarify things:&lt;/p&gt;
&lt;p&gt;Let’s assume the following values for the 6 directions:&lt;/p&gt;
&lt;p&gt;NW = 0, NE = 1, E = 2, SE = 3, SW = 4, W = 5&lt;/p&gt;
&lt;p&gt;And the Cell object will have a structure similar to &lt;code&gt;Cell[] neighbors = new Cell[6];&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;if the cell we are looking at has a neighbor on the NW side, then neighbors[0] 
will point to the neighbor cell. Incidentally the neighboring cells neighbors 
array would have the original cell at the SE (3) position. So this relation 
holds:&lt;/p&gt;
&lt;p&gt;For cells with 6 neighbors the original cell is refers to it’s neighbors in a 
direction and the neighbors refer to the original cell in the opposite direction.&lt;/p&gt;
&lt;p&gt;How can we calculate the opposite direction? Quite easy: The position you 
want + 3 modulo 6. The module will make the directions wrap around after 
reaching the end of the direction array.&lt;/p&gt;
&lt;p&gt;Ok so let’s start of with the easiest direction: the W – E connection.&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/hgn1.png"&gt;/img/hgn1.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In this diagram the white arrows show the W-E relationship between cells. 
Remember that we are populating the neighbor list as we create the grid, so the 
neighboring cells must exist before we can add their pointers to the neighbor 
list. If we start from the bottom left corner, the first cell has no neighbors 
to the W, so we can skip that. On to the second cell to its right. This guy has
a neighbor to the west so we can add this to the list, and the opposite neighbor 
relation also holds. We can do this for the rest of this row, and go on to the 
next row. On the next row, the same is true: skip the first add the rest. So the
condition for creating the E/W relation can be written&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;function addCell(x,z,i) {

 if (x &amp;gt; 0)
 {
  cell.neighbors[W] = cells[i - 1];
  cells[i-1].neighbors[W + 3 % 6] = cell;
 }

}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The assumption here is that all the cells in the grid are stored in an array called cells. This is a 1 dimensional array. I felt that this may be a bit counter intuitive and deserved a remark. The function will be called for each X, Z coordinate with the position of the cell in the cells array.&lt;/p&gt;
&lt;p&gt;For the SW and SE relations we need to distinguish between the cases of even and odd rows. Why? because the the first and last hex of the rows change which neighbors they have. The first element of the 2. row (index 1 so odd) has a SW and SE neighbor but the last hex is missing a SE neighbor. The first element of the 3rd row (index 2) is missing the SW neighbor. None of the cells on the first row have a SE or SW neighbor. So our conditions are:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;if (z &amp;gt; 0 ) {
 if (z % 2 == 0) {
  ...
 } else {
  ...
 }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s take a look at the even case, the purple and orange arrows:&lt;/p&gt;
&lt;p&gt;The first cell doesn’t have a SW neighbor, so that’s will be a special case. The rest of the cells have both neighbors.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;if (z % 2 ==0) {
 cell.neighbors[SE] = cells[i - width]
 //add the opposite too
 if (x &amp;gt; 0) {
  cell.neighbors[SW] = cells[i - width - 1] 
  //add the opposite too
 }
}

//The odd case (yellow and green arrows):

if (z % 2 == 0) {
...
} else {
 cell.neighbors[SW] = cells[i - width]
 //add the opposite
 if (x &amp;lt; width - 1) {
  cell.neighbors[SE] = cells[i-width+1]
  //add the opposite
 }
}
&lt;/code&gt;&lt;/pre&gt;
</content:encoded></item><item><title>Ship movements</title><description>Making the ships move using unity</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Thu, 14 Dec 2017 00:00:00 GMT</pubDate><guid isPermaLink="true">ship_movements.html</guid><content:encoded>&lt;p&gt;Tacked another core feature this evening, which is the movement of the ships 
around the grid. Thankfully Unity provides a nice method of moving object around. 
I’ll get to that but before this I tried doing stuff the old fashioned way, by 
calculating the direction vector between the source and target, and applying a 
translation vector with the delta time to move the object. This does work but 
it runs into 2 problems:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;the movements are jittery. The diagonal edges on the ship were re-rendering&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;giving a sort of escalator effect&lt;/p&gt;
&lt;ol start="2"&gt;
&lt;li&gt;comparing vectors to know when to stop the animation is not nice because of&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;the huge delta you need to provide to the comparison. Which means that there is 
a snap effect after you consider the vectors equal, because you have to center 
the object on the target cell.&lt;/p&gt;
&lt;p&gt;The best method is to use the Vector3.MoveTowards() method which guarantees that
it will never overshoot. Now comparing vectors with a rather small epsilon works
nicely and the stop / recenter animation look quite smooth. Here is what it looks
like currently:&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/h.gif"&gt;/img/h.gif&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;There are obvious things that need to be done, like the ship should follow the 
hex grids and not cut through diagonally. Also the ship needs to rotate in the
direction that it needs to navigate. Also a nice after-burner effect would be 
cool when the ship is moving.&lt;/p&gt;
</content:encoded></item><item><title>New proxmox installation</title><description>Sick of Windows quirks with VMWare, so I installed Proxmox</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Mon, 16 Oct 2017 00:00:00 GMT</pubDate><guid isPermaLink="true">homelab_devlog_2017-10-16.html</guid><content:encoded>&lt;p&gt;Gecen hafta monster notebook’a formati bastim ve proxmox VE kurdum. Windows icinden vmware player ile sunucular su d-drive yavasligindan cok etkileniyordu ayrica windowsun kafasina gore updatelerden restart atmasindan sikildim. Su ana kadar proxmostan mumnumun. Sunucularim:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;plex&lt;/li&gt;
&lt;li&gt;strix&lt;/li&gt;
&lt;li&gt;jenkins&lt;/li&gt;
&lt;li&gt;nexus&lt;/li&gt;
&lt;li&gt;kafka&lt;/li&gt;
&lt;li&gt;sandbox&lt;/li&gt;
&lt;li&gt;notebook&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;RAMin yarisini allocate ettim, bir bu kadar daha kaldirir yani.&lt;/p&gt;
</content:encoded></item><item><title>Warp lane generation with Delaunay triangulation</title><description>How to make good looking warp lanes in a space game</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Sun, 17 Sep 2017 00:00:00 GMT</pubDate><guid isPermaLink="true">warp_lane_generation_with_delaunay_triangulation.html</guid><content:encoded>&lt;p&gt;Hyper lanes a.k.a Warp Lanes? What are those? They are a simple element of most space RTS/TBS games. They the lines that connect the stars. They are the highway lanes of space time, they enable spaceships to travel through them and guide the spaceships to their destination. They are a cheap alternative to wormhole generators which bend space time to connect stars. Here are what they look like from a popular game&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/wlg1.png"&gt;/img/wlg1.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Technically speaking they are edges (the lines) between vertices (stars). What we need to do is generate these edges given a set of vertices and there a couple of methods for doing this. The first one that pops up is to generate a minimum spanning tree. But a minimum spanning tree would look this&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/wlg2.png"&gt;/img/wlg2.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;and this doesn’t exactly look like a nice interstellar highway as we would like to be able to travel to a couple of nearby stars from our origin star. This way when we are trying to reach a distant star we have multiple options of getting to that star. Image that you did your warplanes using an MST and you want to get from star A to star D and the only path is A -&amp;gt; B -&amp;gt; C -&amp;gt; D. What do you do if there is an enemy fleet in the star C system and you don’t want to engage that fleet with your science ship? Observe that the MST has only 1 connection between 2 neighboring stars so there is no way for you to do that.&lt;/p&gt;
&lt;p&gt;So here is a naive algorithm I came up with&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;let S be a list star with random coordinates in a 1000×1000 plane&lt;/li&gt;
&lt;li&gt;for each star in S&lt;ol&gt;
&lt;li&gt;if a star was visited before, skip it&lt;/li&gt;
&lt;li&gt;get the N closest stars to this star&lt;/li&gt;
&lt;li&gt;add a connection from this star to its neighbors&lt;/li&gt;
&lt;li&gt;add a connection from each neighbor to this star the get closest star also needs some attention as we don’t want to return a close neighbor if it already has a connection to the current star.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;the get closest star also needs some attention as we don’t want to return a close neighbor if it already has a connection to the current star.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;filter out all other stars except our current star&lt;/li&gt;
&lt;li&gt;filter out all stars that already have a connection with the current star&lt;/li&gt;
&lt;li&gt;map the remaining stars as a tuple of ( distance to source, this star)&lt;/li&gt;
&lt;li&gt;sort by the distance&lt;/li&gt;
&lt;li&gt;take N closest and return the stars from the tuple&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The N parameter determines the number of max connections going out from a star. Here is an image of this algorithm with N=5&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/wlg3.png"&gt;/img/wlg3.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This does look a bit better but there are too many cramped points where it’s hard to tell what’s going on. The stars are too close to each other so we need some kind of regulation when generating the random points for the stars. One way of doing this is checking the “star density” when generating the star and only placing the star if it’s acceptable. This basically means not placing a star to close another and we can do this by checking if the generated star falls within a range of existing stars. That would be done by checking if it lies in a circle of radius R with the star at its origin.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;let S be a list of stars initially empty&lt;/li&gt;
&lt;li&gt;while S size &amp;lt; number of stars to generate&lt;/li&gt;
&lt;li&gt;generate a random point in the plane&lt;/li&gt;
&lt;li&gt;if this point satisfies the density condition add the star to S&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;One point to note about this algorithm is that it has the possibility of never terminating if the density conditions are too strict and it cannot find a good place for the next star. So it’s a good idea to add a loop counter check that will terminate with an exception after a number of tries and tell the user to relax the number of stars and the radius R. The acceptable density function can be done as follows&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;let R be the minimum distance that two stars should be apart (which is the radius R)&lt;/li&gt;
&lt;li&gt;for each star already generated check if (src.x – star.x)^2 – (src.y – star.y)^2 &amp;lt; R^2&lt;/li&gt;
&lt;li&gt;if there are stars that satisfy this equation then the density condition is not satisfied.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;After adding the density check and reducing N to 3 the lines look a bit clearer.&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/wlg4.png"&gt;/img/wlg4.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;There is a fundamental error in this approach. If you select a low N (connectivity value) then you sometimes will get disconnected stars like this&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/wlg5.png"&gt;/img/wlg5.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;To address this issue a combination of an MST and the naive approach could work.&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/wlg6.png"&gt;/img/wlg6.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Now that the MST guarantees that all the graph will be connected we have addressed the issue but still, the layout doesn’t look good for efficient traveling. We still could use more triangulation that is more lanes connecting nearby stars. Using the closest N method led to a cluttered layout. The cause of this clutter is that if 2 stars are almost in a straight line and are the 2 closest stars, there will 2 connections to these stars that overlap.&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/wlg7.png"&gt;/img/wlg7.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Yet another way of connecting the stars would be to use Delaunay Triangulation. This also produces a very nice warplane structure but still, has the cluttering problem due to the star layout.&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/wlg8.png"&gt;/img/wlg8.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Now let’s address the clutter problem. It seems that the warplanes look cluttered if there are neighboring stars too close to an existing warplane.&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/wlg9.png"&gt;/img/wlg9.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;the green arrow shows a lane we could do better without. How can we detect these lanes? Just from the definition of the problem. If a neighbor star is too close to a lane, drop the existing lane so the closer lane to the a star will remain. Here is a simple outline for the algorithm that requires a bit of linear algebra:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Sort all the neighbors for each star is descending order according to their distance from the origin star.&lt;/li&gt;
&lt;li&gt;for each neighbor i to all neighbors – 1&lt;ol&gt;
&lt;li&gt;for each neighbor j from i + 1 to all neighbors&lt;/li&gt;
&lt;li&gt;if the distance of neighbor i from the lane between origin star and neighbor j &amp;lt; some threshold T discard the lane calculating the distance of a point P0 to a line given by P1 and P2 is&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;code&gt;Math.abs( (y2-y1)x0 – (x2-x1)y0 + x2y1 – y2x1 ) / Math.sqrt( Math.pow(y2-y1,2) + Math.pow(x2-x1,2) )&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Here is the result of a relaxed threshold that will draw a lot of lines&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/wlg10.png"&gt;/img/wlg10.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;here are the same results with a stricter threshold that has discarded the middle lane&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/wlg10.png"&gt;/img/wlg10.png&lt;/a&gt;&lt;/p&gt;
</content:encoded></item><item><title>Procedural Dungeon Generation</title><description>A method for generating a dungeon for rogue-like games</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Sat, 13 May 2017 00:00:00 GMT</pubDate><guid isPermaLink="true">procedural-dungeon-generation.html</guid><content:encoded>&lt;p&gt;The basics of any roguelike dungeon crawling game is the dungeon. What makes these types of game infinitely replayable is their use of procedural generation to produce a new dungeon and artifacts for each game.  Some one in the internets came up with the idea of generating dungeons based on &amp;quot;pushing out&amp;quot; random rectangles generated with in a circle. To get more realistic results it's best to use a Gaussian random number generator, as rarely anything natural is uniformly randomly created.&lt;/p&gt;
&lt;p&gt;So create some random rectangles with in a cirlce:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    for i in range(0, num_cells):
    	var xy = get_xy()
    	var wh = get_wh()
    	var type = &amp;quot;hall&amp;quot;
    	if wh.x * wh.y &amp;gt; mean_width * mean_height * 0.9:
    		type=&amp;quot;room&amp;quot;
    	cells.append({&amp;quot;id&amp;quot;: i, &amp;quot;xy&amp;quot;: xy, &amp;quot;wh&amp;quot;: wh, &amp;quot;topleft&amp;quot;: xy, &amp;quot;bottomright&amp;quot;: xy + wh, &amp;quot;type&amp;quot;:type})

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;the get_xy makes sure that the top left lies in a circle:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
func get_xy():
    var r = 100 * randf()
    var theta = randf() * 2 * PI
    var x = r * cos(theta) + 300
    var y = r * sin(theta) + 300
    return Vector2(x,y)

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;make sure that the width, height is acceptable:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;func get_wh():
    var w = gaussian(mean_width, width_dev)
    var h = gaussian(mean_height, height_dev)
    if w &amp;lt; 10 or h &amp;lt; 10: return get_wh()
    return Vector2(w,h)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;now push the rectangles outwards:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    while touching:
    	touching = false
    	for i in range(0, num_cells):
    		for j in range(i+1, num_cells):
    			var a = cells[i]
    			var b = cells[j]
    			if touches(a, b):
    				touching = true
    				var dx = min(a[&amp;quot;bottomright&amp;quot;].x - b[&amp;quot;topleft&amp;quot;].x + padding, a[&amp;quot;topleft&amp;quot;].x - b[&amp;quot;bottomright&amp;quot;].x - padding)
    				var dy = min(a[&amp;quot;bottomright&amp;quot;].y - b[&amp;quot;topleft&amp;quot;].y + padding, a[&amp;quot;topleft&amp;quot;].y - b[&amp;quot;bottomright&amp;quot;].y - padding)
    				if abs(dx) &amp;lt; abs(dy): dy = 0
    				else: dx = 0
    				var dxa = -dx/2
    				var dxb = dx + dxa
    				var dya = -dy/2
    				var dyb = dy+dya
    				shift_cell(a,Vector2(dxa, dya))
    				shift_cell(b,Vector2(dxb, dyb))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now some of the rectangles are designated as rooms if there are bigger than an average value in area.
We want to use these as the main nodes for joining the rooms together.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    cells.sort_custom(AreaSorter, &amp;quot;sort&amp;quot;)
    var num_rooms = 0
    for c in cells:
    	if c[&amp;quot;type&amp;quot;] == &amp;quot;room&amp;quot;: num_rooms += 1
    for i in range(0, min(num_rooms, num_corridor)):
    	var c = cells.pop_back()
    	rooms.append(c)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now connect the main rooms using Relative Neighborhood Graphs &lt;a href="https://en.wikipedia.org/wiki/Relative_neighborhood_graph"&gt;(RNG)&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    # connect main rooms
    var ab_dist = 0
    var ac_dist = 0
    var bc_dist = 0
    var skip = false
    for i in range(0, rooms.size()):
    	for j in range(i+1, rooms.size()):
    		skip = false
    		ab_dist = pow(center_x(rooms[i]) - center_x(rooms[j]), 2) + pow(center_y(rooms[i]) - center_y(rooms[j]), 2)
    		for k in range(0, rooms.size()):
    			if i == k or j == k: continue
    			ac_dist = pow(center_x(rooms[i]) - center_x(rooms[k]), 2) + pow(center_y(rooms[i]) - center_y(rooms[k]), 2)
    			bc_dist = pow(center_x(rooms[j]) - center_x(rooms[k]), 2) + pow(center_y(rooms[j]) - center_y(rooms[k]), 2)
    			if ac_dist &amp;lt; ab_dist and bc_dist &amp;lt; ab_dist:
    				skip = true
    			if skip: break
    		
    		if not skip:
    			if not rooms[i][&amp;quot;id&amp;quot;] in graph:
    				graph[rooms[i][&amp;quot;id&amp;quot;]] = []
    			graph[rooms[i][&amp;quot;id&amp;quot;]].append(rooms[j][&amp;quot;id&amp;quot;])
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a href="/img/procgen_dungeons.png"&gt;img&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The RNG construction and the overlap checking code is the brute force way of solving these problems. The overlap checking can be done using an interval search tree for a better runtime performance, and the wikipedia article mentions a paper with an algorithm to do it in linearithmic time. But since the number of rooms in a dungeon are relatively small, it's not worth the added code complexity&lt;/p&gt;
</content:encoded></item><item><title>Map and reduce</title><description>Map and reduce is cool, but how do you optimize the number of mappers?</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Mon, 10 Apr 2017 00:00:00 GMT</pubDate><guid isPermaLink="true">map-reduce.html</guid><content:encoded>&lt;p&gt;Map reduce is a nice algorithm for parallelizing work. Say I want to add the numbers from 1 to 100. (yes I know there is a formula for this). If each addition takes 1 unit of time, I could do this task on my own in a 100 units. But If I call 2 friends over and say&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Friend A: add the numbers from 1 to 50 and tell me the result.&lt;/li&gt;
&lt;li&gt;Friend B: add the numbers from 51 to 100 and tell me the result.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Since the 2 operations are mutually exclusive my friends could do this in parallel and tell me the results. Then I would just need to add the 2 results to get my answer. That would take &lt;code&gt;50 + 2&lt;/code&gt; units of time, almost twice as faster as doing it on my own. If I have 4 friends it would take me &lt;code&gt;25 + 4 = 29&lt;/code&gt; time units. But if I called over 100 friends each one would give me back to number I gave them and I would have to add 100 numbers after the map operation to reduce the result. So there is an optimal point for the number of mappers to take. This point is the square root of the number of operations. Although I would guess the optimal solution formula is intuitive to most people, it can be shown with simple calculus. If you write the number of steps required as the function of the number of parallel operations, and take the 1st derivative and find the solution for zero, this will be the optimal point.&lt;/p&gt;
&lt;p&gt;The function can be written like this:
for a number of operations X I need N people doing parallel work. After that I will need N steps to get to the final result.
This is can be written as&lt;/p&gt;
&lt;p&gt;&lt;code&gt;f(n) = X/n + n&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;lets take the 1st derivative&lt;/p&gt;
&lt;p&gt;&lt;code&gt;f(x) = X*n^-1 + n&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;f'(x) = -X*n^2 + C&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;if we say that this is equal to 0, then we can see that the equation is a quadratic equation with the optimal value being the square root of some value.&lt;/p&gt;
&lt;p&gt;This was just a random thought that popped up in my head today.&lt;/p&gt;
</content:encoded></item><item><title>Wikipedia word frequency</title><description>ever wonder what the most common words in wikipedia are? No? I thought so.</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Tue, 28 Mar 2017 00:00:00 GMT</pubDate><guid isPermaLink="true">wikipedia-word-frequency.html</guid><content:encoded>&lt;p&gt;Download a file that contains each word (with a length &amp;gt; 2) and its frequencies extract from the Wikipedia corpus in descending order.
The format of the file is&lt;/p&gt;
&lt;p&gt;&lt;code&gt;(&amp;lt;freq&amp;gt;,&amp;lt;word&amp;gt;)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Download&lt;/strong&gt;
&lt;a href="https://1drv.ms/u/s%21AvhnLreYwL-PgZMAiJKGr9CNvtrkhg"&gt;https://1drv.ms/u/s!AvhnLreYwL-PgZMAiJKGr9CNvtrkhg&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;here is an excerpt of the first 10 entries&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;(134754521,the)
(54428880,and)
(23193612,was)
(15908522,for)
(13531284,with)
(10813887,that)
(9944531,from)
(9452065,his)
(6237633,were)
(5892049,are)
&lt;/code&gt;&lt;/pre&gt;
</content:encoded></item><item><title>TypeSafe config override</title><description>how to override configuration values</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Tue, 28 Mar 2017 00:00:00 GMT</pubDate><guid isPermaLink="true">typesafe-config-override.html</guid><content:encoded>&lt;p&gt;Every now and then you need to be able to define some default value in your configuration and be able to override them based on the environment you are running in. TypeSafe Config has a nice way of allowing this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;production {
  service1: 172.0.0.1
  service2: ${?SERV1}
}

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;when you define you config like this if your application start with &lt;code&gt;-DSERV1=10.0.0.1&lt;/code&gt; then the command line value will override the default in the configuration file.&lt;/p&gt;
</content:encoded></item><item><title>Transparent Vertex Shader</title><description>some shader code to color a mesh with transparency</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Mon, 27 Mar 2017 00:00:00 GMT</pubDate><guid isPermaLink="true">transparent-vertex-shader.html</guid><content:encoded>&lt;p&gt;A game set in space should have a futuristic look and feel. And one of the most important factors in giving this sci-fi feel is the use of transparency. I would like the grid to have a transparent view, showing the beautiful stars in the horizon beneath  them. After rendering the surfaces the material on these surfaces will be responsible for this transparency. More specifically the shader. The OOB shader in unity doesn’t support vertex colors so I had to dive into the mysterious world of shaders. Here is what I came up with:&lt;/p&gt;
&lt;pre&gt;
Shader "Custom/Hex Surface Shader" {
    Properties {
        _Color ("Color", Color) = (1,1,1,0.5)
        _Glossiness ("Smoothness", Range(0,1)) = 0.5
        _Metallic ("Metallic", Range(0,1)) = 0.0
    }
    SubShader {
        Tags{ "Queue" = "Transparent" "RenderType" = "Transparent" }
        LOD 200
        Blend SrcAlpha OneMinusSrcAlpha
        Cull Off
        CGPROGRAM
        // Physically based Standard lighting model, and enable shadows on all light types
        #pragma surface surf Standard fullforwardshadows alpha

        // Use shader model 3.0 target, to get nicer looking lighting
        #pragma target 3.0

        sampler2D _MainTex;

        struct Input {
            float2 uv_MainTex;
            float4 color : COLOR;
        };

        half _Glossiness;
        half _Metallic;
        fixed4 _Color;


        void surf (Input IN, inout SurfaceOutputStandard o) {

            o.Albedo = IN.color;
            o.Metallic = _Metallic;
            o.Smoothness = _Glossiness;
            o.Alpha = IN.color.a;
        }
        ENDCG
    }
    FallBack "Diffuse"
}
&lt;/pre&gt;
&lt;p&gt;Here are some different version of the grid with and without transparency&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/57c7fe7543956-2.png"&gt;/img/57c7fe7543956-2.png&lt;/a&gt; &lt;a href="/img/57c7fe753838c-2.png"&gt;/img/57c7fe753838c-2.png&lt;/a&gt; &lt;a href="/img/57c7fe7539772-2.png"&gt;/img/57c7fe7539772-2.png&lt;/a&gt;&lt;/p&gt;
</content:encoded></item><item><title>Epic4x: Devlog #11</title><description>Clean ups, small improvements here and there</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Mon, 13 Mar 2017 00:00:00 GMT</pubDate><guid isPermaLink="true">epic4x_2017-03-13.html</guid><content:encoded>&lt;p&gt;Posted on March 13, 2017 by dendiz
So after a couple days of saving up features to write on the dev log, here is
what’s been happening:&lt;/p&gt;
&lt;p&gt;I cleaned up the command processing architecture and added event/state based
hooks, so now each command has a pre-execute, execute and post execute stage 
that is called.&lt;/p&gt;
&lt;p&gt;Setup/tear down tasks are be done at the pre/post stages and the execution phase 
does it’s magic. I also added validation for command→components mappings. 
So you can’t go around trying to issue a move command to a ship that doesn’t have
an engine.&lt;/p&gt;
&lt;p&gt;Issuing move commands can get confusing when there are 30.000 planets to choose from. 
The empires will have the location of all stars in the galaxy but they still need
to survey the system to get specifics. Ships now have a sensor component that will
limit the range it can navigate.&lt;/p&gt;
&lt;p&gt;I also tidied up the parameters being passed to the endpoints using the great
spring provided argument resolvers. This makes the controller layer code so
much cleaner, a pleasure to work with. I also went ahead and restructured the 
package layout by functionality instead of application layers. There is no best
practice for this so I’m trying out this type of structuring.&lt;/p&gt;
&lt;p&gt;Now that the backend processing for commands is in place, the client needed 
some attention. The client is a prototype but still it needs a nice way to
enable command input. Also the current command queue of the ships are listed.&lt;/p&gt;
&lt;p&gt;I was using random string generator for names which gets a bit complicated when
looking at planet/star names for navigation so I thought I’d code a small 
Markov chain based name generator for stars, planets and ships. 
Now I get names like the Heliak System, Coltar IV, Otein III and ships called 
Siberty. Sometimes it does spit out weird names that sound like elven too though.&lt;/p&gt;
&lt;p&gt;I also setup the QA server with automated deployments so that I can have friends 
do some play testing, even though it’s still too early for that.&lt;/p&gt;
&lt;p&gt;I merged the info requests that were made periodically into a single request to
reduce server load going forward.&lt;/p&gt;
</content:encoded></item><item><title>Epic4x: Devlog #10</title><description>The command system</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Thu, 09 Mar 2017 00:00:00 GMT</pubDate><guid isPermaLink="true">epic4x_2017-03-09.html</guid><content:encoded>&lt;p&gt;Posted on March 9, 2017 by dendiz
Today I got around to actually implementing the command system. I had to dig 
deep into spring to get the kind of class/object interaction that I was talking 
about. The commands are beans and hibernate entities at the same time. The 
issued command is persisted in the database after validation based on the 
components that the commands affected ship has. So if you want to issue a move 
command the ship must have an engine. At each turn the commands are read from 
the database and their execute method is called which actually does the 
operations like updating a ships x/y coordinates. Hibernate can infer the type
of the object after reading the database entity and call the correct execute
method. Each command extends from a base abstract command object which contains
all the parameters that each command will use. This is a bit off as an “attack” 
command will not need a destination planet field but will inherit one anyway, 
but the execute method will know which parameters to use anyway.&lt;/p&gt;
&lt;p&gt;The most challenging part was figuring out how to instantiate a spring bean with
constructor parameters. A move command is a bean but needs the parameters 
“destination planet” and “ship” at construction. The trick was using something 
like this:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-java"&gt;factory = applicationContext.getAutowireCapableBeanFactory();
Iterable&amp;lt;Command&amp;gt; commands = commandRepository.findAll();
for (Command command : commands) {
   factory.autowireBean(command);
   factory.initializeBean(command, command.getClass().getSimpleName());
   command.execute();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;commands are created with constructor parameters and saved in the database and 
augmented to a spring bean with this code.&lt;/p&gt;
</content:encoded></item><item><title>Epic4x: Devlog #9</title><description>Refactoring the planet service</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Wed, 08 Mar 2017 00:00:00 GMT</pubDate><guid isPermaLink="true">epic4x_2017-03-08.html</guid><content:encoded>&lt;p&gt;Posted on March 8, 2017 by dendiz
Populations on planets have emotions you know, there are not robots. 
You can’t expect them to work with 100% efficiency! That’s what the happiness 
factor in populations are for. I already put what affects happiness how in the 
wiki but I got to actually implementing them. So the happiness is a value from 
0 to 1.0 that is a multiplier for the resources on the a tile. It stars out at 
0.5, so if a new popuation is on a tile with 2 energy output and happiness is 
0.5 they will produce 1 energy per turn. The happiness may increase depending 
on circumstance but it will never exceed the habitability multiplier of the 
planet.&lt;/p&gt;
&lt;p&gt;In other news, I started working on ship and fleet management. I need a good 
ship command system design that is flexible as there are many command with 
different parameters. I’m thinking of linking the components on a ship with 
commands that make sense for that component, e.g an engine component is linked 
to a move command that takes from planet and to planet as parameters. 
I need to come up with a good interface for supporting different types of 
parameters though, like an FTL command would take stars as parameters and 
not planets. An attack command may take a target ship etc. There are also some 
“meta-command” like survey system would actually create N sub-commands of move 
to planet X then survey planet X then move to planey Y… you get the idea. 
Also maybe a counter on these commands would be required that is pre-calculated
and has the duration of this command. If surveying a planet takes 5 turn, then
that command will be on the top of the command queue for 5 turns then the next 
command will start processing. Maybe a looping of a commad series could be 
useful too, for example if you wish to patrol between a few star system you 
could create a command queue like FTL to system A, FTL to B, FTL to C and start 
over. I recall Aurora 4x had a similar command interface.&lt;/p&gt;
&lt;p&gt;While thinking about  this stuff I realized that the ships had an engine component which was for 
travelling between planets, but planets didn’t have coordinates therefore the 
distance between them is not known. I added coordinate generation for planet in
a system using a simple polar coordinate generation with the simple formula of:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Average distance = galaxy density / number of planets in the system
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For every new planet the distance is:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;avg distance + # of planets created * avg distance +/- avg distance / 3
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A random angle alfa Then calculate planet x,y using simlpe trigonometry. 
After plotting the planets on a map it occured to me that there were systems 
with a single planet which looks weird so I changed the planet distribution 
settings. This of course meant that the tests were screwed up again so I had to 
relax the assertions on some tests. After getting this out of the way I will 
concentrate again on the ship command systems.&lt;/p&gt;
</content:encoded></item><item><title>Epic4x: Devlog #8</title><description>Refactoring the planet service</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Fri, 03 Mar 2017 00:00:00 GMT</pubDate><guid isPermaLink="true">epic4x_2017-03-03.html</guid><content:encoded>&lt;p&gt;yet more moving code from one class to another in the process of getting a 
better code structure with method going to classes in which they make more 
sense. This also means refactoring the tests associated with the old class. 
But this moving around code phase is done for the time being and it’s not all 
that was on my agenda today. I also managed to get int around 10 more tests for
services that were previously untested and increased the code coverage of the
services to around 80%. I also implemented the feature that shuts down 
buildings if the player does not have the energy to pay their maintenance. 
Kind of a “no money no honey” situation. As I was play testing the planet 
today I actually realized that if you are unfortunate enough to get a home 
planet with very little food tiles (say 2-3) then you end up having a very 
hard time in building a population on that planet. Even if you keep building 
farms after a while you cannot support that many buildings because you run 
out of energy. If you switch the farms to power plants that the population 
point takes a very sharp dip into the negatives quite fast. Currently this 
doesn’t have any effect but I will be implementing population happiness soon 
which will mean that the populations will be very unhappy if they are starving 
and will stop operating at an optimal level of efficiency. I suppose it’s 
better than having all your building shutdown but still in the even further 
future these populations will be rebelling against you.&lt;/p&gt;
</content:encoded></item><item><title>Epic4x: Devlog #7</title><description>Refactoring the planet service</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Thu, 02 Mar 2017 00:00:00 GMT</pubDate><guid isPermaLink="true">epic4x_2017-03-02.html</guid><content:encoded>&lt;p&gt;Today was another refactoring day. Some of the functionality regarding 
buildings and tiles was all cramped up into classes that dealt with planets, 
so I gave their own classes and endpoints. At first tiles and buildings are 
entities that are tied to planets so it kind of made sense to have them in a 
planet management service but then allocating a bean that would contain 
functionality only for tiles made the system more cohesive. I also made the 
API endpoints REST compliant in case there would be other clients in the 
future that would need to talk with it altough there are no such plans right 
now. It was one of those days when you get to really see the goods and bads 
of writing automated tests. The good is that you can be very confident in 
your refactors as you have tests to verify that you have not broken any 
functionality the bad is that when you refactor you also have to refactor 
some of the tests, especially when you change the interface of a class.&lt;/p&gt;
</content:encoded></item><item><title>PGN Parser with comments and recursive variations support</title><description>C# programm to parse and represent a PGN file</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Wed, 01 Mar 2017 00:00:00 GMT</pubDate><guid isPermaLink="true">pgn-parser-recursive.html</guid><content:encoded>&lt;p&gt;PGN files are the standard way chess games are transmitted across the net. So any chess program that needs to replay or process a game needs to be able to read the PGN format.
There are very many different PGN parsers around in different programming languages. Most of them try to process the PGN using regexes, or just reduce the data to the main
line moves, event discarding the comments and annotations. This may be OK if you are processing the game for purposes of machine consumption as the comments don't mean
anything to a machine but I wanted to write a parser that preserves the comments and the recursive variations.&lt;/p&gt;
&lt;p&gt;So the first part of any non trivial parser is going to be a &amp;quot;Lexer&amp;quot; that tokenizes the input. Check out the PGN formal grammar for 
ANTLR (https://github.com/antlr/grammars-v4/blob/master/pgn/PGN.g4) that has a details. 
It's a good idea to use this ANTLR code to if you don't want to fiddle with insides of a parser.&lt;/p&gt;
&lt;p&gt;So the lexer will consume the input character by character creating tokens from this input. Here is the token class that I used:&lt;/p&gt;
&lt;pre&gt;
    public class Token
    {
        public string Type { get; }
        public string Value { get; }
        public const string MoveNumber = "MoveNumber";
        public const string SAN = "SAN";
        public const string Comment = "Comment";
        public const string EOF = "EOF";
        public const string Result = "Result";
        public const string Header = "Header";
        public const string NAG = "NAG";
        public const string LPAREN = "LPAREN";
        public const string RPAREN = "RPAREN";
        public Token(string type, string value)
        {
            Type = type;
            Value = value.Replace("\n", "");
        }

        public override string ToString()
        {
            return "Token " + Type + " " + Value;
        }
    }
&lt;/pre&gt;
&lt;p&gt;We need to treat the left parenthesis and the right one as individual tokens as they will have a special meaning when we are creating the syntax tree.&lt;/p&gt;
&lt;p&gt;Diving deeper into the Lexer:&lt;/p&gt;
&lt;pre&gt;
        private int _position = 0;
        private Char _currentChar;
        private string _text;
        private Boolean _lexingDone;

        public PgnLexer(string pgnText)
        {
            _text = pgnText;
            if (_text.Length &gt; 0)
                _currentChar = _text[_position];
        }
&lt;/pre&gt;
&lt;p&gt;pretty simple, we need to do some book keeping - the current character pointer and the input data is stored.&lt;/p&gt;
&lt;pre&gt;
        private void Advance()
        {
            _position += 1;
            if (_position &gt;= _text.Length)
            {
                _lexingDone = true;
            }
            else
            {
                _currentChar = _text[_position];
            }
        }
&lt;/pre&gt;
&lt;p&gt;each time we consume a character the Advance() method will increment the pointer and check if all the input has been consumed.&lt;/p&gt;
&lt;pre&gt;
        private void SkipWhitespace()
        {
            while (!_lexingDone &amp;&amp; 
                   (Char.IsWhiteSpace(_currentChar) || 
                                    _currentChar == '.' || 
                                    _currentChar == '\n'))
            {
                Advance();
            }
        }
&lt;/pre&gt;
&lt;p&gt;Some PGN files are transcribed by humans and contain multiple whitespaces, some are computer programs inserting optional white spaces for
better readability etc. The '.' character is also treaded as a white space as the move indication &amp;quot;2... c4&amp;quot; has multiple '.'
characters that we'll skip.&lt;/p&gt;
&lt;pre&gt;
        public Token GetNextToken()
        {
            string result = "";
            while (!_lexingDone)
            {
                //result += _currentChar;
                if (_currentChar == '(')
                {
                    Advance();
                    SkipWhitespace();
                    return new Token(Token.LPAREN, result);
                }

                if (_currentChar == ')' &amp;&amp; result.Trim().Equals(""))
                {
                    Advance();
                    SkipWhitespace();
                    return new Token(Token.RPAREN, result);
                }

                if (_currentChar == '[')
                {
                    Advance();
                    while (_currentChar != ']')
                    {
                        result += _currentChar;
                        Advance();
                    }
                    Advance();
                    SkipWhitespace();
                    return new Token(Token.Header, result);
                }
                if (_currentChar == '.')
                {
                    SkipWhitespace();
                    return new Token(Token.MoveNumber, result);
                }

                if (_currentChar == '{')
                {
                    while (_currentChar != '}')
                    {
                        Advance();
                        result += _currentChar;
                    }
                    Advance();
                    return new Token(Token.Comment, result.Replace("{","").Replace("}",""));
                }

                if ( (_currentChar == '\n' ||_currentChar == ' ' || _currentChar == ')') &amp;&amp; !result.Trim().Equals(""))
                {
                    SkipWhitespace();
                    result = result.Trim().Replace(" ", "").Replace("\n", "");
                    if (result.Equals("1-0") || result.Equals("0-1") || result.Equals("1/2-1/2") || result.Equals("*"))
                        return new Token(Token.Result, result);
                    if (result.StartsWith("$"))
                    {
                        return new Token(Token.NAG, result);
                    }
                    return new Token(Token.SAN, result);
                }

                result += _currentChar;
                Advance();

            }
            if (result.Equals(""))
                return new Token(Token.EOF, "");
            return new Token(Token.Result, result);
        }
&lt;/pre&gt;
&lt;p&gt;this is the real part that does the tokenization. Parenthesis type characters are consumed until the matching one is found, 
otherwise we consume until we reach a character that terminates a move element and return the resulting token. 
If we have consumed all the input we return the game result. Some PGN files may have extra white spaces at the end, 
so we return an EOF token if that's the case.&lt;/p&gt;
&lt;p&gt;Now that we can fetch the tokens from the file, we need to construct a tree representing the moves, comments, variations etc. in the PGN file.&lt;/p&gt;
&lt;pre&gt;
        private readonly PgnLexer _lexer;
        private Token _currentToken;

        public PgnParser(PgnLexer lexer)
        {
            _lexer = lexer;
            _currentToken = lexer.GetNextToken();
        }
&lt;/pre&gt;
&lt;p&gt;We need to track the currentToken and pass a reference to our lexer to fetch more tokens.&lt;/p&gt;
&lt;p&gt;This method will &amp;quot;eat&amp;quot; through the tokens and allow us to move forward in the processing:&lt;/p&gt;
&lt;pre&gt;
        private void Eat(string tokenType)
        {
            if (_currentToken.Type.Equals(tokenType))
            {
                _currentToken = _lexer.GetNextToken();
            }
            else
            {
                throw new Exception("Invalid syntax");
            }
        }
&lt;/pre&gt;
&lt;p&gt;Take for example this made up PGN move text:&lt;/p&gt;
&lt;p&gt;&amp;quot;1.e4 (11. f3 (111. f4 a7) a6) 1... e5 2.f4 exf4 (220... exf3) (221... exf2) 3.Nf3 g5 4.h4 ...&amp;quot;&lt;/p&gt;
&lt;p&gt;(The move numbers are not correct even the moves may be illegal but the purpose is to illustrate the tree that we are aiming to build.)&lt;/p&gt;
&lt;p&gt;We want to transform this into the following tree:&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/1-P17kH330Z1CMJ5qF.png"&gt;image http://forum.dizman.org/assets/images/1-P17kH330Z1CMJ5qF.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;All vertical connections are the next node connections and the horizontal connections are the variation connections. So &amp;quot;e4&amp;quot; move spawns a variation 
that it self has an embedded variation (hence the name recursive variations). The move &amp;quot;exf4&amp;quot; spawns 2 variations at this move.&lt;/p&gt;
&lt;p&gt;So we start with a method to transform the current token to a node:&lt;/p&gt;
&lt;pre&gt;
 private Node Element()
        {
            if (_currentToken.Type.Equals(Token.SAN))
            {
                Node node = new SanNode();
                node.Value = _currentToken.Value;
                return node;
            }

            if (_currentToken.Type.Equals(Token.Result))
            {
                return new ResultNode();
            }

            if (_currentToken.Type.Equals(Token.MoveNumber))
            {
                var node = new MoveNumberNode();
                node.Value = _currentToken.Value;
                return node;
            }

            if (_currentToken.Type.Equals(Token.Header))
            {
                var node = new HeaderNode();
                node.Value = _currentToken.Value;
                return node;

            }

            if (_currentToken.Type.Equals(Token.Comment))
            {
                var node = new CommentNode();
                node.Value = _currentToken.Value;
                return node;
            }
            {
                var node = new NullNode();
                return node;
            }

        }
&lt;/pre&gt;
&lt;p&gt;So first the code to build the tree&lt;/p&gt;
&lt;pre&gt;
        private Stack&lt;Node&gt; _stack = new Stack&lt;Node&gt;();

        private Node BuildTree(Node node)
        {
            Node root = node;
            Node prevNode = node;
            while (true)
            {
                Console.WriteLine(_currentToken);
                if (_currentToken.Type.Equals(Token.EOF))
                {
                    return null;
                }
                var currentNode = Element();
                if (currentNode.GetType() == typeof(ResultNode))
                {
                    Eat(_currentToken.Type);
                    prevNode.Next = currentNode;
                    return root;
                }


                if (_currentToken.Type.Equals(Token.LPAREN))
                {
                    _stack.Push(prevNode);
                    prevNode.Next = currentNode;
                    prevNode = prevNode.Next;
                }

                else if (_currentToken.Type.Equals(Token.RPAREN))
                {
                    prevNode.Next = currentNode;
                    var t = _stack.Pop();
                    t.Variations.Add(t.Next);
                    prevNode = t;
                    prevNode.Next = null;
                }
                else
                {
                    prevNode.Next = currentNode;
                    prevNode = prevNode.Next;
                }
                Eat(_currentToken.Type);
            }


        }
&lt;/pre&gt;
&lt;p&gt;The algorithm is as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Get the node type for the current token.&lt;/li&gt;
&lt;li&gt;if it's a termination token return.&lt;/li&gt;
&lt;li&gt;if it's not a LPAREN just eat the token and link the previous token to the current token.&lt;/li&gt;
&lt;li&gt;if it's a LPAREN it means we are starting a recursive variation annotation (RVA). So push the previous node on the stack. Once we are done with the variation, we'll need to get this node back and continue the main line. Continue linking the next node to this node as if we were not in the RVA.&lt;/li&gt;
&lt;li&gt;it we see a RPAREN pop the node on the stack and add the next pointer nodes to the variations list. Set the previous node to this node, and delete the next pointer for this node.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So if we walk through an example move text of &amp;quot;1. e4 (11. f3 a7) 1...e5 2.Nf3&amp;quot; this is node state and stack state just before the RPAREN:&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/1-awbP4CgiRNjLcGHB.png"&gt;image http://forum.dizman.org/assets/images/1-awbP4CgiRNjLcGHB.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;When we process the RPAREN we will pop the &amp;quot;e4&amp;quot; node from the stack, move the next pointers nodes to the variations, delete the next pointer and set the previous node to e4 and continue processing.&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/1-XnoB3aI53wls76dH.png"&gt;image http://forum.dizman.org/assets/images/1-XnoB3aI53wls76dH.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;There the tree with embedded variations. The code I use actually takes care of further evaluating the tree into the chess model I use in the application by 
checking if the move in the PGN is valid, and adding the comments to the move etc. But this is the basics of parsing the PGN file.&lt;/p&gt;
</content:encoded></item><item><title>Epic4x: Devlog #6</title><description>GUI love</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Wed, 01 Mar 2017 00:00:00 GMT</pubDate><guid isPermaLink="true">epic4x-2017-03-01.html</guid><content:encoded>&lt;p&gt;Posted on March 1, 2017 by dendiz
The gui got some love today with the addition of a button that says “+building” 
that will start the construction of a building on a surface tile. I also 
cleaned up some messy code on the server side that was related to storing 
some definitions about building cost, maintenance, construction time etc. 
With the construction of buildings comes the destruction of buildings too. 
I also fixed an annoying bug where the population relocation box would be 
populated with tiles that were already occupied. I’m thinking of a gui that 
will allow the players to nagivate without using a galaxy map. I checked out
some o-game screenshots and never saw a galactic map so I suspect that is
possible but I’m not sure if it would have an adverse impact on playability.&lt;/p&gt;
</content:encoded></item><item><title>Epic4x: Devlog #5</title><description>More test coverage, a birds eye look at the galaxy, more optimzations</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Tue, 28 Feb 2017 00:00:00 GMT</pubDate><guid isPermaLink="true">epic4x-2017-02-28.html</guid><content:encoded>&lt;p&gt;More tests were on my list today. Got the rest of service classes covered 
with unit tests. Up to now I had generated all of the stars using tests and 
some maths and had no idea what they would look like when laid out visually 
so I created a simple method that would output an SVG file of the star map 
with the warp lanes between the stars. The results were a complicated mess 
of a 1000 dots that are connected to each other. This is what the galaxy would 
look like zoomed out quite a lot, but the in-game map will have support for
zoom in so that you don’t have to look at that mess. At certain zoom levels 
I will also reduce the amount of information displayed on the map 
(like no resource info, star name, etc.). I also took the opportunity to
optimize the edge generation for the MST warp lane builder. It was generating 
all edges between each vertex with is way over what actually needs to be done. 
With the closest N optimization from yesterday generating only K edges to the 
closest vectice sped up the warp lane generation even more. Now I can bump up 
the number of starts from 1000 to 10000 for normal game testing. All also 
went ahead optimized calculations on the next turn event after realizing 
that they were quite slow for 10K stars. Working on these issues I also 
realized that the application would benefit from hibernate’s 2nd level 
caching so I installed and configured that too while at it. I also fixed a 
bug where buildings on tiles that hadn’t finished construction yet were 
producing resources. Tomorrow I’m planning on thinking on some client GUI 
options and adding the building construction command to the client side.&lt;/p&gt;
</content:encoded></item><item><title>Epic4x: Devlog #4</title><description>Optimize the galaxy generation and some testing</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Mon, 27 Feb 2017 00:00:00 GMT</pubDate><guid isPermaLink="true">epic4x-2017-02-27.html</guid><content:encoded>&lt;p&gt;Today I came across an interesting algorithm for selecting the K smallest 
numbers from a list of unsorted numbers. This was in direct relation to part 
of the warp lane generation algorithm I was using (MST+N closest) so I thought
I’d convert my current nlogn to this new nlogk algorithm*. It won’t matter 
to much for small galaxies but should improve performance for larger galaxies.
Another issue that was bothering me was the integration tests were taking a 
long time due to their nature of starting and stopping the context. Also 
IDEA cannot generate test coverage reports from these tests so I wrote unit
tests with mock for the planet service at 88% coverage. I plan to write this
type of tests for the rest of the service and logic classes and reduce the
number of integration tests – or at least not write more for the time being.&lt;/p&gt;
</content:encoded></item><item><title>Epic4x: Devlog #3</title><description>Structures on the planet surface</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Sun, 26 Feb 2017 00:00:00 GMT</pubDate><guid isPermaLink="true">epic4x-2017-02-26.html</guid><content:encoded>&lt;p&gt;What’s a planet surface without any buildings? A vast empty space. 
Buildings will allow the settlers on a planet to produce different resources 
on tiles. Buildings come in various forms: farms, research centers, power 
plants, etc. Each tile can have a building of any type that will produce the 
according resource. A building on a tile without a population will not produce 
anything and a building will suppress any non matching resources. So if you 
have a tile with food resource and decide to build a research center on it, 
then say good bye to the food. Building cost minerals to build and energy to 
maintain. The output and cost and maintanence cost of building depends on its level.&lt;/p&gt;
&lt;p&gt;With these requirements in mind I set of to implement these features. 
Each buildings cost, maintenance, and building time are kept in source code as
a map of type → value. Holding these in the DB or configuration file didn’t 
seem worth the trouble as these parameters will be fixed and not change for 
different games. The costs will increase with each level for the building but 
this will be calculated on the fly so I’m just storing the level 1 costs. 
Maintenance cost and time to complete the building are stored in the database 
for each instance of a building as they will change as the game progresses.&lt;/p&gt;
&lt;p&gt;As I was working on the building features I realized that the only consumption 
on a planet is food and energy. I had written the methods that calculate 
consumption in a generic way to support querying any type of resource 
consumption so I simplified that to only food and energy. I also realized that 
I had skipped increasing the player resources by the income amount so I added 
that too. I would be bad if you saw +3 energy income but you were’nt able to 
accumulate it. The relations between entities are slowly getting upto a point 
where it’s beginning to get confusing and changes are beginning to affect a few
places at once. I might start writing down stories and use cases first instead 
of just tracking them mentally which will have a negative impact on speed. 
I’m also trying to keep good test coverage going as these types of changes are 
very likely to bring up regressive errors.&lt;/p&gt;
</content:encoded></item><item><title>Epic4x: Devlog #2</title><description>A look at the planetary surface and resources</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Fri, 24 Feb 2017 00:00:00 GMT</pubDate><guid isPermaLink="true">epic4x-2017-02-24.2.html</guid><content:encoded>&lt;p&gt;If you don’t have a population on a surface tile with resources then who will harvest them? 
Well, today I implemented a feature that will allow you to move populations from one tile another.
If there is another population on the target tile, then they will swap places with the guys coming in.
Moving a population to another tile will affect their happiness in a bad way, I don’t know how bad just yet.
Another issue was the growth of populations on the planet surface. It works in the following way:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;each planet has a population point&lt;/li&gt;
&lt;li&gt;this point is increased/decreased based on food surplus on the planet&lt;/li&gt;
&lt;li&gt;there is a population score that is calculated based on the number of existing populations on the planet&lt;/li&gt;
&lt;li&gt;if the population points of a planet are &amp;gt; then the population score a new population is born.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The exact formula (each day the population point is adjusted like this):
x = food surplus (production – consumption)
image was lost
the result is added to the current planet population points. if (population points &amp;gt; nextScore) grow new population on an empty tile nextScore is calculated as 1.65p + p^1.12 where p is the current population If a new population spawns it prefers a tile with resources. If none exists then they will settle for an empty tile.
Another improvement(!) was in the UI. I added some simple drop down boxes to relocate a population from one tile to another. Yes drag and drop of populations would be nice, but that sort of UI niceness is low priority until the game mechanics are in place.
image was lost&lt;/p&gt;
</content:encoded></item><item><title>Epic4x: Devlog #1</title><description>Diving in to what I have for a turn based strategy game proto</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Fri, 24 Feb 2017 00:00:00 GMT</pubDate><guid isPermaLink="true">epic4x-2017-02-24.html</guid><content:encoded>&lt;p&gt;Being the first development log on this project and having already been working on this for some time, 
it is going to be a jump in the middle of things. Here is roughly what I have&lt;/p&gt;
&lt;h2&gt;Player registration&lt;/h2&gt;
&lt;p&gt;Each person should be able to play in multiple galaxies at the same time, although these will be isolated games. 
The required that a person is represented by a User object and this person in a galaxy is represented by a Player object. 
I got to this conclusion after painful trial and errors with the player ending up with ships and resources 
he had from another galaxy in another galaxy. I’ve left the actual registration process out of scope for the
moment and I’m just creating a default user if none exists.
Galaxy creation
Each galaxy represents a different game, and there are multiple games going on simultaneously. Galaxies 
are made up of stars systems. The galaxies are in radial form, maybe I might consider adding a spiral
form – but not a priority. The different forms of galaxies should affect FTL traveling.&lt;/p&gt;
&lt;h2&gt;Star systems&lt;/h2&gt;
&lt;p&gt;The galaxy is filled with star systems that are distributed according to a simple density 
function so that no 2 systems are within a certain range of each other. Star systems contain 
planets which the players will exploit and colonize to further their ambitions. Star systems 
are connected by Warp lanes. No system is isolated, meaning that you can travel to any star 
from any star.&lt;/p&gt;
&lt;h2&gt;Planets&lt;/h2&gt;
&lt;p&gt;Planets contain&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;orbital resources&lt;/li&gt;
&lt;li&gt;surface resources&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;orbital resources will be mined by mining stations, surface resources are collected by colonization of the planet. 
The planet surface is split up into tiles. Populations and building will be built on these tiles to gather their resources.&lt;/p&gt;
&lt;h2&gt;Resources&lt;/h2&gt;
&lt;p&gt;There are 5 types: Energy, mineral, society, physics, engineering. Energy and minerals can be stockpiled, 
the research resources cannot. Buildings, ships etc. will cost resources as will researching technologies.&lt;/p&gt;
&lt;h2&gt;Ships Designs&lt;/h2&gt;
&lt;p&gt;Ship designs are blueprints for creating ships. Ships consist of 1 to 3 sections called the core, 
bow, stern section. Each section contains a hull with different slot assignments. Slots may be 
small, medium or large and contain components. Components contain attributes and a value for that
attribute. E.g a power core component contains a power output attribute which a ship will need to
generate power for weapons or survey equipment etc.&lt;/p&gt;
&lt;p&gt;This is a summary of the current progress. Now let’s talk about some of the things I implemented today.
The game progresses in turns, which are automatically incremented at 1 turn per 10 seconds on the 
server side. Each turn planetary resources of the colonized planets are gathered and the costs are
subtracted from these. Initially, I had 5 integers representing the resources on the planets, but 
this turned out to be cumbersome when tallying the resources so I changed this to a ResourceDeposit
object with a type and amount attribute on each planet. This way I can just map the amount for an 
attribute type for each planet and just reduce them.&lt;/p&gt;
&lt;p&gt;Random numbers determine quite a bit of how a galaxy is created, but I needed a stable environment
for integration testing so I moved the Random class to a spring service which I can seed with a number
so that it generates the same numbers each time.&lt;/p&gt;
&lt;p&gt;When a player joins a galaxy some initial processing like creating the template ship designs and 
assigning a home planet must be done. When assigning a home planet an initial population of half 
of the tiles with resources is placed on the best tiles. Best tiles are the tiles with the most 
amount of resources independent of the resource type. So it’s pure chance if you end up on tiles 
with energy or minerals. You can still relocate a population to another tile at any time but that 
will have a happiness cost which in turn will reduce their productivity for some time.&lt;/p&gt;
&lt;p&gt;Gather resources from a tile only makes sense if there is a population on it. Also the productivity 
of the population should play a part in what percentage of the resources are gathered per turn, 
something is waiting to be implemented. Also added some simple client UI to see the summary and the 
surface tiles of a planet, check the image attachments on the page at the bottom. It’s fun to see how 
the UI evolves over time. One thing to mention when developing the UI is the importance of persisting 
the logged in user session, so that you don’t have to login every time you restart the application. 
I used to use in memory maps to persist session data but after a short while having to login constantly 
gets annoying so now I default to persisting sessions to the DB or maybe Memcache/Couchbase when 
running in production.&lt;/p&gt;
&lt;p&gt;Here is how all this stuff is linked together in the DB&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/ep4xdl1-2.jpeg"&gt;/img/ep4xdl1-2.jpeg&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/ep4xdl1-1.jpeg"&gt;/img/ep4xdl1-1.jpeg&lt;/a&gt;&lt;/p&gt;
</content:encoded></item><item><title>Terrain generation using cellular automata</title><description>how to generate different biome on a terrain using cellular automata</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Tue, 24 Jan 2017 00:00:00 GMT</pubDate><guid isPermaLink="true">terrain_generation_cellular_automata.html</guid><content:encoded>&lt;p&gt;Cellular automata are a nice way of representing natural terrains
for game worlds. The idea is that a cell interacts with its neighbor
cells changing their content, just as a natural process would do. The
method actually stems from biology, where a population interacts with
their neighbors either dying due to scarce resources or thriving by
multiplying due to enough mates. The algorithm is pretty simple, each
cell has a binary state that toggles based on the number of neighbors
in a state. E.g if the current cell has more than 4 neighbors that are
alive it will die, otherwise it will live. As you iterate the 2x2 matrix
of cells an organic pattern starts to emerge which is what we need when
imitating a terrain of grass. The cells may have more than 2 states, but
I've used only too to generate a grass land with 2 types of grass tiles.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    public boolean[][] run(int width, int height, int death, int birth, int runs) {
        boolean[][] map = new boolean[height][width];
        boolean[][] temp = new boolean[height][width];

        for (int i = 0; i &amp;lt; map.length; i++) {
            for (int j = 0; j &amp;lt; map[0].length; j++) {
                map[i][j] = Utils.coinFlip();
                temp[i][j] = map[i][j];
            }
        }

        int WIDTH=map[0].length, HEIGHT=map.length;

        for (int k = 0; k &amp;lt; runs; k++) {
            for (int y = 0; y &amp;lt; HEIGHT-1; y++) {
                for (int x = 0; x &amp;lt;WIDTH-1; x++) {
                    int nbs = aliveNeighbors(temp, x, y);
                    if (temp[y][x]) {
                        map[y][x] = nbs &amp;gt;= death;
                    } else {
                        map[y][x] = nbs &amp;gt; birth;
                    }
                }
            }

            //copy generated to temp for the new run
            for (int i = 0; i &amp;lt; map.length; i++) {
                temp[i] = map[i].clone();
            }

        }
        return map;
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;the death and birth parameter define how many neighboring alive cells trigger a death
or a birth. The runs parameter defines how many generations we will process.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;   public int aliveNeighbors(boolean[][] map,int x, int y) {
        int count=0, my = map.length, mx = map[0].length;
        for (int i = -1; i &amp;lt;2; i++) {
            for (int j = -1; j &amp;lt; 2; j++) {
                int nx = x + i;
                int ny = y + j;
                if (i == 0 &amp;amp;&amp;amp; j == 0) {

                } else if (nx &amp;lt; 0 || ny &amp;lt; 0 || nx &amp;gt; mx || ny &amp;gt; my) {
                    count++;
                } else if (map[ny][nx]) {
                    count++;
                }
            }
        }
        return count;
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here is an example output&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/tgwca.png"&gt;/img/tgwca.png&lt;/a&gt;&lt;/p&gt;
</content:encoded></item><item><title>Graph path finding</title><description>simple ways of finding a route in a grid/graph</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Mon, 01 Aug 2016 00:00:00 GMT</pubDate><guid isPermaLink="true">graph-path-finding.html</guid><content:encoded>&lt;p&gt;A poor mans path finding algorithm. Given a start node, find any path that leads to the target node.
I use this piece of code to generate a route from a given planet/star system to another one. The stars are guaranteed to be connected.&lt;/p&gt;
&lt;p&gt;Driver:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public List&amp;lt;StarSystem&amp;gt; FindPath(StarSystem source, StarSystem target)
{
    var path = new List&amp;lt;StarSystem&amp;gt;();
    Find(source, target, new List&amp;lt;StarSystem&amp;gt;(), path, new HashSet&amp;lt;StarSystem&amp;gt;());
    return path;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;private void Find(StarSystem source, StarSystem target, List&amp;lt;StarSystem&amp;gt; path, List&amp;lt;StarSystem&amp;gt; validPath, HashSet&amp;lt;StarSystem&amp;gt; visited)
{
    visited.Add(source);
    if (source == target) validPath.AddRange(path);
    foreach (var neighbor in source.WarpLanes)
    {
    	if (visited.Contains(neighbor)) continue;
    	path.Add(neighbor);
    	Find(neighbor, target, path, validPath, visited);
    	path.Remove(neighbor);
    }
    visited.Remove(source);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It's also possible to implement this iteratively. The following implements Lee's Algorithm (which does find the optimal solution but is rather inefficient)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;func find_path(map, src, target):
    var queue = []
    var visited = []
    var expansion = []
    for i in range(map.size()):
    	visited.append([])
    	expansion.append([])
    	for j in range(map[0].size()):
    		visited[i].append(false)
    		expansion[i].append(0)
    		if map[i][j] != 0:
    			visited[i][j] = true
    		else:
    			visited[i][j] = false
    var marker = 1
    queue.push_back({'node': src, 'dist': marker})
    expansion[src.y][src.x] = marker
    visited[src.y][src.x] = true
    while queue.size() &amp;gt; 0:
    	var cur = queue.pop_front()
    	if cur['node'] == target: break

    	var neighbors = get_neighbors(map, cur['node'])
    	for adj in neighbors:			
    		if visited[adj.y][adj.x]: continue
    		visited[adj.y][adj.x] = true
    		expansion[adj.y][adj.x] = cur['dist'] + 1
    		queue.push_back({'node': adj, 'dist': cur['dist'] + 1})
    var path = [target]
    var cur = target
    marker = expansion[target.y][target.x]
    if marker == 0:
    	return []
    while cur != src:
    	var neighbors = get_neighbors(expansion, cur)
    	for adj in neighbors:
    		if expansion[adj.y][adj.x] == marker - 1:
    			marker -= 1
    			path.push_front(adj)
    			cur = adj
    			break
    return path
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Lee's algorithm works by expanding a &amp;quot;wave&amp;quot; from the source cells to all the cells in the grid.
Assuming s = start, d = destination, 0 = walkable, * = obstacle and movement is permitted in the cardinal directions only:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;s 0 0 0 0
* 0 * 0 0
0 0 * 0 0
0 0 0 d 0
0 * 0 0 0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A BFS is done and each neighbors distance from the start cell is recorded.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;s 1 0 0 0
* 0 * 0 0
0 0 * 0 0
0 0 0 d 0
0 * 0 0 0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;only 1 neighbor cell is walkable&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;after all the cells have been visited the expansion matrix is like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;s 1 2 3 4
* 2 * 4 5
4 3 * 5 6
5 4 5 d 7
6 * 6 7 8
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The path is found by starting at the target and walking backwards towards the neighbor with the smaller number.&lt;/p&gt;
</content:encoded></item><item><title>Moved to Seattle</title><description>Our first couple of days in Seattle</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Thu, 09 Jun 2016 00:00:00 GMT</pubDate><guid isPermaLink="true">moved_to_seattle.html</guid><content:encoded>&lt;p&gt;So the last 2 years I’ve been going back an forth between Pittsburgh and Istanbul every couple of months to visit my wife who was getting her MBA at the Tepper school of business at Carnegie Mellon University. This year she has graduated and has accepted a job offer from a Seattle company and we made the move to Seattle beginning of June after having my parents and the in-laws visit us in Pittsburgh for 10 days (lots of great places seen during their visit for 10 days, but that’s a whole different story). The plan before moving here was to stay at a hotel for a week while we were apartment hunting. I went online to booking.com to find a hotel. Hotels in Seattle are quite expensive since we wanted to stay near residential areas close to down town because our car wouldn’t arrive until a couple of days in. I found the best solution was to rent an “apartel” from Ginosi. This is basically a 1 bedroom apartment in a building. After a 7 hour flight from Pittsburgh when we arrived at the apartel and let our selves in we were pleasantly surprised as it only had 10 reviews on booking.com but a high rating. The place was called “Puget Indigo” and was located at 4th Ave. and Republican West. We arrived late sunday evening so just had to go straight to the apartment with 4 huge pieces of luggage and 3 backpacks and just call it a day. The next was memorial day so all the leasing offices were closed. We spent the day on zillow.com looking for places and reading reviews and social statistics about different neighborhoods like Queen Anne, Ballard, Belltown etc. We decided to assign a day for each neighborhood and Tuesday was Queen Anne day. We had heard good things about this place so it was a priority . B. made an excel sheet with all the places we wanted to see in Queen Anne (roughly 8 places) that matched our criteria. So the first place turned out to be an apartment in the building we were staying at! That was quite funny because we just took the elevator 2 floors down to meet the leasing specialist which took us back to the 4th floor and showed us the place. The location of the building was OK but there were renovations going on at the building and it was the first place we saw so we didn’t really have anything to compare with. The next place we went to see was a condo in upper Queen Anne. The apartment was located on a very nice street with lots of houses with gardens, very residential. But you had to take 2 flights of stairs to reach the building entrance, and 2 more to reach the apartment. This was something I didn’t like having lived at places like that for years. The apartment was small and the bathrooms were old  –- no go.&lt;/p&gt;
&lt;p&gt;The next place was Tarmigan located at 14th Ave W and W Boston St. This was a 2 bedroom loft with a huge volume due to high ceilings and all but it was old and the appliances looked like they were from the 80’s. The best thing to do with that place would be to buy, tear it down and rebuild it.&lt;/p&gt;
&lt;p&gt;Next up was Metro on First located at John St. and 1st Ave. W. The building looked very nice from the outside with julliet patios and architecture resemblant of European style. The main entrance has a small fountain outside and a small garden. I loved how the building looked from the outside. We met with the leasing specialist and she showed us the apartment. It was great! 2 bedrooms 2 bathrooms. A living room with a great view!&lt;/p&gt;
&lt;p&gt;image&lt;/p&gt;
&lt;p&gt;Just for the sake of being the devils advocate I insisted that we see a couple of more places after we saw this apartment even though I really liked it. It was around 3pm and our next appointment was at 7 pm so we went back to the hotel to plan the next day.  10 minutes after we started look at houses in Belltown I said “this is useless, I really liked Metro on First. Let’s pull the trigger on that one”. And so here we are living in lower Queen Anne, Seattle.&lt;/p&gt;
&lt;p&gt;Now it’s time to decorate a new house from scratch for the 3rd time.&lt;/p&gt;
</content:encoded></item><item><title>Blog engine</title><description>A small windows program to generate a static site from markdown</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Fri, 01 Jan 2016 00:00:00 GMT</pubDate><guid isPermaLink="true">blogengine.html</guid><content:encoded>&lt;p&gt;Update 2021-09-11:&lt;/p&gt;
&lt;p&gt;I've switched to a python script and markdown&lt;/p&gt;
&lt;p&gt;Update 2021-06-06:&lt;/p&gt;
&lt;p&gt;I'm using a python script that compiles
posts from Jupyter notebooks.&lt;/p&gt;
&lt;p&gt;Update 2018-05-09:&lt;/p&gt;
&lt;p&gt;I've switched to Hugo&lt;/p&gt;
&lt;p&gt;Update 2018-04-15:&lt;/p&gt;
&lt;p&gt;I decided to write a script using python + make to automate this static site generation. This small program is now obsolete, and
replace with this script.&lt;/p&gt;
&lt;p&gt;2017-05-01:&lt;/p&gt;
&lt;p&gt;I just bought a new laptop to replace my mac book pro retina that was running kind of slow and doesn't really play along with windows, and with this switch all my main computers are now running on windows. I saw this as an opportunity to brush up on my desktop application development. I'm sure there have been tremendous amounts of progress on the desktop development end, but I'm oldschool and went ahead with the classic duo winforms/c#. I wrote a quick port of the groovy script that I used to generate this site as an application.&lt;/p&gt;
&lt;p&gt;I used to provide a binary for this project, but I've decided it could be a security breach so I removed it.&lt;/p&gt;
&lt;p&gt;Future me: Just clone the repo and rebuild the solution, sorry!&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/blogengine.PNG"&gt;/img/blogengine.PNG&lt;/a&gt;&lt;/p&gt;
</content:encoded></item><item><title>Seattle flyback</title><description>Amazon sponsored tour from Pittsburgh to Seattle</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Thu, 15 Oct 2015 00:00:00 GMT</pubDate><guid isPermaLink="true">seattle_flyback.html</guid><content:encoded>&lt;p&gt;So we were invited to fly out to Seattle to check out the city. The trip from Pittsburgh is a relatively long one. Pittsburgh to NY is a 1 hour flight, a 2 hour layout over at JFK, then a 6.5 hour flight to Seattle, only to be greeted by rainy weather. Well what can you do, I guess this is how Seattle is like. We stayed at a corporate housing facility at 1201 Mercer Street and it was quite good. They had everything you could possibly need in the room, from a tumble dryer to a coffee maker. So the first day I got soaking wet strolling around in the city. I took a walk from the apartment to the Seattle Centre going down Mercer street to 5th Ave visiting the Bill And Melinda Gates foundation building, then going down 5th by the Space Needle to Denny Way to the Pacific Science Centre. I thought I'd pay that place a visit but it turned out to be a place for kids so I didn’t want to spend 30$ on that and decided to walk back to the room, as I was a bit under the weather and still feeling tired from the trip the other day. We had some donuts at the Toppot donuts place and headed out to a cocktail. Then we had some good sushi at a place called Japonessa on 1st Ave.&lt;/p&gt;
&lt;p&gt;The next day we were at Pike Place Marker which is a huge farmers market and some other shops. Mostly small local businesses. Interesting shops were a chocolate shop which make genuine chocolate and a hot pepper shop which makes hot chili sauce. The most chili one is made from scorpion pepper extract which I dare not taste. The sauces were expensive, 20$ for about 5 cl of extract. We stopped by the Pike brewery to grab some beer then headed back.&lt;/p&gt;
&lt;p&gt;A donut place in Pike Place market
A donut place in Pike Place market&lt;/p&gt;
&lt;p&gt;We also got to see the first Starbucks shop, which had a long line in front of it with people wanting to drink some coffee there.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;image lost&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;We headed back to the Space Needle after the market place visit, but the weather was cloudy and rainy so we didn't go up. The people who did go up said it wasn't worth it anyway because of the clouds. From the Space Needle we headed to a neighborhood called Ballard and had lunch at a place called Kiss Cafe. Great soup and sandwiches. We strolled around for a bit and sat at a Starbucks and then headed back to 1 Ave for a dinner at an Italian place called Bellini's.&lt;/p&gt;
&lt;p&gt;Seattle looks like a great place, but the weather is rainy and gray 80% of the year.&lt;/p&gt;
</content:encoded></item><item><title>chessboard heat map</title><description>a spark app that generates a heatmap for chess pieces</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Sun, 20 Sep 2015 00:00:00 GMT</pubDate><guid isPermaLink="true">chessboard-heatmap.html</guid><content:encoded>&lt;p&gt;The apache spark framework is a great way of processing HUGE amounts of data in parallel. The learning curve is really flat, and you’ll get to crunching data in no time. I have already implemented a batch log processing / analytics application and a real-time streaming application at work for n11 and I thought that I do another fun project with spark. This time it’s generating a heat-map of a chess board by processing chess games. A heat map of a chess board is 8×8 table with each cell representing a square of the chess board with a color. Blue means there were not many moves to that square, and red means there were a lot. It’s an analogy to the warm-cold method of defining distance. We will do this for each piece there is in chess. The end results will look something like this&lt;/p&gt;
&lt;p&gt;&lt;a href="http://i.imgur.com/6hGU74G.png"&gt;http://i.imgur.com/6hGU74G.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;So, a method we could use and that I’ve tried was to generate a FEN representation of the board after each move, and feed this data to apache spark to extract how much each piece occupied each square. This did sound reasonable and it would have been very efficient because spark would not need any chess knowledge to compute the heat map. Just some string parsing would suffice. But it turns out that this method of processing overwhelms the heat map with the initial positions of the piece. Why? because the pieces rest on their initial squares for quite some time before they move. Let’s look at an example to make it clearer. The initial state of the board as a FEN string is:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;this would mean add 1 to the squares for each piece. E.g the rooks are on a1, a8, h1, h8. Add 1 to each square. After the first move, say 1. e4, the FEN is&lt;/p&gt;
&lt;p&gt;&lt;code&gt;rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The pawn will register a hit for the e4 square, but so will all the other remaining pieces for their home squares! The will generate a heat map that says all the pieces like their home squares best which isn’t really helpful.&lt;/p&gt;
&lt;p&gt;So we need another approach. The best way is to register a square that a piece has moved to. This requires parsing the moves in the PGN game and actually playing through the game. So we need a chess parsing library to use in our spark job. Fortunately I had a nifty little port of chess.js for java handy here that would allow me to play through the games and get back the squares the pieces moved to. But before we can dive into this, we need to clean the PGN files and make them suitable for processing by Spark. Data processing platforms like spark like to munch data that are in CSV format – a line of values separated by a comma. The values in our file will be the moves from each game, starting from the initial position. Here is an example of what I mean&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;d4,Nf6,c4,e6,Nf3,d5,Nc3,Be7,Bg5,h6,Bh4,O-O,e3,b6,Bd3,Bb7,
O-O,Nbd7,Bg3,c5,cxd5,Nxd5,Nxd5,Bxd5,Rc1,Nf6,dxc5,Bxc5,a3,a5,
Qe2,Nh5,Be5,Bxf3,gxf3,Qg5+,Bg3,g6,Rc4,Rfd8,Rd1,Rd5,Rg4,Nxg3,
hxg3,Qf6,Rf4,Qg5,Rg4,Qf6,Rf4,Qg5,Rg4,Qf6
e4,c5,Nf3,d6,d4,cxd4,Nxd4,Nf6,Nc3,a6,g3,e6,Bg2,Be7,O-O,O-O,a4,
Nc6,Be3,Rb8,f4,Qc7,Kh1,Bd7,Nb3,b6,g4,h6,Qe2,Nb4,Nd4,Rbc8,
Rad1,Qc4,Qf3,e5,Nf5,Bxf5,exf5,exf4,Rd4,Qc7,Bxf4,Nxc2,Rd2,Nb4,h4,
Nh7,g5,Qc4,f6,gxf6,gxf6,Bxf6,Ne4,Be5,Rxd6,Bg7,Bxh6,Bxh6,Rxh6,Rc6,Qg4+,Kh8,Rxh7+
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So let’s dive into converting the PGN files.We will use the excellent chesspresso library to parse the PGN files because I haven’t yet integrated PGN methods into chesslib. the dependency for chesspresso can be added using&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;resolvers += &amp;quot;clojars.org&amp;quot; at &amp;quot;http://clojars.org/repo&amp;quot;
libraryDependencies += &amp;quot;com._0xab&amp;quot; % &amp;quot;chesspresso&amp;quot; % &amp;quot;0.9.2&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Thanks to the guy who was kind enough to package and upload this to a repository. Meanwhile I’m not so nice and haven’t uploaded chesslib to a repository, but no problem we’ll just add it to the /lib directory and the sbt assembly plugin will pick it up from there. So let’s start by parsing the PGN files using chesspresso&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;def getGames(file: File) : Stream[Game] = {
    val fis = new FileInputStream(file)
    println(&amp;quot;parsing file &amp;quot; + file)
    val reader = new PGNReader(fis, &amp;quot;&amp;quot;)

    val games = di2(reader)
    //println(file + &amp;quot;... found &amp;quot; + games.size + &amp;quot; games&amp;quot;)

    games
  }

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;this method expects the PGN file as a File object, and reads it using the chesspresso PGNReader.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;def di2(reader:PGNReader): Stream[Game] = {
    @tailrec
    def di3(game:Game, reader:PGNReader, gameList : Stream[Game]): Stream[Game] = {
      if (Option(game).isDefined) {
        if (gameList.size % 5000 == 0) {
          println(&amp;quot;processing game &amp;quot; +gameList.size + &amp;quot; &amp;quot; + game)
        }
        //println(&amp;quot;found game &amp;quot; + game + &amp;quot; list size &amp;quot; +gameList.size )
        di3(try {reader.parseGame()} catch{ case e:Exception=&amp;amp;gt;reader.parseGame()},reader, game #:: gameList)
      } else {
        gameList
      }
    }
    di3(reader.parseGame(), reader, Stream.empty)
  }

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;this is the actual method that reads the games to a list. Chesspresso iterates over the games and streams the games from the file on demand (because PGN files may contain more than one game). Since we are consuming the whole stream this will not work if you try to process a PGN file with lots of games in it (around 1M suffers on my 8gb machine). If you need to split a PGN file to smaller files use pgn-extract.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; def extractMoves(game:Game) : String = {
    game.gotoStart()
    try {
      val mainLine = game.getMainLine.toSeq
      val moves = mainLine.map(x=&amp;gt; {
        game.getPosition.doMove(x)
        x
      }).toList.filter(_ != &amp;amp;quot;&amp;amp;quot;)
      moves.mkString(&amp;amp;quot;,&amp;amp;quot;)
    } catch {
      case e:Exception=&amp;gt;&amp;quot;&amp;quot;
    }
  }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This method will get the moves made in the game as a list and concatenate them using a comma to the CSV format that I showed you above. Chesspresso will throw an exception on an invalid move, and some PGN’s do contain invalid moves.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; def main(args:Array[String]) = {
    val hotFolder = &amp;quot;/data/pgn/archive/&amp;quot;
    val outFolder = &amp;quot;/data/fen/&amp;quot;
    val files: Seq[File] = new File(hotFolder).listFiles().toSeq.filter(_.getName.endsWith(&amp;quot;pgn&amp;quot;))

    files.foreach({file=&amp;gt;
      val games = getGames(file)
      val moves = games.map(extractMoves)
      val target = new BufferedOutputStream( new FileOutputStream(new File(outFolder+file.getName + &amp;quot;.moves&amp;quot;)) )
      try moves.foreach({x=&amp;gt; target.write(x.getBytes); target.write(&amp;quot;n&amp;quot;.getBytes) }) finally target.close
    })
  }

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;All that’s left is to execute the parsing methods and save the CSV move list to a file and we are ready to jump into spark to process this data. Thats what the main function above does.&lt;/p&gt;
&lt;p&gt;So let’s define some spark configs like the CSV file location etc.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;val logFile = &amp;quot;/data/fen/&amp;quot; // Should be some file on your system
val outputDir = &amp;quot;/tmp/&amp;quot;
val conf = new SparkConf().setAppName(&amp;quot;Simple Application&amp;quot;)
val sc = new SparkContext(conf)
val moveData = sc.textFile(logFile)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;we will also need a data structure to hold the results, how many times each piece moves to a square.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; val map = Map(
        &amp;quot;r&amp;quot; -&amp;gt; Array.fill(64)(0),
        &amp;quot;n&amp;quot; -&amp;gt; Array.fill(64)(0),
        &amp;quot;b&amp;quot; -&amp;gt; Array.fill(64)(0),
        &amp;quot;k&amp;quot; -&amp;gt; Array.fill(64)(0),
        &amp;quot;q&amp;quot; -&amp;gt; Array.fill(64)(0),
        &amp;quot;p&amp;quot; -&amp;gt; Array.fill(64)(0)
      )
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;this map can be though of like this: the keys represent each piece (the colors are irrelevant) and the values are an array of size 64 – one slot for each square on the chess board. When a piece moves to a square we will increment the count in the array.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  val mmap = Map(
        &amp;quot;a8&amp;quot;-&amp;gt;0, &amp;quot;b8&amp;quot;-&amp;gt;1, &amp;quot;c8&amp;quot;-&amp;gt;2, &amp;quot;d8&amp;quot;-&amp;gt;3, &amp;quot;e8&amp;quot;-&amp;gt;4, &amp;quot;f8&amp;quot;-&amp;gt;5, &amp;quot;g8&amp;quot;-&amp;gt;6, &amp;quot;h8&amp;quot;-&amp;gt;7,
        &amp;quot;a7&amp;quot;-&amp;gt;8, &amp;quot;b7&amp;quot;-&amp;gt;9, &amp;quot;c7&amp;quot;-&amp;gt;10,&amp;quot;d7&amp;quot;-&amp;gt;11,&amp;quot;e7&amp;quot;-&amp;gt;12,&amp;quot;f7&amp;quot;-&amp;gt;13,&amp;quot;g7&amp;quot;-&amp;gt;14,&amp;quot;h7&amp;quot;-&amp;gt;15,
        &amp;quot;a6&amp;quot;-&amp;gt;16,&amp;quot;b6&amp;quot;-&amp;gt;17,&amp;quot;c6&amp;quot;-&amp;gt;18,&amp;quot;d6&amp;quot;-&amp;gt;19,&amp;quot;e6&amp;quot;-&amp;gt;20,&amp;quot;f6&amp;quot;-&amp;gt;21,&amp;quot;g6&amp;quot;-&amp;gt;22,&amp;quot;h6&amp;quot;-&amp;gt;23,
        &amp;quot;a5&amp;quot;-&amp;gt;24,&amp;quot;b5&amp;quot;-&amp;gt;25,&amp;quot;c5&amp;quot;-&amp;gt;26,&amp;quot;d5&amp;quot;-&amp;gt;27,&amp;quot;e5&amp;quot;-&amp;gt;28,&amp;quot;f5&amp;quot;-&amp;gt;29,&amp;quot;g5&amp;quot;-&amp;gt;30,&amp;quot;h5&amp;quot;-&amp;gt;31,
        &amp;quot;a4&amp;quot;-&amp;gt;32,&amp;quot;b4&amp;quot;-&amp;gt;33,&amp;quot;c4&amp;quot;-&amp;gt;34,&amp;quot;d4&amp;quot;-&amp;gt;35,&amp;quot;e4&amp;quot;-&amp;gt;36,&amp;quot;f4&amp;quot;-&amp;gt;37,&amp;quot;g4&amp;quot;-&amp;gt;38,&amp;quot;h4&amp;quot;-&amp;gt;39,
        &amp;quot;a3&amp;quot;-&amp;gt;40,&amp;quot;b3&amp;quot;-&amp;gt;41,&amp;quot;c3&amp;quot;-&amp;gt;42,&amp;quot;d3&amp;quot;-&amp;gt;43,&amp;quot;e3&amp;quot;-&amp;gt;44,&amp;quot;f3&amp;quot;-&amp;gt;45,&amp;quot;g3&amp;quot;-&amp;gt;46,&amp;quot;h3&amp;quot;-&amp;gt;47,
        &amp;quot;a2&amp;quot;-&amp;gt;48,&amp;quot;b2&amp;quot;-&amp;gt;49,&amp;quot;c2&amp;quot;-&amp;gt;50,&amp;quot;d2&amp;quot;-&amp;gt;51,&amp;quot;e2&amp;quot;-&amp;gt;52,&amp;quot;f2&amp;quot;-&amp;gt;53,&amp;quot;g2&amp;quot;-&amp;gt;54,&amp;quot;h2&amp;quot;-&amp;gt;55,
        &amp;quot;a1&amp;quot;-&amp;gt;56,&amp;quot;b1&amp;quot;-&amp;gt;57,&amp;quot;c1&amp;quot;-&amp;gt;58,&amp;quot;d1&amp;quot;-&amp;gt;59,&amp;quot;e1&amp;quot;-&amp;gt;60,&amp;quot;f1&amp;quot;-&amp;gt;61,&amp;quot;g1&amp;quot;-&amp;gt;62,&amp;quot;h1&amp;quot;-&amp;gt;63
      )

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;this second mmap array is a mapping from the string (SAN) notation of a square to it’s place the array that I mentioned above. We will need this because chesslib’s internal representation of a chess board as an array is different than what we will be using. Now let’s get to crunching those chess moves:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
 val key = moveData.flatMap(line=&amp;gt; {
      // the maps above are here - omitted for readability
      val cl = new ChessLib()
      cl.reset()
      val moves = line.split(&amp;quot;,&amp;quot;)
      moves.foreach(move=&amp;gt; {
        try {
          val resultMove = Option(cl.move(move))
          if (resultMove.nonEmpty) {
            val piece = resultMove.get.piece
            val to = resultMove.get.strTo
            map(piece)(mmap(to)) += 1
          }
        } catch { case _ =&amp;gt; }
      })
      map.toSeq
    }).groupByKey()
    val map1: RDD[(String, List[Array[Int]])] = key.map(x=&amp;gt; (x._1, x._2.toList))

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;we start by mapping each line in our input. We initialise a chesslib instance that we will use to process the moves and reset to the starting position of a game. Next we split the CSV into a list of moves and for each move we make chesslib play that move. The result of the move method contains the piece and the square that the move was made to. We take that square and increment the count in the array contained in the map. We will need some grouping to we convert the map into a sequence. So before the sequence the result will be something like&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Map(&amp;quot;r&amp;quot;-&amp;gt; Array(10, 15, 20, 2, ...) //64 of these numbers
Map(&amp;quot;r&amp;quot;-&amp;gt; Array(11, 25, 10, 1, ...) //64 of these numbers
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;after the conversion to a sequence we will have&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;(&amp;quot;r&amp;quot;, Array(10, 15, 20, 2, ...)), (&amp;quot;r&amp;quot;, Array(11, 25, 10, 1, ...)), ...

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Why do we need this? because we will merge these maps to sum all the values in the arrays for each piece. The above example states that the rook was on a1 10 times in game 1 and 11 times in game 2. So the heat map will contains 21 for the rook on a1. When we group this sequence by key using the spark provided groupByKey method we will have the following result&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;(&amp;quot;r&amp;quot; -&amp;amp;gt; List(Array(10, 15, 20, 2, ...), Array(11, 25, 10, 1, ...) )
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;we need to add the corresponding indexes in each array to obtain our result. We will use a helper function for this called combineLists&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;def combineLists[A](ss:List[Array[A]]) =
    (ss.head.map(List(_)) /: ss.tail)(_.zip(_).map(p=&amp;gt;p._2 :: p._1))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;this methods takes a list of arrays, and returns a list of zipped lists. To for the input&lt;/p&gt;
&lt;p&gt;&lt;code&gt;List(1,2,3), List(5,6,7), List(7,8,9)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;we will get the output&lt;/p&gt;
&lt;p&gt;Next we need to sum the values in the combined lists for a our final result&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;val map2: RDD[(String, List[Int])] = values.map(x=&amp;amp;gt; (x._1, x._2.map(_.sum).toList))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;this will give us the total numbers of moves to each square for each piece. Just what we needed for the heat map!
But we still need to do one more thing before we can start the rendering of the map and that is to normalise the values in the array to values between 0 and 1. We can do that using the feature normalisation formula&lt;/p&gt;
&lt;p&gt;&lt;a href="http://imgur.com/l4gwnyv.png"&gt;http://imgur.com/l4gwnyv.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;the code is like this&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;val map3: RDD[(String, List[Double])] = map2.map(x=&amp;amp;gt; (x._1, x._2.map( y=&amp;gt; (y - x._2.min) / (x._2.max.toDouble - x._2.min) )))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;now let’s create our map files as HTML pages with a table containing the heat map&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;   map3.collect().foreach(rdd=&amp;gt; {
      val tpl = html(rdd._1, rdd._2.mkString(&amp;quot;,&amp;quot;))
      new PrintWriter(outputDir + rdd._1 + &amp;quot;.html&amp;quot;) { write(tpl); close}
    })

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;the html() function used here is a string template that uses the values between 0 and 1 to create a HLS color for a 5 color heat map. check out the code in the repo – it’s too verbose to include it in this post.&lt;/p&gt;
&lt;p&gt;That’s about it on how to generate a chess board heat map. Here are the results for 1.5M games analyzed:&lt;/p&gt;
&lt;p&gt;&lt;a href="http://i.imgur.com/6hGU74G.png"&gt;http://i.imgur.com/6hGU74G.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://imgur.com/PbJC7Kx.png"&gt;http://imgur.com/PbJC7Kx.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://imgur.com/FHXDfVL.png"&gt;http://imgur.com/FHXDfVL.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://imgur.com/5I08pXS.png"&gt;http://imgur.com/5I08pXS.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://imgur.com/HaHDp9E.png"&gt;http://imgur.com/HaHDp9E.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://imgur.com/UvNxeq7.png"&gt;http://imgur.com/UvNxeq7.png&lt;/a&gt;&lt;/p&gt;
</content:encoded></item><item><title>MacBook Pro mouse lag</title><description>Mouse lag issues with an external monitor on macOS X</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Fri, 04 Sep 2015 00:00:00 GMT</pubDate><guid isPermaLink="true">macbook_pro_mouse_lag.html</guid><content:encoded>&lt;p&gt;Suddenly my macbook's mouse started lagging and jumping all over the screen. For a second I would see it where I expected it to be then when I moved the mouse (or trackpad) the cursor would teleport to some weird part of one my screens. This is really annoying and it actually hinders you from getting anything done on the computer. After some research on the apple forums I saw that people have been complaining about this for ages (since 2012). The problem only happens if you have an external monitor connected. And event then it doesn't happen all the time. I use a separate macbook at work connected to an external monitor and I have had no issues there but at home my mouse is erratic. I've read that people have found different solutions that make the problem go away, some of them even looked like superstitions like unplug the USB mouse, count to 10, switch of the left monitor, replug the mouse, switch the monitor back on and bam! it works no more lag. What worked for my was to change the monitor refresh rate from 60 to 60. Yes that's not a typo, there are 2 60's in the drop down.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;image missing&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;the second 60 is the charm. Computers are weird some times.&lt;/p&gt;
&lt;p&gt;update: This kept working until the monitors went to sleep for the night. In the morning the lag and jumping was back and changing the refresh rate didn’t fix things this time. I’ve tried lowering the resolution on the monitors and the jumping was gone.&lt;/p&gt;
&lt;p&gt;update 2: so after disconnecting and reconnecting the issue appeared again. So the ultimate cure is to change the resolution after connecting the monitors. And I thought linux had multi monitor issues!&lt;/p&gt;
</content:encoded></item><item><title>Positional chess</title><description>a computer analysis tool for chess games</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Mon, 10 Aug 2015 00:00:00 GMT</pubDate><guid isPermaLink="true">positional.html</guid><content:encoded>&lt;p&gt;Here is my new addition to the online chess tools I’m currently working on:
Positional – a web based chess position analysis tool. Here is a short screen cast showing what it does:&lt;/p&gt;
&lt;p&gt;&lt;a href="https://youtu.be/HTtWQqM533E"&gt;https://youtu.be/HTtWQqM533E&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;It’s meant to give an analysis of the position but you could also use it as to play agains the computer. It uses the Carballo java chess engine behind the scenes. The api that it uses to evaluate also supports stockfish by launching it as an external process and using UCI to speak with it but I find that using an embedded java engine is prettier although it cannot reach stockfishes strength it is still a pretty strong engine. I plan also to add my own engine once it’s finished.&lt;/p&gt;
&lt;p&gt;I’m not planning to make this available to the public because chess engines obviously require a lot of server resources and I don’t have them.&lt;/p&gt;
</content:encoded></item><item><title>Tactics chess</title><description>a chess puzzle generator and solver interface</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Sat, 01 Aug 2015 00:00:00 GMT</pubDate><guid isPermaLink="true">tactix.html</guid><content:encoded>&lt;p&gt;Tactics training is such an essential part of chess if you want to improve. So much so that I bought a premium chess.com subscription mainly for the unlimited tactics they give. But then I thought, why not do my own and have unlimited tactics to practice on? See that cluster from laptops a couple of posts ago? well that is the chess engine cluster that I’m using to generate tactics training puzzles such as this:&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/tactix1.png"&gt;/img/tactix1.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;white to play and get a good position with blacks king wondering around the board 😀&lt;/p&gt;
&lt;p&gt;So how are tactics like these generated? Find the positions for tactical opportunities is actually rather simple. You get some game PGN’s, and feed them into a chess engine like stockfish, and mark the position where the engine evaluation goes from a draw-ish position to a material advantage for one side. For example consider the board state&lt;/p&gt;
&lt;p&gt;&lt;code&gt;r1b1r3/1p1nqpkp/p3pnp1/3p2N1/3P3Q/2NBP3/PP3PPP/3R1RK1 b - - 13 15&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;the evaluation stock fish has given for this position is 34cp (0.34 pawns). But in the game black made the mistake of playing e5 which tilted the evaluation of the position to 338cp (3.38 pawns) in whites favour. This means that white has the opportunity to gain a substantial advantage with a certain move. That’s what’s asked of the player during the tactics training session, find this move and the sequence of moves that come after it to hold the advantage. And that’s the hard part. How do you know when to terminate the sequence of moves for the puzzle. If you just let the player play 1 move, you have no way of knowing if the player actually saw the correct sequence that leads to an advantageous position or if it was just a lucky guess. It’s not satisfying to the player just to play one move and not follow through.&lt;/p&gt;
&lt;p&gt;The chess engine evaluation line actually gives you the lines that it considers good, so that’s a big help. You just need to have the player play along these lines, but for how many moves? A tactical position may result in an advantage in 2 moves or 5 moves after a long combination. What I have found that works nicely are the following conditions for termination:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Go a maximum of 6 moves (12 plies) deep during searching. 6 moves deep is very challenging even for masters of the game.&lt;/li&gt;
&lt;li&gt;if the last move was not a capture&lt;/li&gt;
&lt;li&gt;if the last move was not a check&lt;/li&gt;
&lt;li&gt;if the last move was not a mate in X move&lt;/li&gt;
&lt;li&gt;if the opponent would pass, a capture would not be made&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Checking for these conditions after every candidate move leads to some pretty decent puzzles.&lt;/p&gt;
&lt;p&gt;Here is my poor-mans cluster that crunched all the games to generate the tactics&lt;/p&gt;
&lt;p&gt;&lt;a href="http://imgur.com/ZEySaMS.png"&gt;http://imgur.com/ZEySaMS.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Architecture
The tactix application consists of 3 main parts&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;domain models&lt;/li&gt;
&lt;li&gt;tactix finder&lt;/li&gt;
&lt;li&gt;tactix webapp&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The most interesting part is the tactix-finder module that actually implements most of what I was talking above. It is an Akka app (hence the cluster in the image above) that distributes calculation of tactics to different actors in the network. Here are a bunch of diagrams that explain how this is accomplished:&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/tactix3.png"&gt;/img/tactix3.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/tactix4.png"&gt;/img/tactix4.png&lt;/a&gt;&lt;/p&gt;
</content:encoded></item><item><title>A simple solution to the Monty Hall problem</title><description>No complex math solution to the Monty Hall problem.</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Thu, 16 Jul 2015 00:00:00 GMT</pubDate><guid isPermaLink="true">simple_solution_to_the_monty_hall_problem.html</guid><content:encoded>&lt;p&gt;The Monty Hall problem is an interesting probability question that people have a hard time understanding the solution. The problem is this: You are on a TV show and the there are 3 closed doors. Behind one of the doors is a brand new car, and behind the two other doors there is a goat. Obviously you want the car. So you make a choice. The door you chose remains closed but one of the other doors are opened and a goat is revealed (always). Now you are asked the following question: Would you like to change the door you selected, or stay with your initial selection? What should you do? does it even matter?&lt;/p&gt;
&lt;p&gt;I've asked this question to a few people and all of them thought that it didn't matter. I had a hard time explaining to them that it did, until I saw this table which explains it all so nicely&lt;/p&gt;
&lt;p&gt;In the table stay means choose door 1 and stay with your choice, change means choose 1 but change.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
  &lt;th&gt;door 1&lt;/th&gt;
  &lt;th&gt;door 2&lt;/th&gt;
  &lt;th&gt;door 3&lt;/th&gt;
  &lt;th&gt;stay&lt;/th&gt;
  &lt;th&gt;change&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
  &lt;td&gt;car&lt;/td&gt;
  &lt;td&gt;goat&lt;/td&gt;
  &lt;td&gt;goat&lt;/td&gt;
  &lt;td&gt;cat&lt;/td&gt;
  &lt;td&gt;goat&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;td&gt;goat&lt;/td&gt;
  &lt;td&gt;cat&lt;/td&gt;
  &lt;td&gt;goat&lt;/td&gt;
  &lt;td&gt;goat&lt;/td&gt;
  &lt;td&gt;car&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;td&gt;goat&lt;/td&gt;
  &lt;td&gt;goat&lt;/td&gt;
  &lt;td&gt;cat&lt;/td&gt;
  &lt;td&gt;goat&lt;/td&gt;
  &lt;td&gt;car&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;so you can see that unless you picked the car on your initial pick, you will get a goat 2/3 times if you don't change. The reason is that Monty always reveals the door with a goat behind it and of course never your selected door. Such a nice example of a table as a data visualization tool being useful.&lt;/p&gt;
</content:encoded></item><item><title>Moving code... yet again</title><description>Moving from a self hosted git to gitlab</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Tue, 14 Jul 2015 00:00:00 GMT</pubDate><guid isPermaLink="true">moving_code_yet_again.html</guid><content:encoded>&lt;p&gt;About a year ago I decided that I would run my own git server and host my pet projects. After all why the hell am I paying for a VPS with 2 gigs of RAM if I am not gonna be able to host my small git server? Well it turned out that 2 gigs of RAM isn’t a hell of a lot and my server is in constant swap-land which degrades performance a lot. So I’ve decided to move the stuff to gitlab. Why not github? because I like the idea of having private repositories in which I can host shitty projects that haven’t been shaped yet. So my gitlab profile is &lt;a href="http://gitlab.com/u/dendiz"&gt;here&lt;/a&gt; and I will be redirecting git.dendiz.com to this URL when I have the chance to do so. It was fun using the gogs project while it lasted and I’m sure they will add great features in the future (nice alliteration;) )&lt;/p&gt;
</content:encoded></item><item><title>Jenkins builds not terminating</title><description>How to fix Jenkins not terminating builds that have a shell script</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Mon, 13 Jul 2015 00:00:00 GMT</pubDate><guid isPermaLink="true">jenkins_build_not_terminating.html</guid><content:encoded>&lt;p&gt;I used a bunch of Jenkins jobs for deployments and triggering some scripts that run apache spark jobs. One issue I recently ran into was if you are running a program from within a shell script and that uses nohup and output redirection jenkins may not terminate the build, even though the shell scripts exits. The problematic script maybe something like this:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-bash"&gt;#!/bin/bash

PID_FILE=/home/user/pidfile.pid
if [ -a $PID_FILE ]; then
echo &amp;quot;killing $JOB job&amp;quot;
kill -9 `cat $PID_FILE`
rm $PID_FILE
sleep 5
fi

nohup java -jar -Dspring.profiles.active=prod myjar.jar 2&amp;gt;&amp;amp;1 &amp;gt; /dev/null &amp;amp;
echo $! &amp;gt; $PID_FILE
echo &amp;quot; &amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Simple enough, it just launches a java application in the background, but this build will never terminate. The reason took some time to track down, but it's because of the order of the redirection.
swap &lt;code&gt;2&amp;gt;&amp;amp;1&lt;/code&gt;  and &lt;code&gt;&amp;gt; /dev/null&lt;/code&gt;  and the build will terminate normally.&lt;/p&gt;
</content:encoded></item><item><title>Installing Automatic outside the USA</title><description>How to get the Automatic app working for Android outside the USA</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Sun, 31 May 2015 00:00:00 GMT</pubDate><guid isPermaLink="true">automatic_installation_outside_usa.html</guid><content:encoded>&lt;p&gt;automatic is a nice little gadget that will collect information about your car from the ODB port (available in almost all cars) and combine that with the GPS on the phone to give you a nice summary of your drives. This all sounded great and I ordered one immediately but there is one catch: Automatic only supports vehicles in the US. But this wasn't going to stop me from using it! Here are the step I took to get my automatic working.&lt;/p&gt;
&lt;h3&gt;App installation&lt;/h3&gt;
&lt;p&gt;First of all when I did a search for automatic in the google play store, I got back silly results. None of them were the automatic app I was looking for. So I found the exact play store link from their web site, and to my dismay the app could not be installed on devices outside of the US. So the first thing to do is to find the APK (the so called archive for and android app, like an exe for windows) for the android client. After a couple of hours searching I was able to find the 1.5 version of the client (35mb). I had no luck with the evozi tool, I'm uploading my version of the client for others to download it. Once you have to file, just copy it on to your device via a USB cable and run it from the device. Use the file manager to locate the file on your phone and just click it. This will install the automatic app.&lt;/p&gt;
&lt;p&gt;update: If you are an IOS user, you can download the app by switching the app store country/region to the US. You will need a US credit card or an iTunes gift card. If you have a friend from the US who trusts you enough you can also login with their account to download the app and then logout.&lt;/p&gt;
&lt;h3&gt;Dongle installation&lt;/h3&gt;
&lt;p&gt;I had no problems installing the dongle on my car. Just locate the ODB port and plugin the device in firmly. It will beep once it's in place and follow the on screen instructions on the phone. You need bluetooth and an internet connection. I had to restart the pairing process a few times because it would not discover the device. But I got it to work after a few tries. When the application is done pairing it will get the VIN from the dongle and will fail because your cars wasn't made/sold in the US, but the application will let you enter a VIN manually. I open a VIN generator and created a random VIN. You can find a VIN generator site here. Just generate a VIN until you get one starting with a 1 or an A. I got a 2011 Jeep Renegade for the VIN that was generated for me. After you input this VIN automatic will start logging your trips.&lt;/p&gt;
</content:encoded></item><item><title>Apache spark reduce function</title><description>The effect of having a non-commutative non-associative reduce function</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Tue, 26 May 2015 00:00:00 GMT</pubDate><guid isPermaLink="true">apache_spark_reduce_function.html</guid><content:encoded>&lt;p&gt;normally reducing a list in scala will work as expected and you will get a value depending on your operation that is predictable.
for example consider the following list&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-scala"&gt;val x = List(&amp;quot;a&amp;quot;, &amp;quot;b&amp;quot;, &amp;quot;c&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and the operation we reduce is&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-scala"&gt;x.reduce((x,y) =&amp;gt; x + y)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;the accumulator will be &amp;quot;a&amp;quot; and the current element will be &amp;quot;b&amp;quot;. After the first iteration the accumulator will be &amp;quot;ab&amp;quot; and the current element will be &amp;quot;c&amp;quot; and in the final iteration the accumulator will be &amp;quot;abc&amp;quot;. Just the result we expected. But if you were to do this operation on an apache spark RDD you will get a different result each execution. Sometimes you will get &amp;quot;abc&amp;quot;, other times &amp;quot;bca&amp;quot;. You could end up with all variations. So what's going on here, why is the spark result unpredictable. It due to the parallelism that spark provides. How the partitions are aggregated are not defined. So when using the apache spark reduce you have to pay attention that the reducing function is commutative and also associative. Since string concatination is not we get a different result after each run. But if we were to define are list as a list of integers and use the same reduce function we would get the expected result each time, because the order of the numbers added does not change the result.&lt;/p&gt;
</content:encoded></item><item><title>Anatomy of a chess engine</title><description>how a chess engine is structured</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Sat, 09 May 2015 00:00:00 GMT</pubDate><guid isPermaLink="true">anatomy-of-a-chess-engine.html</guid><content:encoded>&lt;p&gt;Let's check out the anatomy of a chess engine.&lt;/p&gt;
&lt;h1&gt;Board Representation&lt;/h1&gt;
&lt;p&gt;The first thing we will tackle in programming our chess engine is a representation of the board. We will use the technique called a 10×12 board with sentinel markers. In this method the 8×8 chess board is wrapper with an extra 2 rows at the top and bottom and extra rows on the right and left side as in the figure&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/10x12-board.png"&gt;/img/10x12-board.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The blue squares are the actual chess board and the orange squares the sentinel squares that will come in handy when we are generating moves. You can think of the board as a 2 dimensional array in java. The square with the number 21 is the A1 square and the square 98 is the H8 square of the chess board. We will place our chess pieces in the array locations in this array. So say for example if a white pawn was represented with the value 2 then&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Board[21] = 2&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;would mean that there is a white pawn on A1 (which is not a legal board state for chess – but just for the sake of an example bear with it)&lt;/p&gt;
&lt;p&gt;So let's dive right in and define a few classes that we will need to represent the board. First of some key squares that we will use throughout our engine go into a class&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public class Squares {
    public static final int A1 = 21;
    public static final int B1 = 22;
    public static final int C1 = 23;
    public static final int D1 = 24;
    public static final int E1 = 25;
    public static final int F1 = 26;
    public static final int G1 = 27;
    public static final int H1 = 28;

    public static final int A8 = 91;
    public static final int B8 = 92;
    public static final int C8 = 93;
    public static final int D8 = 94;
    public static final int E8 = 95;
    public static final int F8 = 96;
    public static final int G8 = 97;
    public static final int H8 = 98;
    public static final int NOSQ = 99;
    public static final int OFFBOARD = 100;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;now we will define some enumerations to make the code more programmer friendly so we don't see magic numbers everywhere&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public class Rank {
    public static final int RANK_1 = 0;
    public static final int RANK_2 = 1;
    public static final int RANK_3 = 2;
    public static final int RANK_4 = 3;
    public static final int RANK_5 = 4;
    public static final int RANK_6 = 5;
    public static final int RANK_7 = 6;
    public static final int RANK_8 = 7;
    public static final int RANK_NONE = 8;
}

public class File {

    public static final int FILE_A = 0;
    public static final int FILE_B = 1;
    public static final int FILE_C = 2;
    public static final int FILE_D = 3;
    public static final int FILE_E = 4;
    public static final int FILE_F = 5;
    public static final int FILE_G = 6;
    public static final int FILE_H = 7;
    public static final int FILE_NONE = 8;
}

public class File {

    public static final int FILE_A = 0;
    public static final int FILE_B = 1;
    public static final int FILE_C = 2;
    public static final int FILE_D = 3;
    public static final int FILE_E = 4;
    public static final int FILE_F = 5;
    public static final int FILE_G = 6;
    public static final int FILE_H = 7;
    public static final int FILE_NONE = 8;
}

public class Color {
    public static final int WHITE = 0;
    public static final int BLACK = 1;
    public static final int BOTH = 2;
}

public class Color {
    public static final int WHITE = 0;
    public static final int BLACK = 1;
    public static final int BOTH = 2;
}

public class Piece {
    public static final int EMPTY = 0;
    public static final int wP = 1;
    public static final int wN = 2;
    public static final int wB = 3;
    public static final int wR = 4;
    public static final int wQ = 5;
    public static final int wK = 6;
    public static final int bP = 7;
    public static final int bN = 8;
    public static final int bB = 9;
    public static final int bR = 10;
    public static final int bQ = 11;
    public static final int bK = 12;
}

public class Piece {
    public static final int EMPTY = 0;
    public static final int wP = 1;
    public static final int wN = 2;
    public static final int wB = 3;
    public static final int wR = 4;
    public static final int wQ = 5;
    public static final int wK = 6;
    public static final int bP = 7;
    public static final int bN = 8;
    public static final int bB = 9;
    public static final int bR = 10;
    public static final int bQ = 11;
    public static final int bK = 12;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ok these classes are pretty self-explanatory they are a bunch of definitions. Now for some real stuff&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public class Board {
    public static final int NUM_SQ = 120;
    int[] filesBoard = new int[NUM_SQ];
    int[] ranksBoard = new int[NUM_SQ];

    private static Board instance;

    private Board() {

        init();
    }

    public static Board getInstance() {
        if (instance == null) {
            instance = new Board();
        }
        return instance;
    }

    public static int fileRank2Square(int file, int rank) {
        return 21 + file + rank * 10;
    }

    public void init() {

        for (int i = 0; i &amp;lt; NUM_SQ; i++) { // part 1
            filesBoard[i] = Squares.OFFBOARD;
            ranksBoard[i] = Squares.OFFBOARD;
        }

        for (int file = File.FILE_A; file &amp;lt;= File.FILE_H ; file++) { // part 2
            for (int rank = Rank.RANK_1; rank &amp;lt;= Rank.RANK_8; rank++) {
                int sq = Board.fileRank2Square(file, rank);
                filesBoard[sq] = file;
                ranksBoard[sq] = rank;
            }
        }

    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So we have here a basic initialization of the board. We have 2 arrays here that need attention: filesBoard and  ranksBoard . These two arrays hold the values for ranks and files. So after initialized the files board will look like&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/10x12-fileboard.png"&gt;/img/10x12-fileboard.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;and the rank file board will look like&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/10x12-rankboard.png"&gt;/img/10x12-rankboard.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;We have also a method that will return the index of a square for the given file and rank. So now on to the initialization part. First off we go and set everything slot in both arrays to an off square value to initialize the sentinel squares. Then we loop from file A rank 1 to file H rank 8 basically iterating over all of the squares on the chess board and set the file and rank values appropriately. After this initialization code has run the state of the arrays will like the figures above.&lt;/p&gt;
&lt;p&gt;Now lets write a test to make sure that our code is working as expected&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@Test
    public void testFilesBoardInit() {
        Board b = Board.getInstance();
        assertTrue(b.ranksBoard[0] == Squares.OFFBOARD);
        assertTrue(b.ranksBoard[Squares.A1] == Rank.RANK_1);
        assertTrue(b.filesBoard[Squares.A1] == File.FILE_A);

        assertTrue(b.filesBoard[Squares.C8] == File.FILE_C);
        assertTrue(b.ranksBoard[Squares.C8] == Rank.RANK_8);
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;h1&gt;Board Flags&lt;/h1&gt;
&lt;p&gt;next some more variables in our board class to hold some board states.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;int[] pieces = new int[NUM_SQ];
    int side = Color.WHITE;
    int fiftyMoves = 0;
    int historyPly = 0;
    int ply = 0;
    int castlePerms = 0;

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;the pieces  array will hold the actual pieces as values that we defined in the Pieces class.&lt;/p&gt;
&lt;p&gt;the side  variable holds the current side to move, we just initialize it to white but later we may change it according to a given starting position.&lt;/p&gt;
&lt;p&gt;the fiftyMove  variable is used to determine a draw by fifty moves. This is a lesser known rule in chess so check out this wikipedia page if you don’t know the rule. This variable will get incremented for every move made, and will be reset if a pawn move or a capture happens. If the value every reaches 100 (that’s in half moves, so it’s 50 full moves) then either side is eligible to claim a draw.&lt;/p&gt;
&lt;p&gt;the historyPly  is the number of half-moves (a move by one side) since the beginning of the game. We will use this as an index for undoing moves later.&lt;/p&gt;
&lt;p&gt;the ply  variable is the number of moves in the search tree. Don’t worry about this – you will understand how it is used during the searching phase and move generation.&lt;/p&gt;
&lt;p&gt;the castlePerms  holds the castling permissions for both sides in an integer. The least significant bit represents white king side castling and the next white queen side castling and so on. So it takes 4 bits to represent all castling permissions. In the class CastleMask we define these bits. So to check if a white can castle king side all we need to do is bit wise and the castlePerms  variable with the corresponding value in CastleMask . Bit wise operations are a bit scary for most people so brush up on your bit wise operations by checking out this article.&lt;/p&gt;
&lt;p&gt;Here is the CastleMask class that we use to check the castling permissions&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public class CastleMask {
    int wk = 1;
    int wq = 2;
    int bk = 4;
    int bq = 8;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So for example if the castle permissions had a value of 3 which is 0011 in binary and we wanted to check if white can castle queen side we would do this operation castlePerm &amp;amp; CastleMask.wq  and check if the result of this operation is 0 or 1. If it is 1 then white can castle queen side. If you apply this operation 0011 and 0010 ( CastleMask.wq  is 2 which is this in binary) the result will be 1 so white can castle queen side.&lt;/p&gt;
&lt;h1&gt;Piece lists&lt;/h1&gt;
&lt;p&gt;When we want to generate moves for the pieces on the board the first approach that comes to mind is looping through all the squares on the board and checking if the current square has a piece of the correct color for the side to move and generating the moves for that piece. But by using some extra memory – only very little we can do a bit better. Instead of going through the squares we will track pieces and know on which square that piece is currently sitting. Before we implement this idea lets add a few convenience variable that we will use later on for look-ups. So in Piece.java we need the following&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    public int[] pieces = new int[]{EMPTY, wP, wN, wB, wR, wQ, wK, bP, bN, bB, bR, bQ, bK};
    public boolean[] pieceBig = new boolean[]{false, false, true, true, true, true, true, false, true, true, true, true, true};
    public boolean[] pieceMaj = new boolean[]{false, false, false, false, true, true, true, false, false, false, true, true, true};
    public boolean[] pieceMin = new boolean[]{false, false, true, true, false, false, false, false, true, true, false, false, false};
    public int[] pieceVal = new int[]{0, 100, 325, 325, 550, 1000, 50000, 100, 325, 325, 550, 1000, 50000};
    public int[] pieceCol = new int[]{Color.BOTH, Color.WHITE, Color.WHITE, Color.WHITE, Color.WHITE, Color.WHITE, 
        Color.WHITE,Color.BLACK, Color.BLACK, Color.BLACK, Color.BLACK, Color.BLACK, Color.BLACK};
    public boolean[] piecePawn = new boolean[]{false, true, false, false, false, false, false, true, false, false, false, false, false};
    public boolean[] pieceKnight = new boolean[]{false, false, true, false, false, false, false, false, true, false, false, false, false};
    public boolean[] pieceKing = new boolean[]{false, false, false, false, false, false, true, false, false, false, false, false, true};
    public boolean[] pieceRookQueen = new boolean[]{false, false, false, false, true, true, false, false, false, false, true, true, false};
    public boolean[] pieceBishopQueen = new boolean[]{false, false, false, true, false, true, false, false, false, true, false, true, false};
    public boolean[] pieceSlides = new boolean[]{false, false, false, true, true, true, false, false, false, true, true, true, false};

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;These are just some look-up tables and they are pretty simple but I’ll explain one just as an example. The pieceVal[]  array holds the values for each piece indexed by the piece index in the pieces[]  array. So the first element in the  pieces[]  array is EMPTY with an index of 0. The the element at pieceVal[0]  is also 0 because an empty piece does not have a value. The next element in the pieces[]  array at pieces[1]  is a white pawn. So the value in the pieceVal[1]  array is 100 signifying the value of a pawn etc. You get the basic idea behind this, feel free to leave a comment if anything is unclear.&lt;/p&gt;
&lt;p&gt;Now let’s get back to the piece lists. In Board.java we need the following arrays&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;int[] material = new int[2]; //WHITE,BLACK;
    int[] pceNum = new int[13];
    int[] pList = new int[130];
    int enPassantSquare = 0;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The material[]  array holds the total value of material present at the board indexed by color. So if the white side has a single pawn on the board material[0]  would 100. Simple enough.&lt;/p&gt;
&lt;p&gt;The pceNum[]  array holds the number of pieces of a certain type on the board. This is again using the Piece.pieces[]  as the index. So the index of a white pawn is 1 in the pieces array, so pceNum[1]  would be 5 if there were 5 white pawns on the board. The pList[] array holds the squares for each of the pieces on the board. There can be a maximum of 10 pieces of the same kind on the board at a given state. How is that possible you ask? This is an edge case but think about this scenario: I promote each of may eight pawns to rooks and I already have my two rooks so that makes a total of ten rooks for me. Taking this logic into account we set aside ten slots for each piece. So the following position&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/ah9syj4hw36s.png"&gt;/img/ah9syj4hw36s.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;would have pceNum[1]  = 8 and pList = [0,0,0,0,0,0,0,0,A2,B2,C2,...]  where A2 is the actual integer value of the board index. To get the square from the piece list all we have to do is multiply the piece integer representation by 10 and to get the beginning index in the pList[] array then we can get the next pceNum[piece integer value] elements. Let’s add that to the Board class&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  public static int pieceIndex(int piece, int pieceNum) {
        return piece * 10 + pieceNum;
    }

&lt;/code&gt;&lt;/pre&gt;
&lt;h1&gt;Position Hashing&lt;/h1&gt;
&lt;p&gt;In this part we will lay the foundation of our position hashing. Position hashing is mapping a unique value to each unique position on the board. What makes a position unique? It’s basically the pieces on the board, and which squares they are on. If we have two knights on the board we cannot call this unique because we haven’t stated the squares the knights are on. But if we say two knights on the board on squares A1 and A8 we can say this is a unique position. We also have to factor in the side to play, the castling statuses and any en passant squares (If you don’t know what en passant means, take a look here). We will use a method called zorbist hashing to achieve this. The essentials of the hashing algorithm are like this: First we generate a random number for pieces on the board and XOR this with the current key. Then we XOR the resulting value with the side to move and XOR the resulting key with the en passant square etc until we have used all our defining attributes. Let’s do an example to solidify. Say that we have 3 pieces p1, p2 and p3 and our key k.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;p1 = random();
p2 = random();
p3 = random();
k = 0;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;we initialized our pieces and our key. Next up XOR&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;k = k XOR p1
k = k XOR p2
k = k XOR p3
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;this will yield our final key for the position (we have discarded en passant and the other stuff for simplicity). The nice thing about this hashing is that if we want to take out p1 from the hash we don’t have to reconstruct the hash from the beginning for p2 and p3, we can just XOR p1 out of the hash like this&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;k = k XOR p1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and this would give the same result as doing&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;k = 0
k = k XOR p2
k = k XOR p3
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So here is our random number generator and our variable to hold the position key that goes into our Board class&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public static int random() {
        return ((int)Math.floor((Math.random()*255)+1) &amp;lt;&amp;lt; 23) | ((int)Math.floor((Math.random()*255)+1) &amp;lt;&amp;lt; 16)
                | ( (int) Math.floor((Math.random()*255)+1) &amp;lt;&amp;lt; 8) | (int) Math.floor((Math.random()*255)+1);

    }
    int posKey = 0;

&lt;/code&gt;&lt;/pre&gt;
&lt;h1&gt;Position hashing and key generation&lt;/h1&gt;
&lt;p&gt;In this part we will incorporate the hashing into our engine. We will introduce a new class called Hash that will take care of all hashing related functions. We will need to initialize a table for each piece and square combination, a hashing key for side to move and for the castling permissions. Here is the definition part in code&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public  int[] pieceKeys = new int[13 * 120];
    public  int sideKey;
    public  int[] castleKey = new int[16];
    public static Hash instance;

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The reason we are using 13 x 120 is that our board has sentinel squares around it and it’s a total of 120 squares for 13 piece types. The castling permissions is a 4 bit number which is 16 in decimal so we use an array of length 16. We will be applying the singleton pattern that is why we defined an instance variable. Now let’s initialize these tables with some values&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;private Hash() {}
    public static Hash getInstance() {
        if (instance == null) {
            instance = new Hash();
        }
        return instance;
    }

    public void initHashKeys() {
        for (int i = 0; i &amp;lt; 13 * 120; i++) {
            pieceKeys[i] = Board.random();
        }
        sideKey = Board.random();
        for (int i = 0; i &amp;lt; 16; i++) {
            castleKey[i] = Board.random();
        }
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is fairly simple, we just put a random number for every slot in all the arrays. Moving on to the actual key generation:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public int generatePosKey() {
        int finalKey = 0;
        for (int sq = 0; sq &amp;lt; Board.NUM_SQ; sq++) {
            int piece = Board.getInstance().pieces[sq];
            if (piece != Piece.EMPTY &amp;amp;&amp;amp; piece != Squares.OFFBOARD) {
                finalKey ^= pieceKeys[(piece * 120) + sq];
            }
        }
        if (Board.getInstance().side == Color.WHITE) {
            finalKey ^= sideKey;
        }

        if (Board.getInstance().enPassantSquare != Squares.NOSQ) {
            finalKey ^= pieceKeys[Board.getInstance().enPassantSquare];
        }
        finalKey ^= castleKey[Board.getInstance().castlePerms];
        return finalKey;
    }

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ok, here we iterate through all of the squares on the board (including the sentinels) and if there is a piece on that square and it is not a sentinel square we get the corresponding random number from our previously generated pieceKeys[]  array and XOR it with the hash key. Remember we laid our our pieceKeys[]  array by piece type and 120 slots for each piece type. So we can access it by multiplying the piece integer value with 120 and adding the square. We incorporate the side to move into the key if it’s white or skip it for black. If the en passant square is set we also XOR that into our key. We could have also accessed the pieceKeys[]  like this for en passant pieceKeys[Piece.EMPTY * 120 + sq]  but Piece.EMTPY is zero so we can leave it out.&lt;/p&gt;
&lt;p&gt;We can also add some tests to verify that our initialization and generation are working as expected&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@Test
    public void shouldInitHashKeys() {
        Hash.getInstance().initHashKeys();
        for (int i = 0; i &amp;lt; 13 * 120; i++) {
            int pieceKey = Hash.getInstance().pieceKeys[i];
            assertTrue(pieceKey != 0);
        }
        assertTrue(Hash.getInstance().sideKey != 0);
        for (int i = 0; i &amp;lt; 16; i++) {
            assertTrue(Hash.getInstance().castleKey[i] != 0);
        }
    }

    @Test
    public void shouldGeneratePosKey() {
        Board.getInstance().pieces[21] = Piece.wP;
        Hash.getInstance().initHashKeys();
        int key = Hash.getInstance().generatePosKey();
        assertTrue(key != 0);
    }

&lt;/code&gt;&lt;/pre&gt;
</content:encoded></item><item><title>Groovy templates variable passing</title><description>a tip on passing variables to groovy templates</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Fri, 08 May 2015 00:00:00 GMT</pubDate><guid isPermaLink="true">groovy-templates-variable-passing.html</guid><content:encoded>&lt;p&gt;Groovy Templates is one of the new cool kids on the block. It enables you to ditch the stinky old templates like FreeMarker or Velocity and use groovy to write your templates, which basically means no more eyes bleeding from angled brackets and HTML syntax. You can check it out here. One of the issues that I was facing with the templates was trying to pass a variable in the groovy context to an included template. Let me give an example to make it clear&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;modelAndView.addObject(&amp;quot;myvar&amp;quot;, 5)
...


main.tpl:

div {
 include template 'included.tpl'
}


included.tpl:
 yield myvar

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You add a variable to your model and have it rendered from the included template. The result is as expected this&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;div&amp;gt;myvar&amp;lt;/div&amp;gt;

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But let’s say that myvar was a list of items that you wanted to iterate. Then the template code will be something like&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;main.tpl:

div {
 myvars.each { myvar -&amp;gt;
   include template 'included.tpl'
 }
}


included.tpl:
 yield myvar

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now you would expect it to render the contents of “myvar” in the included template but this will not happen. Instead you will get an error saying myvar is null. There is a kind of hack that I came up with to make this work and it’s to use the fragment directive. So the template becomes something like this&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;div {
 myvars.each { myvar -&amp;gt;
   fragment &amp;quot;include template: 'included.tpl'&amp;quot;, myvar:myvar
 }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;this passes the variable to the included template model context.&lt;/p&gt;
</content:encoded></item><item><title>Lenovo Yoga 2 Pro Bluetooth mouse disconnection issue</title><description>How to fix the buggy Windows 8 bluetooth drivers causing the mouse to disconnect</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Mon, 30 Mar 2015 00:00:00 GMT</pubDate><guid isPermaLink="true">lenovo_yoga_mouse_disconnection.html</guid><content:encoded>&lt;p&gt;I just got a Microsoft Comfort Sculpt Bluetooth mouse, to free up the USB ports on my Lenovo Yoga 2 pro laptop, but I soon faced the problem that many other users were facing&lt;/p&gt;
&lt;p&gt;mouse freezes suddenly
mouse disconnects
Doing some research quickly revealed quite a bit of people were facing the same issues with this product. The problem is with the windows 8.1 bluetooth drivers. The solution is simple uninstall the current drivers.&lt;/p&gt;
&lt;p&gt;Important! Before you proceed make sure your D drive contains the lenovo provided restore utilities including the blue tooth drivers. If you do not have these or are unsure do not proceed!&lt;/p&gt;
&lt;p&gt;Press CTRL + X and select device manager from the popup on the bottom right.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;image lost&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;right click on the highlighted item and click uninstall. Select delete drivers check box and remove the driver. Now go to &lt;code&gt;d:\Drivers\Bluetooth\Win7\vs64\&lt;/code&gt;  and right click the Setup.exe file. Choose properties and select the compatibility tab. Select windows 7 compatibility mode as shown in the screen shot.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;image lost&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Now run the &lt;code&gt;setup.exe&lt;/code&gt; program and install the driver. The windows 7 drivers will work correctly and the disconnection issues will disappear.&lt;/p&gt;
&lt;p&gt;Now open the device manager again and right click on Bluetooth driver in the first image and select properties to open the following dialog&lt;/p&gt;
&lt;p&gt;&lt;em&gt;image lost&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;and uncheck the power save option. This will stop the mouse from freezing and will make it responsive.&lt;/p&gt;
</content:encoded></item><item><title>Spring content negotiating view resolver</title><description>how to setup a content negotiating view for spring</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Fri, 13 Mar 2015 00:00:00 GMT</pubDate><guid isPermaLink="true">spring-content-negotiating-view-resolver.html</guid><content:encoded>&lt;p&gt;Returning HTML or JSON data from the same controller is a valuable thing to have. Code once, use for HTML interfaces or API interfaces. 
How does it work? Like this:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;curl http://localhost/data.json&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;retruns&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{
 data:[1,2,3]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and a request to the same url without the extionsion &lt;code&gt;curl http://localhost/data&lt;/code&gt; returns&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;html&amp;gt;
..
data 1,2,3
&amp;lt;/html&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and the code for the controller is the same, maybe something like&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public String controller(Map&amp;lt;String,Object&amp;gt; model) {
 model.put(&amp;quot;data&amp;quot;, Arrays.asList(1,2,3));
 return &amp;quot;viewname&amp;quot;;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Spring will automatically detect the extension and return the correct view. Here is the configuration:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@Configuration
public class WebConfigurationAdapter extends WebMvcConfigurerAdapter {

    @Override
    public void configureContentNegotiation(ContentNegotiationConfigurer configurer) {
        configurer.favorPathExtension(true)
                .defaultContentType(MediaType.TEXT_HTML)
                .ignoreAcceptHeader(true)
                .mediaType(&amp;quot;html&amp;quot;, MediaType.TEXT_HTML)
                .mediaType(&amp;quot;json&amp;quot;, MediaType.APPLICATION_JSON);
        super.configureContentNegotiation(configurer);
    }

    @Override
    public void configureViewResolvers(ViewResolverRegistry registry) {
        MappingJackson2JsonView jsonView = new MappingJackson2JsonView();
        jsonView.setPrettyPrint(true);
        registry.freeMarker();
        registry.enableContentNegotiation(jsonView);
        super.configureViewResolvers(registry);
    }
}

&lt;/code&gt;&lt;/pre&gt;
</content:encoded></item><item><title>h3 chess</title><description>a chess opening explorer</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Sun, 01 Feb 2015 00:00:00 GMT</pubDate><guid isPermaLink="true">h3.html</guid><content:encoded>&lt;p&gt;chess is an incredibly fascinating game. I’ve been playing and more and more over the past 18 months and I’ve grown to appreciate the vastness and complexity of the game. I’ve previously written about the anatomy of a chess engine, and I am working on a java chess engine but I decided to squeeze another chess project in between. This one is a chess game explorer and opening explorer. The opening explorer allows you to visit different chess openings played in games and enrich your repertoire. The game explorer provides you with option of examining master level games collected from the FICS servers. My goal is to put online 2 million games with the most popular moves played from a given position for the opening explorer and engine analysis support for all the games in the game explorer and have this running on a server with only 2G of RAM that will host the application and the data base. I guess this will be the most challenging part of this project. Here is a screenshot of the current state of the application (very unfinished i must say):&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/57edee11b8363.png"&gt;/img/57edee11b8363.png&lt;/a&gt;&lt;/p&gt;
</content:encoded></item><item><title>Spring controller parameter injection</title><description>how to inject custom parameters to spring controllers</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Thu, 01 Jan 2015 00:00:00 GMT</pubDate><guid isPermaLink="true">spring-controller-parameter-injection.html</guid><content:encoded>&lt;p&gt;For most applications that have some sort of login feature, you need the logged in user in your controllers or else where. If you are using an authorization/authentication framework they probably provide a nice way of doing this. If you are managing your sessions with spring there are probably different ways of doing this but for the sake of an example this is the scenario I'm going with. I want to pass the current user as a parameter to a controller method and have it populated with the current user by spring. This is done with a component that implement &lt;code&gt;HandlerMethodArgumentResolver&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@Component
public class CurrentPlayerParameterResolver implements HandlerMethodArgumentResolver {
    @Resource
    PlayerSessionRepository playerSessionRepository;
    @Override
    public boolean supportsParameter(MethodParameter parameter) {
        return parameter.getParameterType().equals(Player.class);
    }

    @Override
    public Object resolveArgument(MethodParameter parameter, ModelAndViewContainer mavContainer, NativeWebRequest webRequest, WebDataBinderFactory binderFactory) throws Exception {
        HttpServletRequest req = webRequest.getNativeRequest(HttpServletRequest.class);
        Cookie[] cookies = req.getCookies();
        if(cookies == null) return null;
        for (Cookie cookie : cookies) {
            if (cookie.getName().equals(Const.COOKIE_SID)) {
                return playerSessionRepository.findBySessionId(cookie.getValue());
            }
        }
        return null;
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;install the resolver&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@Configuration
public class WebConfigurationAdapter extends WebMvcConfigurerAdapter {
    @Resource
    CurrentPlayerParameterResolver currentPlayerParameterResolver;

    @Override
    public void addArgumentResolvers(List&amp;lt;HandlerMethodArgumentResolver&amp;gt; argumentResolvers) {
        argumentResolvers.add(currentPlayerParameterResolver);
        super.addArgumentResolvers(argumentResolvers);
    }

}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and use it in your controllers&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@GetMapping(value = &amp;quot;/galaxies&amp;quot;)
public String galaxy(Map&amp;lt;String,Object&amp;gt; model, Player currentPlayer) {
//currentPlayer is populated
...
}
&lt;/code&gt;&lt;/pre&gt;
</content:encoded></item><item><title>Creating a Windows 7 bootable USB in Ubuntu 14.10</title><description>A series of bash commands to get the job done</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Sun, 09 Nov 2014 00:00:00 GMT</pubDate><guid isPermaLink="true">win7_bootable_usb_in_ubuntu14.html</guid><content:encoded>&lt;p&gt;Apparently the new versions of unetbootin fail on creating a bootable Windows 7 USB so some extra actions have to be taken with Ubuntu 14.10.
First make sure that your USB is formatted as NTFS. To do this you can start gparted and it should list the file system type as NTFS. If not just re-format the USB stick to NTFS. Make sure the partition has the boot flag on. If not just right click and choose manage flags and and the boot flag. Now copy over the files from your Windows 7 ISO over the USB stick. You can do this by mounting the ISO file in Linux using the command&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-bash"&gt;mount -t  loop isofile /mnt
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;now you can just copy all the files in the /mnt directory to the USB drive. Now it’s time to install grub on the USB drive so that it can boot into Windows  7 installation.
Launch gparted again and choose your USB from the devices drop down on the left. Now right click on the partition and choose information. In the dialog that opens there is a field called UUID make note of this field on a piece of paper as we will need it during the boot.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-bash"&gt;sudo grub-install --target=i386-pc --boot-directory=&amp;quot;/mnt/boot&amp;quot; /dev/sdX
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;where sdX  is the device for your USB.&lt;/p&gt;
&lt;p&gt;All is set, reboot from the USB stick and you should be in the grub bootloader screen. Now type these commands:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-bash"&gt;insmod ntfs
search --fs-uuid --set root
chainloader +1 
boot
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and your Windows installation should start.&lt;/p&gt;
</content:encoded></item><item><title>Grails exception mapping with http status codes</title><description>A clean way to map exceptions to http return codes</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Wed, 22 Oct 2014 00:00:00 GMT</pubDate><guid isPermaLink="true">grails_exception_http_status_mapping.html</guid><content:encoded>&lt;p&gt;an integral part of an API is returning meaningful response codes on errors. If the client is trying to access a restricted resource without authentication the correct code to return would be http 403 etc. Doing this in grails without going through the hassle of try/catching every exception by hand and sending the appropriate code is by using exception mapping feature in grails.&lt;/p&gt;
&lt;p&gt;In the &lt;code&gt;UrlMappings&lt;/code&gt; class just register the following&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-groovy"&gt;static mappings = {
&amp;quot;/$controller/$action?/$id?(.$format)?&amp;quot;{
   constraints {
       // apply constraints here
   }
}

&amp;quot;/&amp;quot;(view:&amp;quot;/index&amp;quot;)
&amp;quot;500&amp;quot;(controller:'error'),
&amp;quot;500&amp;quot;(controller: 'error', action: 'error403', exception: AuthenticationException)

}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;this tells grails to forward any http 500 error, which are exceptions that you can throw in your code, to the controller and action you define.
For this example we need to define an &lt;code&gt;ErrorController&lt;/code&gt; with the action index and &lt;code&gt;error403&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-groovy"&gt;class ErrorController {
   def index() {
       response.status = 500
       render([status: &amp;quot;error&amp;quot;, message: &amp;quot;an internal server error occured&amp;quot;])
   }

   def error403() {
       try {
       def message = request.exception?.cause?.message ?: &amp;quot;authentication error&amp;quot;
       response.status = 403
       render([&amp;quot;status&amp;quot;: &amp;quot;error&amp;quot;,&amp;quot;message&amp;quot;: message] as JSON)
       } catch(ex) {
       }
   }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;the thing to note here is that&lt;/p&gt;
&lt;p&gt;the exceptions that you throw in your code should extend &lt;code&gt;RuntimeException&lt;/code&gt;
Even though we catch the exception as a 500 response code in the mappings file, we can override the http response code in the error controller.
you can get the root cause from the request.exception object, which is handy.
it's a good idea to surround the exception handling code in the actions, otherwise if you get an exception in the exception handling code you will find yourself in an infinite loop, and eventually a stack overflow.&lt;/p&gt;
</content:encoded></item><item><title>Groovy - picking keys from a map based on a list</title><description>neat little groovy trick to collect some values from a map</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Tue, 21 Oct 2014 00:00:00 GMT</pubDate><guid isPermaLink="true">groovy_pick_keys_from_map.html</guid><content:encoded>&lt;p&gt;one of the most common things you do when programming is transforming one representation of data to another.
here is a very common example:
say you have a map, say a result of a database query&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-groovy"&gt;def src = [id:1, name:'john', surname:'doe', password:'password', ccNumber1:'12312321']
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and you wish to transform this into another map, but exclude some of the keys, and rename others.
A naive approach with tons of bloat is this&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-groovy"&gt;def result = [id: src.id, name:src.name, surname:src.surname, creditcard: src.ccNumber1]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;for a few attributes, this looks ok, but if you have a lot it looks quite bad. Fortunately groovy
provides a very elegant method to convert in this situation. Here are 2 examples, first one if you
just want to pick keys, and the second one if you also want to rename the keys:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-groovy"&gt;def keys = ['id', 'name', 'surname']
keys.inject([:]) { acc,it -&amp;amp;gt; acc + [ (it) : report[it] ] }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-groovy"&gt;def keys = [id: 'id', ccNumber1: 'creditcard']
keys.inject([:]) {acc,it-&amp;amp;gt; return acc + [ (it.value) : report[it.key] ] }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;whats going on here is that we are starting off with an empty map, and iterating the keys
map/array. For every iteration we add the map to the accumulated map and move on.&lt;/p&gt;
</content:encoded></item><item><title>Image hoster</title><description>A simple go app to host images</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Mon, 20 Oct 2014 00:00:00 GMT</pubDate><guid isPermaLink="true">image_hoster.html</guid><content:encoded>&lt;p&gt;one of the things I've been missing since I switched to a static site generator for hosting these page is the ability to upload images that wordpress or other publishing platforms offer by default.
I've tried several ways of overcoming this. I've uploaded files via FTP, which is very cumbersome. You have to launch an ftp client, find the directory you want to copy the files to, launch a browser to that directory and have apache list the files there, CTRL+F and search for the file, copy the link address and finally paste it back to the markdown document, only to see that the image is way too big for the post. Now you have to resize the damn image and do that stuff all over again. I’d rather not upload an image at all! An easier way was just copying the file to my Dropbox folder. But you still have to go to the dropbox web site to get a public link and the sizing issues are still there. So I thought that I’d address this issue of having problems hosting images. This also gave me a nice opportunity to test out go lang and martini. To my surprise go was a very pleasant language to work with and martini is just the right micro framework to build a go web application with. So imagehoster was born. You can check it out at my repository. The process is much more simple now&lt;/p&gt;
&lt;p&gt;go to the imagehoster web app
drag and drop, or choose the image file to upload
copy the returned link to the clip board and paste it into the document
adjust the size of the image via appending the needed size at the end of the url
Here are a few images dynamically sized&lt;/p&gt;
&lt;p&gt;&lt;a href="attachment:18.jpeg"&gt;18.jpeg&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="attachment:200.jpeg"&gt;200.jpeg&lt;/a&gt;
&lt;a href="attachment:100.jpeg"&gt;100.jpeg&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
&lt;/code&gt;&lt;/pre&gt;
</content:encoded></item><item><title>Build order in a parallel maven build</title><description>Figuring out how to get the dependencies in order for a Grails app and a multi module maven project</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Sun, 19 Oct 2014 00:00:00 GMT</pubDate><guid isPermaLink="true">maven_parallel_build_order.html</guid><content:encoded>&lt;p&gt;After completing the development of a grails application for a client, they asked me to integrate the grails app with the current build-test-deploy cycle which is using maven. The grails application depends on a few artifacts from the java project. Grails does have maven support, but you will run into all sorts of classpath problems when you try to integrate with a multi-module complicated parent project. So the solution was to execute the grails build after the parent project was done. The problem is that the parent project artifacts were not being published to a maven repository and the grails app needs to find the artifacts in the local repository before it can do anything. For a multi-module maven project, it is not a problem for the individual modules as they recognize each other as dependencies but the grails project is not a module of this parent project. So the initial solution was to create a pom for the grails project with the exec-maven-plugin running grailsw test-app -unit after the install phase. The relevant pom part looks like this&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-xml"&gt;&amp;lt;plugin&amp;gt;
    &amp;lt;groupId&amp;gt;org.codehaus.mojo&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;exec-maven-plugin&amp;lt;/artifactId&amp;gt;
    &amp;lt;version&amp;gt;1.2.1&amp;lt;/version&amp;gt;
    &amp;lt;executions&amp;gt;
        &amp;lt;execution&amp;gt;
            &amp;lt;phase&amp;gt;install&amp;lt;/phase&amp;gt;
            &amp;lt;goals&amp;gt;
                &amp;lt;goal&amp;gt;exec&amp;lt;/goal&amp;gt;
            &amp;lt;/goals&amp;gt;
        &amp;lt;/execution&amp;gt;
    &amp;lt;/executions&amp;gt;
    &amp;lt;configuration&amp;gt;
        &amp;lt;executable&amp;gt;./build.sh&amp;lt;/executable&amp;gt;
        &amp;lt;workingDirectory&amp;gt;.&amp;lt;/workingDirectory&amp;gt;
        &amp;lt;skip&amp;gt;false&amp;lt;/skip&amp;gt;
        &amp;lt;arguments&amp;gt;
            &amp;lt;argument&amp;gt;-e&amp;lt;/argument&amp;gt;
        &amp;lt;/arguments&amp;gt;
    &amp;lt;/configuration&amp;gt;
&amp;lt;/plugin&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Add this to the parent pom as a module, and you are set to go, except that you are not. If the builds run sequentially all is fine, because the dependencies all get installed and the grails app is the last module to run and grails can locate the artifacts in the local repository. But this is a relatively large code base and running parallel builds really cuts down the build time. The trick to solve this problem is to go back to the roots of maven: Maven is a dependency management application, and it will make sure that if a build depends on A, A will be present to continue. So adding the artifacts as dependencies to the pom makes sure that they are present in the local repository even when doing parallel builds. Using this you can actually serialize a parallel build, making sure that the required artifacts for a module that is not built with maven are present. The downside is that you have to add the dependencies to both &lt;code&gt;BuildConfig.groovy&lt;/code&gt; and the &lt;code&gt;pom.xml&lt;/code&gt;&lt;/p&gt;
</content:encoded></item><item><title>Spark Java File uploads</title><description>how to upload files using the java spark micro framework</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Sat, 18 Oct 2014 00:00:00 GMT</pubDate><guid isPermaLink="true">spark-java-file-upload.html</guid><content:encoded>&lt;p&gt;spark java is a micro framework inspired by sinatra for java. It’s a really cool substitute for spring mvc which is a drag to because it takes so much time to boot the framework. 
I’ve been giving spark a go on a few projects (see: pads ) and I am quite pleased with the results. The new version also supports java 8 and has a lot of improvements over the 1.1.1 version. 
A problem that I came across using spark was during file uploads. Spark uses an embedded jetty server and the servlet 3.0 spec which requires @MultipartConfig on servlets that handle file uploads. Since spark is using handlers and you dreally don’t want to configure servlets and a web.xml fileuploading needs a work around which is rather simple. On the handler that is going to process the file upload just add these lines:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public Object handle(Request request, Response response) {
   MultipartConfigElement multipartConfigElement = new MultipartConfigElement(&amp;quot;/tmp&amp;quot;);
   request.raw().setAttribute(&amp;quot;org.eclipse.multipartConfig&amp;quot;, multipartConfigElement);
   ....
   Part file = request.raw().getPart(&amp;quot;file&amp;quot;); //file is name of the upload form

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;the parameter to MultiparConfig is the location for the temporary uploaded file.&lt;/p&gt;
</content:encoded></item><item><title>Ubuntu power saving on Asus Zenbook prime UX31A</title><description>making the Asus Zenbook work longer on Ubuntu</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Fri, 17 Oct 2014 00:00:00 GMT</pubDate><guid isPermaLink="true">asus_zenbook_power_saving_ubuntu.html</guid><content:encoded>&lt;p&gt;my primary laptop has been running a flavor of windows for the last couple of months and I was getting really good battery juice (upto 6 hours). I decided to install the lastest ubuntu gnome 14.04 to checkout what the gnome guys were doing mainly, and because I missed the native bash stuff. But to my surprise the battery / power saving out of the box is terrible. I got a measly 2.5~3 hours with the default settings. So to enable longer battery life you need to do these:&lt;/p&gt;
&lt;h3&gt;enable ASPM during boot&lt;/h3&gt;
&lt;p&gt;This will stop the machine from electrically communicting with the PCI-E slots and save some watts. You need to edit /etc/default/grub and replace the line with the following&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;GRUB_CMDLINE_LINUX_DEFAULT=&amp;quot;quiet splash pcie_aspm=force drm.vblankoffdelay=1 i915.semaphores=1&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;enable ALPM&lt;/h3&gt;
&lt;p&gt;This mod enables the kernel AHCI controller to put the SATA link into a sleepy state when there is no communication. This will shave off a couple of watts from your power consumption as weel&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo apt-get install pm-utils
echo SATA_ALPM_ENABLE=true | sudo tee /etc/pm/config.d/sata_alpm
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here are some results for before and after these tweaks
Running for 300 seconds (30 samples at 10 second intervals).
ACPI battery power measurements will start in 180 seconds time&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  Time    User  Nice   Sys  Idle    IO  Run Ctxt/s  IRQ/s Fork Exec Exit  Watts
22:07:13   0.4   0.0   0.4  98.7   0.6    2    356    211    0    0    0  14.54
22:07:23   0.2   0.0   0.3  99.0   0.6    1    277    184    0    0    0  12.95
22:07:33   1.6   0.0   0.6  96.7   1.1    1    991    319    0    0    0  13.10
22:07:43   0.2   0.0   0.3  98.9   0.6    1    291    190    0    0    1  12.96
22:07:53   1.1   0.0   0.5  97.4   1.1    1    515    247    1    0    0  13.24
22:08:03   1.5   0.0   0.6  96.9   1.1    1    954    319    1    0    1  12.95
-------- ----- ----- ----- ----- ----- ---- ------ ------ ---- ---- ---- ------
 Average   0.8   0.0   0.4  98.0   0.8  1.2  564.1  244.9  0.3  0.0  0.3  13.29
  StdDev   0.6   0.0   0.1   1.0   0.3  0.4  299.1   56.2  0.5  0.0  0.5   0.57
-------- ----- ----- ----- ----- ----- ---- ------ ------ ---- ---- ---- ------
 Minimum   0.2   0.0   0.3  96.7   0.6  1.0  276.7  184.2  0.0  0.0  0.0  12.95
 Maximum   1.6   0.0   0.6  99.0   1.1  2.0  991.3  319.1  1.0  0.0  1.0  14.54
-------- ----- ----- ----- ----- ----- ---- ------ ------ ---- ---- ---- ------
Summary:
 13.29 Watts on Average with Standard Deviation 0.57  




Running for 300 seconds (30 samples at 10 second intervals).
ACPI battery power measurements will start in 180 seconds time

  Time    User  Nice   Sys  Idle    IO  Run Ctxt/s  IRQ/s Fork Exec Exit  Watts
22:13:03   0.7   0.0   0.5  98.2   0.6    1    526    236    2    0    1  10.65
22:13:13   0.5   0.0   0.3  98.5   0.6    1    336    202    1    0    0   9.31
22:13:23   1.7   0.0   0.6  96.7   1.1    2    976    321    1    0    0   9.36
22:13:33   0.6   0.0   0.4  98.3   0.7    1    604    249    0    0    2   8.99
22:13:43   2.1   0.0   0.7  95.9   1.3    1   1171    359    0    0    0   9.10
22:13:53   1.0   0.0   0.8  97.6   0.7    1    950    341    0    0    0   9.37
22:14:03   1.7   0.0   0.6  96.9   0.8    1    677    287    0    0    0  10.22
22:14:13   1.5   0.0   0.5  97.1   0.9    1    924    304    0    0    0   9.00
-------- ----- ----- ----- ----- ----- ---- ------ ------ ---- ---- ---- ------
 Average   1.2   0.0   0.5  97.4   0.8  1.1  770.5  287.3  0.5  0.0  0.4   9.50
  StdDev   0.6   0.0   0.1   0.9   0.2  0.3  260.6   50.9  0.7  0.0  0.7   0.57
-------- ----- ----- ----- ----- ----- ---- ------ ------ ---- ---- ---- ------
 Minimum   0.5   0.0   0.3  95.9   0.6  1.0  336.0  202.5  0.0  0.0  0.0   8.99
 Maximum   2.1   0.0   0.8  98.5   1.3  2.0 1171.2  358.7  2.0  0.0  2.0  10.65
-------- ----- ----- ----- ----- ----- ---- ------ ------ ---- ---- ---- ------
Summary:
  9.50 Watts on Average with Standard Deviation 0.57
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;
&lt;/code&gt;&lt;/pre&gt;
</content:encoded></item><item><title>Sitemap generation with Spring</title><description>Generating an sitemap.xml file for your spring app.</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Tue, 07 Oct 2014 00:00:00 GMT</pubDate><guid isPermaLink="true">sitemap_generation_spring.html</guid><content:encoded>&lt;p&gt;The &lt;code&gt;sitemap.xml&lt;/code&gt; file defines all the url that a search engine should crawl on your site and is vital to SEO. After some research on how people did this using Spring mvc, I was quite baffled to see that no one actually used freemarker (or any other template engine) to achieve this and chose the path of cumbersome path of XML marshaling and programming. So I thought I'd write a short tutorial on how to accomplish this task really fast and clean. I'm going to assume that you have spring mvc and freemarker already configured and running, if you don't there are plenty of resources showing how to do that so just go ahead and use them, there is no need to repeat that stuff here. I'll also assume that your freemarker configuration bean &lt;code&gt;org.springframework.web.servlet.view.freemarker.FreeMarkerConfigurer&lt;/code&gt; is called &lt;code&gt;freemarkerConfig&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;So what we need to do is this&lt;/p&gt;
&lt;p&gt;in your controller create a request mapping that maps to &lt;code&gt;/sitemap.xml&lt;/code&gt; and produces xml
in this controller get all the urls that you’ll be using and put them in a model
get the &lt;code&gt;sitemap.xml&lt;/code&gt; template from freemarker and interpolate this template with the above model.
simple. Here's the code to accomplish this:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-java"&gt;@Controller
  public class Controller {
    @Resource
    private FreeMarkerConfigurer freemarkerConfigurer;
    @RequestMapping(value = &amp;quot;/sitemap.xml&amp;quot;, produces=&amp;quot;application/xml&amp;quot;)
    @ResponseBody
    public String sitemap() {
       Template template = freemarkerConfigurer.getConfiguration().getTemplate(&amp;quot;sitemap.ftl&amp;quot;);
       Map&amp;amp;lt;String, Object&amp;amp;gt; model = new HashMap&amp;amp;lt;String, Object&amp;amp;gt;();
       List&amp;amp;lt;Product&amp;amp;gt; products = productService.findAll();
       model.put(&amp;quot;products&amp;quot;, products);
       String rendered = FreeMarkerTemplateUtils.processTemplateIntoString(template, model);
       return rendered;
   }
 }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and the template should look something like this&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  [#ftl]
   &amp;lt;?xml version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;UTF-8&amp;quot;?&amp;gt;
   &amp;lt;urlset xmlns=&amp;quot;http://www.sitemaps.org/schemas/sitemap/0.9&amp;quot;&amp;gt;
   [#list products as product]
   &amp;lt;url&amp;gt;
      &amp;lt;loc&amp;gt;/${product.sku}/${product.slug}&amp;lt;/loc&amp;gt;
   &amp;lt;/url&amp;gt;
   [/#list]
   &amp;lt;/urlset&amp;gt;

&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;
&lt;/code&gt;&lt;/pre&gt;
</content:encoded></item><item><title>Spring Boot multi module with Gradle</title><description>how to create a multi-module spring project</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Wed, 13 Aug 2014 00:00:00 GMT</pubDate><guid isPermaLink="true">spring-boot-multi-module-gradle.html</guid><content:encoded>&lt;p&gt;Gradle is a build tool in the java world that will one day hopefully deprecate maven. I hate editing XML (like most other humans) and Gradle uses it’s own DSL (looks like groovy) to define you build file. Spring boot has a great plugin for Gradle which make setting up the build easier.
To create a multi module project for Spring boot with Gradle here are the steps you need to follow:&lt;/p&gt;
&lt;h1&gt;Root configuration&lt;/h1&gt;
&lt;p&gt;in the root directory of your project create a file called settings.gradle and add this content&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;include &amp;quot;my-sub-module1&amp;quot;
include &amp;quot;my-sub-module2&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;add all the sub modules with an include directive.
Now create a file build.gradle in the root directory and add the following&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;buildscript {
    repositories {
        mavenCentral()
    }
    dependencies {
        classpath(&amp;quot;org.springframework.boot:spring-boot-gradle-plugin:1.3.0.RELEASE&amp;quot;)
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h1&gt;Sub-module configuration&lt;/h1&gt;
&lt;p&gt;Now for each sub-module that you have you will create a build.gradle file in the sub-module directory with the content&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;apply plugin: &amp;quot;java&amp;quot;
apply plugin: &amp;quot;idea&amp;quot;
apply plugin: &amp;quot;eclipse&amp;quot;
apply plugin: &amp;quot;spring-boot&amp;quot;
apply plugin: &amp;quot;war&amp;quot;
repositories {
    mavenCentral()
    maven { url &amp;quot;http://mvn.dendiz.com/repository/internal&amp;quot; }
}

dependencies {
    testCompile &amp;quot;junit:junit:4.11&amp;quot;
}

sourceCompatibility = 1.8
targetCompatibility = 1.8

dependencies {
    // tag::jetty[]
    compile(&amp;quot;org.springframework.boot:spring-boot-starter-web&amp;quot;) {
        exclude group:&amp;quot;org.springframework.boot&amp;quot;, module: &amp;quot;spring-boot-starter-jetty&amp;quot;
    }
    compile(&amp;quot;org.springframework.boot:spring-boot-starter-data-mongodb&amp;quot;)
    compile(&amp;quot;org.springframework.boot:spring-boot-starter-freemarker&amp;quot;)
    testCompile(&amp;quot;org.springframework.boot:spring-boot-starter-test&amp;quot;)
    testCompile(&amp;quot;junit:junit&amp;quot;)
}

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;adjust your plugins and dependencies as needed, these are just some example dependencies.&lt;/p&gt;
</content:encoded></item><item><title>Spring annotation based authentication</title><description>a simple authentication mechanism for spring, when Spring Security is too much</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Fri, 18 Jul 2014 00:00:00 GMT</pubDate><guid isPermaLink="true">spring-annotation-authentication.html</guid><content:encoded>&lt;p&gt;a simple authentication mechanism for those that cannot be bother to set up spring security can be implemented using spring interceptors and an annotation. Spring interceptors and invoked before the controllers and are a great place to do authentication checking. The basic approach is&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;create an interceptor&lt;/li&gt;
&lt;li&gt;check the method that will be executed for this request in the interceptor&lt;/li&gt;
&lt;li&gt;if the method has an annotation check login state for the request.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I'll be demonstrating this concept for an API that does authentication using a parameter called “token” but it can be simply adapted to session based authentication mechanisms.
First of all you’ll need the interceptor, create a class called AuthenticationInterceptor and extend the spring HandlerInterceptorAdapter class. You could also implement the HandlerInterceptor interface.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@Override
    public boolean preHandle(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse, Object handler) throws Exception {
        HandlerMethod handlerMethod = (HandlerMethod) handler;
        LoginRequired loginRequired = handlerMethod.getMethod().getAnnotation(LoginRequired.class);
        if (loginRequired == null) {
            return true;
        }

        String token = httpServletRequest.getParameter(&amp;quot;token&amp;quot;);

        if (StringUtils.isBlank(token)) {
            throw new MissingParameterException();
        }

        authenticationService.checkToken(token);

        return super.preHandle(httpServletRequest, httpServletResponse, handler);
    }

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;what’s going on here is that we get the method for the request from the handler object, and check for an annotation named LoginRequired. If it is not present than this action does not require any login checks so proceed with any other handlers in the chain. If there is an annotation ask the authenticationService to do some checks. I assume that the service will throw an exception if the token is invalid.
Next we need the annotation itself. Create an the annotation with the content&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@Target({ElementType.METHOD, ElementType.TYPE})
        @Retention(RetentionPolicy.RUNTIME)
        public @interface LoginRequired {
        }

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Quite simple. The retention policy is important so that the interceptor can find the annotation.
next annotate any controllers you need to be protected with @LoginRequired.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@RequestMapping(value = &amp;quot;/protected/controller&amp;quot;)
@LoginRequired
public ResponseEntity&amp;lt;BaseResponse&amp;gt; controller() {
   ...
}
&lt;/code&gt;&lt;/pre&gt;
</content:encoded></item><item><title>Cure for your boredom at work</title><description>Not challanged or bored at work? This is why and how to cure it.</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Tue, 17 Jun 2014 00:00:00 GMT</pubDate><guid isPermaLink="true">cure_for_job_boredom.html</guid><content:encoded>&lt;p&gt;Most of the people around me in all kinds of different domains of work, usually complain about how boring / mundane their jobs are and are demotivated and probably hate getting up in the morning and going to work. There are also the &amp;quot;lucky&amp;quot; kind of people that despite doing the same thing year after year either are not bored or are bored but don't mind the boredom. If there are really not bored, which I find incomprehensible - that's fine. If they are bored but don't have the will power to change it then there is not much I could recommend. But there are also the kind that want to change but don't know how it's possible. I probably would fall into this category. At it's core what you do as a software engineer is read/write and process data. One way or another be it be database manipulations, video/image manipulations or something else. Different domains require different optimizations on the way of manipulating the data. For example some could require efficient usage of memory, others may require fault tolerance or speed. And for most of the people out there nobody is inventing a new wheel. We are just implementing already defined solutions to our problem. This can get boring extremely fast. Although I do not have any experience as a professional in other disciplines, I believe it's not wrong to interpolate that the same goes for jobs. It's the same rinse and repeat cycle day after day and for people with creative minds this can be a torturing experience. This is one of the main reasons I believe that the turn-over rate in the IT industry is above average (http://www.techrepublic.com/blog/career-management/tech-companies-have-highest-turnover-rate/). So what can be done to make your job challenging and fun? What drives those who are creative but yet still manage to do amazing stuff without getting bored? Those who everybody looks at with envy and wishes they had that job? What I came to realize is that the kind of people that consistently seek new challenges will satisfy this by either letting go of the current position, or by progressing in a different area. This doesn't mean that you have solved or out grown the task at hand, it just means that you are no longer satisfied in general with doing the similar stuff day after day. An example would be for a database programmer to explore the field of 3D graphics and games. There are new unexplored problems in that domain that you can relate to and solving these problems or researching them broadens your perspective. The moment you can adapt the methods used in that field to your field of expertise you've hit the jackpot. This can be a moment of a truly unique discovery or invention or just a satisfying &amp;quot;aha&amp;quot; moment. But whatever it is it will make your brain flood with endorphins and make you feel good. A lot of inventions ranging from machinery to algorithms were made by mimicking nature! A completely unrelated field to both computer science and engineering in general. It is highly likely that some guy who was a keen observer and a creative type and possibly had an ant farm one day had a lightning bolt idea of mimicking the techniques used by ants to optimize their food search and adapting these techniques to calculate optima in general CS problems - Ant swarm optimization was born. Yngwie Malmsteen is a great electric guitar virtuoso but if he is the type of guy I'm talking about I bet he would be bored sick with all his songs and albums, because they basically very similar. On the other hand Pink Floyd who is infamous for experimenting with drugs brings a whole new experience to their music. They are incorporating different aspects from different experiences into their music not to get boring. The 1970s version of top gear was just like any other car show. That's why it was boring and eventually went off-air. The new version of top gear has so many different themes in it ranging from comedy to challenges to other ridiculous stuff but that's what made the show a huge success and interesting. Adapting aspects from totally different areas into your own area or domain makes things interesting and worth while.&lt;/p&gt;
</content:encoded></item><item><title>The mechanics of the Bachelor show</title><description>A look at the psychological games and manipulations in the TV show 'The Bachelor(ette)'</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Thu, 10 Oct 2013 00:00:00 GMT</pubDate><guid isPermaLink="true">mechanics_bachelor.html</guid><content:encoded>&lt;p&gt;2013-10-10&lt;/p&gt;
&lt;p&gt;Usually I don't have any time to watch unplanned TV (zapping from channel to channel etc.) but recently I -by chance- did catch an episode of the reality TV show known as The Bachelor. I would have assumed that these shows consist of fabricated scenarios that are setup on purpose to introduce conflict and drama, so the show will sell. I was not disappointed.&lt;/p&gt;
&lt;p&gt;The basics of the show are that you have 25 women competing for the &amp;quot;love&amp;quot; of one man. Why would anybody want to participate in this to find love, that I cannot understand. The chances of getting a proposal seem rather slim, and even if you do, the chances of a marriage that would last is even slimmer. The show aired 17 seasons (excluding the sister show - the bachelorette) and of these 17 couples only 1 has made it this far. So that's 5% success rate if you are a winner. Each season has 25 contestants which means that out of the 425 women, only 1 made it. Those are rather slim chances considering the humiliation and suffering after rejection that you will have to face when you are eliminated, plus the drama, conflict and the stress that you will have to endure during the season. But still the public demands this show otherwise it would not have aired for 17 seasons.&lt;/p&gt;
&lt;p&gt;What is interesting is how the producers of this show manipulate the contestant and how these women still want to participate knowing that they are very likely to end up with a broken heart and hurt feelings. First of all the bachelor candidate is very above the average guy you would see around. Physical attraction and basic primitives are at work here. The producers also super charge this man with extremities that a regular person would not be able to deliver such as luxury dates in exotic location (a dinner in Thailand), abnormal ways of transportation (elephant back riding through the rain forest), etc. which adds to the admiration that the women build up for this man. What the women fail to realize (or they never mention it) is that these are all setup by the producers of the show and will end after the season, and they will probably be going back to eating cheap take outs.&lt;/p&gt;
&lt;p&gt;Another way to impose a bonding process (which is required so that the show will continue) is that they let the bachelor guide the women through a frightening experience, which would make the woman believe the bachelor is their hero. It is fairly simple for an isolated person, who is living away from the normal routine of their lives, to get confused by such an overwhelming exposure to raw emotions. The setup for this would include I believe an elicitation process done by the casting crew before the show is shot where the women would talk about their phobias or traumatic experiences. Once these are known it is fairly simple for the producers to setup scenarios where the bachelor can save the women from a plot that was fabricated by the producers in the first place. These ploys also exploit the fact that people are confused by the source of excitement during an adrenalin rush. They can't distinguish between cause of this sense. Is the source the event or the person that they are together with during this event. This type of bonding where the person would mistake physical safety for emotional safety would open the path for the person to trust the other person and to share traumas and other intimate secrets. Why on earth otherwise would you share such personal information with some one you only know for a couple of week and maybe spent only a few hours together? To amplify these effects the candidates are taken away from their daily lives and from the people that they know and trust that would normally contribute thoughts about this relationship. On the episodes that I watched where the guy goes to meet the family, nearly all of the families were skeptical about the process and the show, and they were right. This is because they are not caught in the race, and they are not manipulated. The same is true for women meeting the guys family. They are not in isolation and have a better perspective on the whole situation. But ultimately they all say &amp;quot;it's your choice.&amp;quot;. It's no wonder that the women are thinking that this guy is &amp;quot;the one&amp;quot; for them, because the producers are using the scarcity principle to elevate the value of the bachelor. The women only have a limited time with the guy, and they are pressured to make most of that time and therefore agree to doing all sorts of crazy stuff - like eating fried bugs - that they might normally prefer not to do. They also get caught in the heat of the competition.&lt;/p&gt;
&lt;p&gt;The producers select a mix of personalities that are likely to produce the most drama, and once the women assume a role, a persona for themselves they stick with it. This is comparable to the Stanford prison experiment conducted by Zimbardo, in which the inmates would comply with the request that were made by the guardians, even though they didn't have to. They chose instinctively to stick to their personas. These personas are usually stereotypical like the bitchy one, and the brave one who will confront the bitchy one, and the naive one who really is only seeking true love.&lt;/p&gt;
&lt;p&gt;I would say that seeking true love by participating in a TV show is total non-sense. The way that this is marketed as a means of helping people find love is also an insult. But never the less it was fun to watch a few episodes and enlightening to analyze the way that TV show producers are using psychological games to drive a business.&lt;/p&gt;
</content:encoded></item><item><title>Installing PHP PEAR in Wamp Server for Windows</title><description>how to get Wamp server to play nice with PEAR</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Tue, 05 Feb 2013 00:00:00 GMT</pubDate><guid isPermaLink="true">install_php_pear_wamp_server.html</guid><content:encoded>&lt;p&gt;This is just a reminder post for installing PHP PEAR in Wamp Server for windows, and a tutorial for people who want to install the PHP PEAR packages in Wamp server.
First thing's first download &lt;code&gt;GOPEAR&lt;/code&gt; which is a PHP archived version of the PEAR installer that we will use to install any packages. Save this file to your Wamp installations PHP binary directory (which for me is &lt;code&gt;C:\opt\wamp\bin\php\php5.3.13&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;now open a command prompt as an administrator (right click on &lt;code&gt;cmd.exe&lt;/code&gt; and choose &amp;quot;run as administrator&amp;quot;) and type the following commands&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;php go-pear.phar
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;choose system for a system wide installation. When the program prompts you with a list, just press enter to accept the defaults.
After the download has finished a file called &lt;code&gt;PEAR_ENV.reg&lt;/code&gt; will be created. This file contains environment variables for PEAR. Just double click it and install the registry file. Now open the file &lt;code&gt;C:\opt\wamp\bin\php\php5.3.13\php.ini&lt;/code&gt; and add the following&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;include_path = &amp;quot;.;C:\opt\wamp\bin\php\php5.3.13&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Don't forget to replace the path with your own installation directory. Add the same line to the file &lt;code&gt;C:\opt\wamp\bin\apache\apache2.2.22\bin\php.ini&lt;/code&gt; and restart apache. Now you can use the file &lt;code&gt;pear.bat&lt;/code&gt; in &lt;code&gt;C:\opt\wamp\bin\php\php5.3.13&lt;/code&gt; to install any packages. E.g&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pear.bat install net_smtp
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That's all there is to it really...&lt;/p&gt;
</content:encoded></item><item><title>JSPipe</title><description>A component framework for building JavaScript single page applications</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Wed, 01 Feb 2012 00:00:00 GMT</pubDate><guid isPermaLink="true">jspipe.html</guid><content:encoded>&lt;h1&gt;Quick Intro&lt;/h1&gt;
&lt;p&gt;PIPE is a small javascript framework for building ajax enabled application using a declarative syntax and minimal amount of javascript code. It works by splitting the application pages into fragments that have attributes that define the view model and behavior of the fragment. Installation is very easy, just include pipe.js in your HTML and the dependencies underscore.js and jquery and you are good to go. PIPE will run automatically after the document is loaded and work its magic.&lt;/p&gt;
&lt;h1&gt;Details&lt;/h1&gt;
&lt;p&gt;&lt;a href="http://deniz.dizman.org/img/pipejs-fragment.png"&gt;http://deniz.dizman.org/img/pipejs-fragment.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The diagram above shows components of a list application. We can divide this application into the following parts&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A collection of lists, that show which lists the user has created.&lt;/li&gt;
&lt;li&gt;The items in the selected list.&lt;/li&gt;
&lt;li&gt;The details of the item selected.&lt;/li&gt;
&lt;li&gt;Comments on the selected item.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Each of these components load a different view, have different behaviors, and refresh them selves on certain events. For example the comment component should refresh its self after the user has posted a comment, but the list collection need not refresh its self. This is what ajax applications are all about, just refreshing the required parts of the page, and leaving the rest alone, therefore providing a faster and smoother user experience. These components are called &amp;quot;fragments&amp;quot; in PIPE terminology. PIPE provides a framework of managing the lifecycles of these fragments, by loading and unloading them or refreshing them whenever there are data changes. It does so by making the user write only a minimal amount of javascript. The user can declare the behavir of the fragment by assigning special attributes in the markup.&lt;/p&gt;
&lt;p&gt;Let's take a closer look on these fragments (the following examples are all available on the example application on github):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    &amp;lt;div class=&amp;quot;span3&amp;quot;&amp;gt;
        &amp;lt;div id=&amp;quot;listbox&amp;quot; fragment-url=&amp;quot;/partial/listbox&amp;quot; watch=&amp;quot;/lists/add&amp;quot;&amp;gt;&amp;lt;/div&amp;gt;
        ...
    &amp;lt;/div&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is the code for the listbox - the collection of the lists - from the file &lt;code&gt;home.html.php&lt;/code&gt; which is the users home screen after login. The &lt;code&gt;div&lt;/code&gt; is the container for the fragment. Let's check out the attributes:&lt;/p&gt;
&lt;h1&gt;fragment-url&lt;/h1&gt;
&lt;p&gt;This attribute defines the URL that PIPE will request to inject into the container. When the page is loaded PIPE will scan all the &lt;code&gt;div&lt;/code&gt;s in the markup and find the fragment containers. Then an ajax GET request will be sent to these fragment URL in parallel. If a fragment is dependent on another fragment, you should embed the dependent fragment into the other fragments markup. PIPE will resolve the dependencies and load them in serial mode.&lt;/p&gt;
&lt;h1&gt;watch&lt;/h1&gt;
&lt;p&gt;This attribute defines a watcher URL which is used to notify the fragment that data has been updated and that it should load its self. PIPE will scan all fragments and register any watch URLs that a fragment contains. The URL is a regular expression so multiple URLs or wild card URLs may be defined using the javascript regular expression syntax. After an ajax request to the watch URL is completed, PIPE will refresh all the fragments with this watch URL, which means a request will be made to the fragment-url and the result will be injected into the container.&lt;/p&gt;
&lt;h1&gt;Params&lt;/h1&gt;
&lt;p&gt;This attribute defines any extra parameters that need to be sent to the fragment url as GET parameters. This enables interaction between fragments. For example in the lists application, when a user selects a list in the list box, the list item display fragment must be aware of which list to load. This can be done by passing parameters to the fragment url indicating which list to load. This attribute can also be manipulated using the javascript API of PIPE with the methods:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;PIPE.addParam&lt;/li&gt;
&lt;li&gt;PIPE.removeParam&lt;/li&gt;
&lt;li&gt;PIPE.setParams&lt;/li&gt;
&lt;li&gt;PIPE.getParams&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The attribute is stored as a query string, although the javascript API manipulates it as a JSON object.&lt;/p&gt;
&lt;h1&gt;Disabled&lt;/h1&gt;
&lt;p&gt;If this attribute is set to &amp;quot;disabled&amp;quot; PIPE will skip loading this fragment. This is usefull for just placing the container in the markup for future use. The example application uses this to show the details of the selected item. Until an item is selected from the list, it doesn't make sense to have the details item fragment loaded.&lt;/p&gt;
&lt;h1&gt;Unload&lt;/h1&gt;
&lt;p&gt;This attribute is used to empty the content of the fragment container on certain requests. This attribute acts exactly the same as the watch attribute, except that instead of refreshing the fragment, it will empty it. The example application uses this to empty the item details fragment, when an item is deleted.&lt;/p&gt;
&lt;h1&gt;Routes&lt;/h1&gt;
&lt;p&gt;PIPE also provides a javascript API under the PIPE namespace. PIPE can act as a router for binding functions to the location hash. This is a very simple way of adding behaviour to your elements. The syntax is very simple and can be seen in the &lt;code&gt;lists.js&lt;/code&gt; file.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    PIPE.register(&amp;quot;#!/list/:id/filter/:filter&amp;quot;, function(id,filter) {
        ....
    });
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;:id&lt;/code&gt; and &lt;code&gt;:filter&lt;/code&gt; are named parameters, meaning that any portion that matches the pattern will be given to the function as an argument. When the location hash matches this filter, the function gets executed. For example the URL&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    http://localhost/home/#!/lists/6/filter/incomplete
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;will execute the function with the parameters 6 and &amp;quot;incomplete&amp;quot; respectively.&lt;/p&gt;
&lt;h1&gt;PIPE.load&lt;/h1&gt;
&lt;p&gt;After certain user actions, you may need to reload a fragment with adjusted parameters. Using the PIPE parameter manipulation functions and PIPE.load this is possible. An example is displaying the item details. The registered function for the item display URL gets the list id, and item id from the named parameters and reloads the item detail fragment using the javascript API. Multiple requests made to the same fragment are queued and only the newest content will be injected into the container&lt;/p&gt;
</content:encoded></item><item><title>JSChess</title><description>A simple (stupid) engine that plays chess with you in your browser</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Sun, 15 Jan 2012 00:00:00 GMT</pubDate><guid isPermaLink="true">jschess.html</guid><content:encoded>&lt;p&gt;JSchess is a simple chess game coded with javascript against a moderate AI opponent (around 1200 ELO) that runs in the browser.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://deniz.dizman.org/img/jschess.png"&gt;img&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Source: https://github.com/dendiz/JSChess&lt;/p&gt;
</content:encoded></item><item><title>Carbine</title><description>an HTML5 game prototype</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Sat, 23 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">carbine.html</guid><content:encoded>&lt;p&gt;Carbine is an implementation of the game Crimsonland developed by 10tons. It’s a shoot’em up style game where you start the map in the middle and all sorts of zombies, spiders, monsters start creeping up towards you and you have to shoot them and keep running away from them. Here’s a video of the game if you don’t know it already.&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/h10.gif"&gt;/img/h10.gif&lt;/a&gt;
&lt;a href="https://youtu.be/lpYcCAgKMxs"&gt;https://youtu.be/lpYcCAgKMxs&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Here are some screenshots&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/57f4522362aaf.png"&gt;/img/57f4522362aaf.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/57f4523b99a8b.png"&gt;/img/57f4523b99a8b.png&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;Source code&lt;/h1&gt;
&lt;p&gt;The source code is released under any public domain license, i really don’t care. Use it, modify it, do what ever you want with it. You can find it on &lt;a href="http://github.com/dendiz"&gt;http://github.com/dendiz&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;Zombie movement&lt;/h1&gt;
&lt;p&gt;Each zombie has x and y coordinates that get updated at each game tick. The new x,y coordinates are calculated as x = velocity * math.sin(direction) and y = vel * math.cos(direction) where direction is the angle that the zombie is facing. This angle has to be towards the player at some times if we ever want the player to drop dead. The angle is calculated as alpha = atan2(player.x-zombie.x, player.y-zombie.y) derived from some simple vector calculations&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/57f45260c7ec9.png"&gt;/img/57f45260c7ec9.png&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;Blast effect when firing&lt;/h1&gt;
&lt;p&gt;Implemented by swaping the sprites of the original player with sprites that have a blast at the end on the gun at each move() function call for the player if the fire_anim variable is enabled. The fire_anim variable is set to true at the fire() method of the player and a timer is set to disable in after 10ms have passed.&lt;/p&gt;
&lt;h1&gt;Player keybinding&lt;/h1&gt;
&lt;p&gt;the a,s,d,w and keys are bound using the javascript evet handler. The a,s keys set the current player Y velocity to +maxspeed and -maxspeed and the a,d keys set the X velocity to -max and +max. They are triggered by the keydown event, and at each move() function call the coordinates are updated according to the value of the velocity variable. The keyup event sets these variables to zero. This way if the key is held in a pressed state the actor will keep moving.&lt;/p&gt;
&lt;h1&gt;Player movement&lt;/h1&gt;
&lt;p&gt;the direction of the player is calculated by taking the atan2 of the current player x,y and the current mouse x,y so that the player is always facing towards the cross-hair. If the velocity of the player is 0 than the current player sprite isn’t swapped because we don’t want the player to perform a moving animation otherwise the seconds that have passed from the game start is calculated form the current frame number and FPS and the correct sprite is selected form the sprite array of the player.&lt;/p&gt;
&lt;h1&gt;Player rendering&lt;/h1&gt;
&lt;p&gt;The player is rendered on the canvas by translating the canvas to the player x,y and rotating the canvas by the player direction and drawing the current sprite from the sprite index.&lt;/p&gt;
&lt;h1&gt;Player weapon firing&lt;/h1&gt;
&lt;p&gt;If the bullet count is 0 the weapon is reloaded. Then a bullet object is created an pushed on the projectiles array.&lt;/p&gt;
&lt;h1&gt;Projectile system&lt;/h1&gt;
&lt;p&gt;Projectiles are bullets fired by weapons. A weapon may fire multiple projectiles e.g shotgun. Rockets are also projectiles.The projectiles are stored in the C.projectiles array when they are displayable on the screen. Different types of projectiles may be present with different velocities and different damage factors. Location of the bullet is calculated each frame by the main event loop. Collision detection is performed at each frame with each zombie on the screen. If a collision is true the projectile is removed from the C.projectiles array.&lt;/p&gt;
&lt;h1&gt;Effects&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;projectiles are small but visible to the user&lt;/li&gt;
&lt;li&gt;projectiles should leave a trail of smoke or something to indicate the path. this trail is calculated by saving the x,y at the bullets creation time and drawing a line gradient with a fading alpha form the current x,y position of the bullet to saved position&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;Monotonic Trajectory&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;at the time of firing the bullet life is 0 and incremented each frame&lt;/li&gt;
&lt;li&gt;the x,y of the projectile is the player x,y at the time of firing.&lt;/li&gt;
&lt;li&gt;the direction angle phi is calculated as the angle between the x-axis and the line between the player x,y and an x,y at a random point in the crosshair circle&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;at each frame the next x,y is current x,y + sin(direction)/cos(direction) * velocity * bullet life&lt;/p&gt;
&lt;p&gt;Projectile direction angle&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/57f4527f8642c.png"&gt;/img/57f4527f8642c.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Projectile Trajectory&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/57f45298050e8.png"&gt;/img/57f45298050e8.png&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;Accuracy&lt;/h1&gt;
&lt;p&gt;The crosshair of the player widens with consecutives shots less than N seconds apart. The trajectory of the projectile intersect at a random point within this widend cross hair circle.&lt;/p&gt;
</content:encoded></item><item><title>Thoughts on Christopher Alexander's OOPSLA speech</title><description>Alexander talks about patterns, design and their applications to software</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">caoopsla.html</guid><content:encoded>&lt;p&gt;Alexanders thoughts on patterns and how they come to form a living structure can be adapted to software to some extent. CA, not being an expert in the field even mentions mappings of what he calls &amp;quot;centers&amp;quot; to software objects. Objects in software can be grouped in a few equivalence classes (interfaces, abstract classes, etc) that correspond to Alexander's core entities and are the building blocks of patterns. Using patterns as a means of information transfer and communication guide lines is already being used extensively. CA asks about the morality and the profoundness of his pattern language and how that is used is software, if it ever is. He mentions that the objective of a living structure is to increase the quality of life of those who experience it. This can be adapted to software, but from a different point of view. Software runs on a system which means it is governed by the virtual machine it runs on and the operating system at the least. So it can only interact with the system in a very constrained way, so there is not too much room for morality here. On the other side the interaction with the humans is the place that can be improved and the software may increase the quality of the experience it offers.
I think that buildings can be alive or dead like CA mentions, but buildings are not living things. They are static. They can't adapt to the changing environment or the circumstances. But software does have this opportunity. Software should be a living entity. Let me clarify this with a concrete example. The way many people start applications on they computers is usually by selecting the item through a variety of menus. In the DOS era such a visual aid providing an over sight of all the available applications was a contribution to the users perceived quality of life. This sort of application launching is still common today, but programs such as QuickSilver for mac take this one step further by allowing the user to conveniently type just a few letters of the program they wish to run, or an action they wish to perform (e.g copy a file) and adaptively suggest actions to the user by analyzing their usage patterns. This is what I understand from a living entity. The ability to adapt. So yes software can have profoundness and morality, but this can't be achieved by using more design patterns, nor does using any design patterns bring this quality. This can be achieved by making the software understand the users patterns and making it more humane.
On the subject of generativity: using a patterns language can't guarantee wholeness and coherence due to the fact that it is localized. So long as one doesn't maintain an outlook at the whole system there is no way of achieving coherence. Hence it is no surprise that their attempt to create a living campus failed in general but delivered locally successful results. The same would be true for any system including software or hardware systems.
Another subject of patterns in software in the issue of graphical user interface design and the patterns associated with it.This seems more in tact with the pattern theory of CA. I think in the last decade major improvements have been made to the way we act with computers. Current user interfaces are profound and coherent. Do they increase the quality of our lives? 
probably yes. Do they make the world a better place? I don't know. These are subjective matters, and I personally am not the type that really cares for &amp;quot;design&amp;quot; because I get bored easily. I sold my mac book pro for an ibm thinkpad, what do I understand from design. That's why I shouldn't be taken too seriously on these matters.&lt;/p&gt;
</content:encoded></item><item><title>BitchX uzerinden IM</title><description>Konsoldan cikmadan IM</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Mon, 01 Jan 2007 00:00:00 GMT</pubDate><guid isPermaLink="true">bitchx_im.html</guid><content:encoded>&lt;p&gt;Konsol kullanmanin zevki bir baskadir.. Insani nedense bir tribe sokar? Benim konsol ve konsolda calisan programlari sevmemin nedeni, mouse kullanmadan, klavyeden hizlica islemlerin yapilmasidir. Cunku mouse kullanmak icin elimi klavyeden kaldirmam demek, 0.5 sn mouse gidis, 0.5 sn mouse pointerini istedigim yere getirmem, 0.5 sn tekrar klavyeye donus, 0.5 saniye klavyeye yerlesme, yani 2 sn kayip demek.Ayrica ekstradan getirdigi ritm bozuklugunuda eklemek gerekli. Neyse bu amacla konsol uzerinden calisabilecek bir IM istemcisi aramaya koyuldum. EKG2 gayet artiz bir ara yuze sahip, yetenekli bir istemci gibi gorunuyordu, biraz kurcaladim, ama inanilmaz bir dokuman, daha dogrusu ingilizce dokuman eksikligi var. Polonyaca (herhalde boyle deniliyor) dokumanlari cozmeye calismaktan imanim gevredi, en sonundada pes ettim. Licq ve arkadaslari gibi bir cok yetenkli program buldum , ama istedigim ara yuze sahip degillerdi. Benim aklimdaki (EKG2de de olan) bitchX tarzi bir arayuzdu. Daha sonra BitchX uzerinden (aslinda herhangi bir IRC istemcisi uzerinden) MSN, Jabber, vs. protokollere baglanmayi sagalayan BitlBee diye bir daemon programina rastladim. Mantik gayet basit ve $ikti. IRC sunucusu gibi davranan bu program, arkada belirtilen IM protokoluna bagalaniyor, ve mesajlari forwardliyor. Kanal Listesinde ise IM programindaki rosteriniz da gorununen kisiler gorunuyor. Artik BitchX le IM yapabiliyorum.&lt;/p&gt;
</content:encoded></item><item><title>How to Pokebot</title><description>Taking a stab at creating an online poker bot</description><author>Deniz Dizman &lt;deniz.dizman@gmail.com&gt;</author><pubDate>Mon, 01 Jan 2007 00:00:00 GMT</pubDate><guid isPermaLink="true">how_to_pokebot.html</guid><content:encoded>&lt;p&gt;&lt;em&gt;This a historic document that I found somewhere on my hard drive. It's incomplete
and the quality is very poor at best&lt;/em&gt;&lt;/p&gt;
&lt;h2&gt;The devil: win32 API&lt;/h2&gt;
&lt;p&gt;To capture the messages from the window of the poker client, had to be done with win api stuff. The other options that come to mind are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;decrypt the network traffic between the poker room client and server, which is probably impossible&lt;/li&gt;
&lt;li&gt;screen scrape the poker room client, which i think is a bad idea and hard to implement error prone etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So we need to hook various api functions, ExtTextout, DrawText, etc. Tutorial about this stuff on the web are quite scarce, after quite a while of searching i came up with two simple code examples:&lt;/p&gt;
&lt;p&gt;hookdll.c:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#include &amp;lt;windows.h&amp;gt;
#include &amp;lt;string.h&amp;gt;
#include &amp;lt;stdio.h&amp;gt;

#pragma data_seg(&amp;quot;hookdata&amp;quot;)
HHOOK oldkeyhook = 0;
#pragma data_seg()
#pragma comment(linker, &amp;quot;/SECTION:hookdata,RWS&amp;quot;)

#define DllExport  __declspec (dllexport)

DllExport LRESULT CALLBACK KeyboardProc(int nCode, WPARAM wParam, LPARAM lParam);
DllExport void InstallHook(int nCode);
DllExport void EndHook();

HINSTANCE hInst = NULL;

BOOL APIENTRY DllMain(HINSTANCE hInstance,DWORD  ul_reason_for_call,LPVOID lpReserved)
{
    switch(ul_reason_for_call)
    {
    case DLL_PROCESS_ATTACH:
 	   hInst = hInstance;
 	   break;
    case DLL_PROCESS_DETACH:
 	   break;
    case DLL_THREAD_ATTACH:
 	   break;
    case DLL_THREAD_DETACH:
 	   break;
    }
    return TRUE;
}

void InstallHook(int nCode)
{
    oldkeyhook = SetWindowsHookEx(WH_KEYBOARD, (HOOKPROC)KeyboardProc, hInst, 0);
}

DllExport LRESULT CALLBACK KeyboardProc(int nCode, WPARAM wp, LPARAM lp)
{
    FILE *fp;
    if (nCode &amp;gt;= 0)
    { 	  
 	   if ((lp &amp;amp; 0x80000000) == 0x80000000)
 	   {
 		   fp = fopen(&amp;quot;C:\\keys.txt&amp;quot;,&amp;quot;a+&amp;quot;);
 		   char lpszName[0x100] = {0};
 		   GetKeyNameText(lp,lpszName,0xFF);
 		   fwrite(lpszName,strlen(lpszName),1, fp);
 		   fclose(fp); 	  
        }   
   }
   return CallNextHookEx(oldkeyhook,nCode,wp,lp);
}
void EndHook(void)
{
    UnhookWindowsHookEx(oldkeyhook);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;hookexe.c:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#include &amp;lt;windows.h&amp;gt;

LRESULT CALLBACK WindowProcedure (HWND, UINT, WPARAM, LPARAM);
char szClassName[ ] = &amp;quot;mTn&amp;quot;;

int WINAPI WinMain (HINSTANCE hThisInstance,
                    HINSTANCE hPrevInstance,
                    LPSTR lpszArgument,
                    int nFunsterStil)

{
   
    MSG messages;           
    WNDCLASSEX wincl;       
    HWND hwnd; 
   
    wincl.hInstance = hThisInstance;
    wincl.lpszClassName = szClassName;
    wincl.lpfnWndProc = WindowProcedure;     
    wincl.style = CS_DBLCLKS;                
    wincl.cbSize = sizeof (WNDCLASSEX);

   
    wincl.hIcon = LoadIcon (NULL, IDI_APPLICATION);
    wincl.hIconSm = LoadIcon (NULL, IDI_APPLICATION);
    wincl.hCursor = LoadCursor (NULL, IDC_ARROW);
    wincl.lpszMenuName = NULL;                
    wincl.cbClsExtra = 0;                     
    wincl.cbWndExtra = 0;                     
   
    wincl.hbrBackground = (HBRUSH) COLOR_BACKGROUND;

   
    if (!RegisterClassEx (&amp;amp;wincl))
        return 0;

   
    hwnd = CreateWindowEx (
           0,                  
           szClassName,        
           &amp;quot;mTn keyb hook&amp;quot;,      
           WS_OVERLAPPEDWINDOW,
           CW_USEDEFAULT,      
           CW_USEDEFAULT,      
           190,                
           58,                
           HWND_DESKTOP,       
           NULL,               
           hThisInstance,      
           NULL                
           );

    ShowWindow (hwnd, nFunsterStil);

    while (GetMessage (&amp;amp;messages, NULL, 0, 0))
    {
        TranslateMessage(&amp;amp;messages);  
        DispatchMessage(&amp;amp;messages);
    }
    return (int)messages.wParam;
}

LRESULT CALLBACK WindowProcedure (HWND hwnd, UINT message, WPARAM wParam, LPARAM lParam)
{
   
    HWND hButton;
    HWND hButton1;
    static HMODULE hInsDll;
    HFONT hfDefault;
    void (*pInstallHook)(int);
    void (*pUninstallHook)(void);
    switch (message)                 
    {
       
 	   case WM_DESTROY:
            PostQuitMessage (0);      
            break;
        case WM_CREATE:
 		   hfDefault = (HFONT)GetStockObject(DEFAULT_GUI_FONT);//Sistem fontunu alýr
 		   hButton =  CreateWindow(&amp;quot;button&amp;quot;,&amp;quot;HOOK ET&amp;quot;,WS_CHILD | WS_VISIBLE | BS_PUSHBUTTON | WS_TABSTOP,0,0,80,24,hwnd,(HMENU)1001,((LPCREATESTRUCT)(lParam))-&amp;gt;hInstance,NULL);
 		   SendMessage(hButton, WM_SETFONT, (WPARAM)hfDefault, MAKELPARAM(FALSE, 0)); //sistem fontunu kullandýrýr
 		   hButton1 =  CreateWindow(&amp;quot;button&amp;quot;,&amp;quot;BIRAK&amp;quot;,WS_CHILD | WS_VISIBLE | BS_PUSHBUTTON | WS_TABSTOP,90,0,90,24,hwnd,(HMENU)1002,((LPCREATESTRUCT)(lParam))-&amp;gt;hInstance,NULL);
 		   SendMessage(hButton1, WM_SETFONT, (WPARAM)hfDefault, MAKELPARAM(FALSE, 0)); //sistem fontunu kullandýrýr
 		   hInsDll = LoadLibrary(&amp;quot;kbHookDll.dll&amp;quot;);
 		   break;
 	   case WM_COMMAND:
 		   switch(LOWORD(wParam))
 		   {
 			   case 1001:
 				   pInstallHook = (void (*)(int))GetProcAddress(hInsDll, &amp;quot;InstallHook&amp;quot;);
 				   pInstallHook(TRUE);
 				   break;

 			   case 1002:
 				   pUninstallHook = (void(*)(void))GetProcAddress(hInsDll,&amp;quot;EndHook&amp;quot;);
 				   pUninstallHook();
 				   break;
 		   }
 		   break;
        default:                     
            return DefWindowProc (hwnd, message, wParam, lParam);
    }
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The exe file injects a system wide hook dll that intercepts the keyboard keypress api call and logs the key pressed into a file. A very simple key-logger if you will. The codes logic is pretty simple i think, you just reroute the original api call to yours, do the stuff you want and then call the original api method. The method used here is a method provided by the windows api, so there is nothing illegitimate with the method. But thebad news is that this type of hooking is only supported for hooking messages between windows and not gdi32 api calls, which we need. So we can't use this method on a poker room client, that disguises its log text&lt;/p&gt;
&lt;h2&gt;Trying it Under Wine&lt;/h2&gt;
&lt;p&gt;After failed attemps on win32 API programming I came up with the ingenious idea of running the poker desktop clients on linux, under the wine win32 API emulator.  We had a discussion about the pro/cons of this approach.
Pros:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;wine is open source, so easy access to the API implementation to override custom windows stealth behaviours.&lt;/li&gt;
&lt;li&gt;No need to avoid poker room clients detection attempts, everything is in the wine source code&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Linux environment&lt;/p&gt;
&lt;p&gt;Cons:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Probably no source code to examine, need to hack wine codes by ourselves&lt;/li&gt;
&lt;li&gt;User input simulation still remains a mystery&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Installing wine under debian etch, was quite easy. I just grabbed the source from the sourceforge page and untarred it. The configure script keeps bugging you for the dependencies, which where lib-png, lib-jpeg, flex, bison, libxml2 for me,on a minimal desktop installation of debian. The build time takes quite a while, ~1,5 million lines of code, but completes without errors.
Next up, download the pokerroom executable from their page, and run it under wine. Wine complained about missing DLLs such as mfc 4.2 and visual C runtime files. To satisfy this hunger we used winetricks from http://www.kegel.com/winetricks which is a small script that downloads and install the dependecy DLLs.
When you fire up wine, the poker room client executes complaining about some DLL being old, which is not important. After you try to login, it says that it can't connect to the login server. This is because wine hardware ID's are blacklisted. To overcome this, you need to patch wine to report a different hardware id. Here is the patch for version 0.9.30:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;diff -uNr wine-0.9.30-fe/dlls/advapi32/advapi.c wine-0.9.30-fe-patched/dlls/advapi32/advapi.c
--- wine-0.9.30-fe/dlls/advapi32/advapi.c	2007-01-25 07:53:50.000000000 -0800
+++ wine-0.9.30-fe-patched/dlls/advapi32/advapi.c	2007-02-22 16:50:15.000000000 -0800
@@ -112,11 +112,57 @@
*/
BOOL WINAPI GetCurrentHwProfileA(LPHW_PROFILE_INFOA pInfo)
{
-	FIXME(&amp;quot;(%p) semi-stub\n&amp;quot;, pInfo);
-	pInfo-&amp;gt;dwDockInfo = DOCKINFO_DOCKED;
-	strcpy(pInfo-&amp;gt;szHwProfileGuid,&amp;quot;{12340001-1234-1234-1234-1233456789012}&amp;quot;);
-	strcpy(pInfo-&amp;gt;szHwProfileName,&amp;quot;Wine Profile&amp;quot;);
-	return 1;
+       CHAR profile[32];
+       DWORD type;
+       DWORD size;
+       DWORD ret;
+       DWORD val;
+       HKEY hkey;
+       BOOL profile_result = 0;
+
+       ret = RegOpenKeyA(HKEY_LOCAL_MACHINE, &amp;quot;System\\CurrentControlSet\\Control\\IDConfigDB&amp;quot;,
+                         &amp;amp;hkey);
+
+       if (ret != ERROR_SUCCESS)
+               goto profile_error;
+
+       ret = RegGetValueA(hkey, NULL, &amp;quot;CurrentConfig&amp;quot;, RRF_RT_DWORD,
+                          &amp;amp;type, &amp;amp;val, &amp;amp;size);
+       if (ret != ERROR_SUCCESS || size != 4 || type != REG_DWORD)
+               goto profile_error;
+
+       /* At least, I think the profile names are hex */
+       sprintf(profile, &amp;quot;Hardware Profiles\\%04x&amp;quot;, (WORD)(val &amp;amp; 0xffff));
+
+       /* Set the profile name */
+       size = MAX_PROFILE_LEN;
+       ret = RegGetValueA(hkey, profile, &amp;quot;FriendlyName&amp;quot;, RRF_RT_REG_SZ,
+                          &amp;amp;type, pInfo-&amp;gt;szHwProfileName, &amp;amp;size);
+
+       if (ret != ERROR_SUCCESS || type != REG_SZ)
+               goto profile_error;
+
+       /* Now get the GUID of this profile */
+       size = HW_PROFILE_GUIDLEN;
+       ret = RegGetValueA(hkey, profile, &amp;quot;HwProfileGuid&amp;quot;, RRF_RT_REG_SZ,
+                          &amp;amp;type, pInfo-&amp;gt;szHwProfileGuid, &amp;amp;size);
+
+       if (ret != ERROR_SUCCESS || type != REG_SZ)
+               goto profile_error;
+
+       /* And finally the docking state */
+       ret = RegGetValueA(hkey, &amp;quot;CurrentDockInfo&amp;quot;, &amp;quot;DockingState&amp;quot;, RRF_RT_DWORD,
+                          &amp;amp;type, &amp;amp;pInfo-&amp;gt;dwDockInfo, &amp;amp;size);
+
+       if (ret != ERROR_SUCCESS || size != 4 || type != REG_DWORD)
+               goto profile_error;
+
+       /* Success */
+      profile_result = 1;
+
+profile_error:
+       RegCloseKey(hkey);
+      return profile_result;
}

/******************************************************************************
diff -uNr wine-0.9.30-fe/tools/wine.inf wine-0.9.30-fe-patched/tools/wine.inf
--- wine-0.9.30-fe/tools/wine.inf	2007-01-25 07:53:50.000000000 -0800
+++ wine-0.9.30-fe-patched/tools/wine.inf	2007-02-22 16:51:03.000000000 -0800
@@ -237,6 +237,22 @@
HKLM,System\CurrentControlSet\Control\Session Manager\Environment,&amp;quot;windir&amp;quot;,,&amp;quot;%10%&amp;quot;
HKLM,System\CurrentControlSet\Control\Session Manager\Environment,&amp;quot;winsysdir&amp;quot;,,&amp;quot;%11%&amp;quot;

+[IDConfigDB]
+HKLM,System\CurrentControlSet\Control\IDConfigDB,&amp;quot;CurrentConfig&amp;quot;,,0x00000000
+HKLM,System\CurrentControlSet\Control\IDConfigDB,&amp;quot;UserWaitInterval&amp;quot;,,0x0000001e
+HKLM,System\CurrentControlSet\Control\IDConfigDB,&amp;quot;IsPortable&amp;quot;,,0x00000000
+HKLM,System\CurrentControlSet\Control\IDConfigDB\Alias\0000,&amp;quot;DockingState&amp;quot;,,0x00000000
+HKLM,System\CurrentControlSet\Control\IDConfigDB\Alias\0000,&amp;quot;Capabilities&amp;quot;,,0x00000000
+HKLM,System\CurrentControlSet\Control\IDConfigDB\Alias\0000,&amp;quot;DockID&amp;quot;,,0x00000000
+HKLM,System\CurrentControlSet\Control\IDConfigDB\Alias\0000,&amp;quot;SerialNumber&amp;quot;,,0x00000000
+HKLM,System\CurrentControlSet\Control\IDConfigDB\Alias\0000,&amp;quot;ProfileNumber&amp;quot;,,0x00000000
+HKLM,System\CurrentControlSet\Control\IDConfigDB\Hardware Profiles,&amp;quot;Unknown&amp;quot;,,0x00000000
+HKLM,System\CurrentControlSet\Control\IDConfigDB\Hardware Profiles\0000,&amp;quot;PreferenceOrder&amp;quot;,,0x00000000
+HKLM,System\CurrentControlSet\Control\IDConfigDB\Hardware Profiles\0000,&amp;quot;FriendlyName&amp;quot;,,&amp;quot;Wine Profile&amp;quot;
+HKLM,System\CurrentControlSet\Control\IDConfigDB\Hardware Profiles\0000,&amp;quot;Aliasable&amp;quot;,,0x00000000
+HKLM,System\CurrentControlSet\Control\IDConfigDB\Hardware Profiles\0000,&amp;quot;Cloned&amp;quot;,,0x00000000
+HKLM,System\CurrentControlSet\Control\IDConfigDB\Hardware Profiles\0000,&amp;quot;HwProfileGuid&amp;quot;,,&amp;quot;{abba0009-1ed34-1dad4-1333-1e3e4ebb890a}&amp;quot;
+
[Fonts]
HKLM,%FontSubStr%,&amp;quot;Arial CE,238&amp;quot;,,&amp;quot;Arial,238&amp;quot;
HKLM,%FontSubStr%,&amp;quot;Arial CYR,204&amp;quot;,,&amp;quot;Arial,204&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;cd into the wine source installation directory and apply the patch with&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;patch -p0 &amp;lt; patch.txt
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next you need to install some registry keys. Put the following into a text file and import with regedit file.txt.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;REGEDIT4
[HKEY_LOCAL_MACHINE\System\CurrentControlSet\Control\IDConfigDB]
&amp;quot;CurrentConfig&amp;quot;=hex:00,00,00,00
&amp;quot;IsPortable&amp;quot;=hex:00,00,00,00
&amp;quot;UserWaitInterval&amp;quot;=hex:00,00,00,1e
[HKEY_LOCAL_MACHINE\System\CurrentControlSet\Control\IDConfigDB\Alias]
[HKEY_LOCAL_MACHINE\System\CurrentControlSet\Control\IDConfigDB\Alias\0000]
&amp;quot;Capabilities&amp;quot;=hex:00,00,00,00
&amp;quot;DockID&amp;quot;=hex:00,00,00,00
&amp;quot;DockingState&amp;quot;=hex:00,00,00,00
&amp;quot;ProfileNumber&amp;quot;=hex:00,00,00,00
&amp;quot;SerialNumber&amp;quot;=hex:00,00,00,00
[HKEY_LOCAL_MACHINE\System\CurrentControlSet\Control\IDConfigDB\Hardware Profiles]
&amp;quot;Unknown&amp;quot;=hex:00,00,00,00
[HKEY_LOCAL_MACHINE\System\CurrentControlSet\Control\IDConfigDB\Hardware Profiles\0000]
&amp;quot;Aliasable&amp;quot;=hex:00,00,00,00
&amp;quot;Cloned&amp;quot;=hex:00,00,00,00
&amp;quot;FriendlyName&amp;quot;=&amp;quot;Wine Profile&amp;quot;
&amp;quot;HwProfileGuid&amp;quot;=&amp;quot;{abba0009-1ed34-1dad4-1333-1e3eb00a890a}&amp;quot;
&amp;quot;PreferenceOrder&amp;quot;=hex:00,00,00,00
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Build the source code, and install it.
After the installation process this is what you get:&lt;/p&gt;
&lt;p&gt;Now that wine works, we need to hook the text drawing functions to capture the game log and process it.
Normally this would be an easy task under windows, but the poker rooms use tricks to prevent this from happening.
They use custom windows that override the WM_GETTEXT function that should return the contents of a control, and make it return nothing. So we have to hook the text displaying portion of the operating systems API, in this case the wine API.
This method resides in the file dlls/user32/text.c. For testing purposes add the following line into DrawTextExW():&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;FIXME(&amp;quot;%s, %d, [%s] %08x\n&amp;quot;, debugstr_wn (str, count), count,
        wine_dbgstr_rect(rect), flags);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now save the file and exit. Run the poker room client with wine, and watch the terminal output a lot of messages. Login to your account and sit at a table.
If you watch the terminal log, you'll see messages flying by with every little piece of text that is ever drawn on to the wine windows. This includes the game log that we are interested in. Now there are a few problems that we can identify here:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;we don't want to receive messages from the lobby windows, including garbage chat conversations.&lt;/li&gt;
&lt;li&gt;Poker room developers tried make our lives harder by calling drawText for every word instead of sentences.&lt;/li&gt;
&lt;li&gt;There are duplicate messages all over the place&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This is a screen shot of where we are now:&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/pokebot.png"&gt;/img/pokebot.png&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;The Brain&lt;/h2&gt;
&lt;p&gt;Before setting out to code and getting our hands dirty, the most scary part seemed to me the win 32 API stuff, probably because I've been a linux console/web programmer all my life, and i was never into windows and desktop client, especially low level - unmanaged windows API calls. But it seems there are a lot of resources and documents, and even managed code that hooks API calls (discussed in a different chapter). The real beast is the brain, the decision making part, the AI Server.&lt;/p&gt;
&lt;p&gt;First off before discussing the actual algorithms and techniques, lets dicuss the architecture, and why it is called the AI Server. Simple: we'll have multiple poker room clients, playing on mutliple tables, some times even 2 of our bots playing on the same table, and sharing data, though one might think that this would decrease the winnings, and giving more rake, but this would increase our chances of winning more money from the other players. AI algorithms should be changable and tunable on the fly, and yet per AI Client (the Agent) configurable. The best design decision seemed like a client/server model, where the server was the AI Server, and the clients were the agents, that were the gateway between the AI and the poker room client. The AI Server's architectural crude design is like this:
[AIServer Diagram in Omnigraffle]&lt;/p&gt;
&lt;p&gt;Flexibilty is a key design objective in most of the projects that get designed. This also was the case in the AI Server. Different algorithms had to be pluggable as modules, changeable according to table characteristics (heretic players, tight players, etc.) without the need of recompilation of code.&lt;/p&gt;
&lt;p&gt;Multi-thread is a core requirement, because we'll be serving a lot of requests and clients&lt;/p&gt;
&lt;p&gt;Cheating and using a application container such as tomcat doesn't help because HTTP is a stateless protocol, and poker is a statefull game. The state will have to be carried out by URL parameters or session/cookies which means that the agent will need to implement a HTTP client, which is not worth the effort. Instead we designed our own text based communication protocol. The protocol is TCP and Text based. Very simple, clients send commands and the server threads act accordingly.&lt;/p&gt;
</content:encoded></item></channel></rss>